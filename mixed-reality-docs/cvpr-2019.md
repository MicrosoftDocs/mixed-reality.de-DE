---
title: Anwendungen für Computer Vision für Mixed Reality-Headsets-Workshop an CVPR 2019
description: Übersicht über und den Zeitplan für die Computer Vision-Anwendungen für Mixed Reality-Headsets Workshop, bei der Konferenz CVPR Juni 2019 übermittelt werden soll.
author: fbogo
ms.author: febogo
ms.date: 1/9/2019
ms.topic: article
keywords: Ereignis, Research-Modus, Cvpr, maschinelles sehen, Forschung, HoloLens
ms.openlocfilehash: 89d79bcef77043564e51faada940d2c71a6005e4
ms.sourcegitcommit: 2f600e5ad00cd447b180b0f89192b4b9d86bbc7e
ms.translationtype: MT
ms.contentlocale: de-DE
ms.lasthandoff: 06/15/2019
ms.locfileid: "67148709"
---
# <a name="computer-vision-applications-for-mixed-reality-headsets"></a><span data-ttu-id="7b07d-104">Anwendungen für Computer Vision für Mixed Reality-Headsets</span><span class="sxs-lookup"><span data-stu-id="7b07d-104">Computer Vision Applications for Mixed Reality Headsets</span></span>

<span data-ttu-id="7b07d-105">In Verbindung mit organisiert [CVPR 2019](http://cvpr2019.thecvf.com/)</span><span class="sxs-lookup"><span data-stu-id="7b07d-105">Organized in conjunction with [CVPR 2019](http://cvpr2019.thecvf.com/)</span></span>

<span data-ttu-id="7b07d-106">Lange Strandspaziergänge (CA)</span><span class="sxs-lookup"><span data-stu-id="7b07d-106">Long Beach (CA)</span></span>

<span data-ttu-id="7b07d-107">Juni 17, 2019 Nachmittag) - Hyatt Regency F</span><span class="sxs-lookup"><span data-stu-id="7b07d-107">June 17, 2019 (Afternoon) - Hyatt Regency F</span></span>


## <a name="organizers"></a><span data-ttu-id="7b07d-108">Organisatoren</span><span class="sxs-lookup"><span data-stu-id="7b07d-108">Organizers</span></span>
* <span data-ttu-id="7b07d-109">Marc Pollefeys</span><span class="sxs-lookup"><span data-stu-id="7b07d-109">Marc Pollefeys</span></span>
* <span data-ttu-id="7b07d-110">Federica Bogo</span><span class="sxs-lookup"><span data-stu-id="7b07d-110">Federica Bogo</span></span>
* <span data-ttu-id="7b07d-111">Johannes Schönberger</span><span class="sxs-lookup"><span data-stu-id="7b07d-111">Johannes Schönberger</span></span>
* <span data-ttu-id="7b07d-112">Osman Ulusoy</span><span class="sxs-lookup"><span data-stu-id="7b07d-112">Osman Ulusoy</span></span>

## <a name="overview"></a><span data-ttu-id="7b07d-113">Übersicht</span><span class="sxs-lookup"><span data-stu-id="7b07d-113">Overview</span></span>

![Teaser-Bild](images/cvpr2019_teaser2.jpg)

<span data-ttu-id="7b07d-115">Mixed Reality-Headsets, z. B. die Microsoft HoloLens Produktivitätsgründen leistungsfähige Plattformen, um die Computer Vision-Anwendungen zu entwickeln.</span><span class="sxs-lookup"><span data-stu-id="7b07d-115">Mixed reality headsets such as the Microsoft HoloLens are becoming powerful platforms to develop computer vision applications.</span></span> <span data-ttu-id="7b07d-116">HoloLens Research-Modus können Forschung zu maschinellem sehen auf Gerät, indem Zugriff auf alle raw-Image-Sensor Streams – einschließlich der Tiefe und IR</span><span class="sxs-lookup"><span data-stu-id="7b07d-116">HoloLens Research Mode enables computer vision research on device by providing access to all raw image sensor streams -- including depth and IR.</span></span> <span data-ttu-id="7b07d-117">Da Research-Modus jetzt seit Mai 2018 verfügbar sind, beginnen wir damit mehrere interessante Demos und Anwendungen, die HoloLens entwickelt wird, finden Sie unter.</span><span class="sxs-lookup"><span data-stu-id="7b07d-117">As Research Mode is now available since May 2018, we are starting to see several interesting demos and applications being developed for HoloLens.</span></span> 

<span data-ttu-id="7b07d-118">Das Ziel von diesem Workshop ist zum Zusammenführen von Schüler/Studenten und Forscher interessiert maschinelles sehen für mixed Reality-Anwendungen.</span><span class="sxs-lookup"><span data-stu-id="7b07d-118">The goal of this workshop is to bring together students and researchers interested in computer vision for mixed reality applications.</span></span> <span data-ttu-id="7b07d-119">Der Workshop bieten einen Veranstaltungsort zum Freigeben von Demos und Anwendungen und erfahren Sie mehr voneinander, zum Erstellen oder Portieren von Anwendungen, mixed Reality.</span><span class="sxs-lookup"><span data-stu-id="7b07d-119">The workshop will provide a venue to share demos and applications, and learn from each other to build or port applications to mixed reality.</span></span> 

<span data-ttu-id="7b07d-120">Wir empfehlen die Übermittlung von Apps zu den Themen der objekterkennung (Neugier-orientierte), manuell und durch Benutzer, aktivitätserkennung, SLAM, 3D Wiederaufbau, Verständnis der Szene, sensorbasierte Lokalisierung, Navigation und mehr.</span><span class="sxs-lookup"><span data-stu-id="7b07d-120">We encourage submissions on the topics of (ego-centric) object recognition, hand and user tracking, activity recognition, SLAM, 3D reconstruction, scene understanding, sensor-based localization, navigation and more.</span></span>

## <a name="paper-submission"></a><span data-ttu-id="7b07d-121">Dokument-Übermittlung</span><span class="sxs-lookup"><span data-stu-id="7b07d-121">Paper Submission</span></span>
* <span data-ttu-id="7b07d-122">Stichtag für das Dokument senden: 17. Mai</span><span class="sxs-lookup"><span data-stu-id="7b07d-122">Paper submission deadline: May 17</span></span>
* <span data-ttu-id="7b07d-123">Benachrichtigung für Autoren: 24. Mai</span><span class="sxs-lookup"><span data-stu-id="7b07d-123">Notification to authors: May 24</span></span>

<span data-ttu-id="7b07d-124">Artikel sollten die CVPR-Vorlage verwenden und sind 4 Seiten sowie Verweise auf.</span><span class="sxs-lookup"><span data-stu-id="7b07d-124">Paper submissions should use the CVPR template and are limited to 4 pages plus references.</span></span> <span data-ttu-id="7b07d-125">Darüber hinaus empfehlen wir die Autoren, um ein Video, das mit ihrer Anwendung zu übermitteln.</span><span class="sxs-lookup"><span data-stu-id="7b07d-125">In addition, we encourage the authors to submit a video showcasing their application.</span></span>
<span data-ttu-id="7b07d-126">Beachten Sie, dass Übermittlungen von zuvor veröffentlichte Arbeitselemente zulässig sind (einschließlich Arbeit akzeptieren, um die CVPR 2019 hauptkonferenzraum).</span><span class="sxs-lookup"><span data-stu-id="7b07d-126">Note that submissions of previously published work are allowed (including work accepted to the main CVPR 2019 conference).</span></span> 

<span data-ttu-id="7b07d-127">Um CMT können Übergaben hochgeladen werden: https://cmt3.research.microsoft.com/CVFORMR2019</span><span class="sxs-lookup"><span data-stu-id="7b07d-127">Submissions can be uploaded to the CMT: https://cmt3.research.microsoft.com/CVFORMR2019</span></span>

<span data-ttu-id="7b07d-128">Eine Teilmenge von Dokumenten in einer wird für mündlich Präsentation zu den Workshop ausgewählt werden.</span><span class="sxs-lookup"><span data-stu-id="7b07d-128">A subset of papers will be selected for oral presentation at the workshop.</span></span> <span data-ttu-id="7b07d-129">Allerdings empfohlen dringend, dass alle Autoren präsentieren Sie ihre Arbeit während der demositzung.</span><span class="sxs-lookup"><span data-stu-id="7b07d-129">However, we strongly encourage all the authors to present their work during the demo session.</span></span>


## <a name="schedule"></a><span data-ttu-id="7b07d-130">Zeitplan</span><span class="sxs-lookup"><span data-stu-id="7b07d-130">Schedule</span></span>
* <span data-ttu-id="7b07d-131">13:30-13:45: Willkommen, und öffnen "Hinweise".</span><span class="sxs-lookup"><span data-stu-id="7b07d-131">13:30-13:45: Welcome and Opening Remarks.</span></span>
* <span data-ttu-id="7b07d-132">13:45-14:15: **Keynote-Vortrag**: Prof. Marc Pollefeys ETH Zürich und Microsoft.</span><span class="sxs-lookup"><span data-stu-id="7b07d-132">13:45-14:15: **Keynote talk**: Prof. Marc Pollefeys, ETH Zurich/Microsoft.</span></span> <span data-ttu-id="7b07d-133">Titel: Egocentric maschinelles sehen für HoloLens.</span><span class="sxs-lookup"><span data-stu-id="7b07d-133">Title: Egocentric Computer Vision on HoloLens.</span></span>
* <span data-ttu-id="7b07d-134">14:15-14:45: **Keynote-Vortrag**: Prof. Kris Kitani, Carnegie Mellon University.</span><span class="sxs-lookup"><span data-stu-id="7b07d-134">14:15-14:45: **Keynote talk**: Prof. Kris Kitani, Carnegie Mellon University.</span></span> <span data-ttu-id="7b07d-135">Titel: Egocentric Aktivität und die Haltung Vorhersagen.</span><span class="sxs-lookup"><span data-stu-id="7b07d-135">Title: Egocentric Activity and Pose Forecasting.</span></span>
* <span data-ttu-id="7b07d-136">14:45-15:15: **Keynote-Vortrag**: Dr. Yang Liu, California Institute of Technology.</span><span class="sxs-lookup"><span data-stu-id="7b07d-136">14:45-15:15: **Keynote talk**: Dr. Yang Liu, California Institute of Technology.</span></span> <span data-ttu-id="7b07d-137">Titel: Können ein Cognitive-Assistent für Blinde mit Augmented Reality-Modus.</span><span class="sxs-lookup"><span data-stu-id="7b07d-137">Title: Powering a Cognitive Assistant for the Blind with Augmented Reality.</span></span>
* <span data-ttu-id="7b07d-138">15:15-16:15: Kaffeepause und Demos.</span><span class="sxs-lookup"><span data-stu-id="7b07d-138">15:15-16:15: Coffee break and demos.</span></span>
* <span data-ttu-id="7b07d-139">16:15-16:45: **Keynote-Vortrag**: Prof. Kristen Grauman, University of Texas in Austin/Facebook-KI-Forschung.</span><span class="sxs-lookup"><span data-stu-id="7b07d-139">16:15-16:45: **Keynote talk**: Prof. Kristen Grauman, University of Texas at Austin/Facebook AI Research.</span></span> <span data-ttu-id="7b07d-140">Titel: Human-Object-Interaktion in Zeitraffervideos Video.</span><span class="sxs-lookup"><span data-stu-id="7b07d-140">Title: Human-object interaction in first-person video.</span></span>
* <span data-ttu-id="7b07d-141">16:45-17:15: Mündliche Präsentationen:</span><span class="sxs-lookup"><span data-stu-id="7b07d-141">16:45-17:15: Oral presentations:</span></span>
    * <span data-ttu-id="7b07d-142">Registrierung war einfach – eigenständige Orthopädische Navigation mit HoloLens.</span><span class="sxs-lookup"><span data-stu-id="7b07d-142">Registration made easy - standalone orthopedic navigation with HoloLens.</span></span> <span data-ttu-id="7b07d-143">F.</span><span class="sxs-lookup"><span data-stu-id="7b07d-143">F.</span></span> <span data-ttu-id="7b07d-144">Liebmann, S. Roner, M. von Atzigen, f Wanivenhaus, C. Neuhaus, J. Spirig, D. Scaramuzza, r Sutter, J. Snedeker, M. Farshad, s. Furnstahl.</span><span class="sxs-lookup"><span data-stu-id="7b07d-144">Liebmann, S. Roner, M. von Atzigen, F. Wanivenhaus, C. Neuhaus, J. Spirig, D. Scaramuzza, R. Sutter, J. Snedeker, M. Farshad, P. Furnstahl.</span></span>
    * <span data-ttu-id="7b07d-145">Learning-Stereo mit einem HoloLens.</span><span class="sxs-lookup"><span data-stu-id="7b07d-145">Learning stereo by walking around with a HoloLens.</span></span> <span data-ttu-id="7b07d-146">H.</span><span class="sxs-lookup"><span data-stu-id="7b07d-146">H.</span></span> <span data-ttu-id="7b07d-147">Zhan, Y. Pekelny, O. Ulusoy.</span><span class="sxs-lookup"><span data-stu-id="7b07d-147">Zhan, Y. Pekelny, O. Ulusoy.</span></span>
* <span data-ttu-id="7b07d-148">17:15-17:30: Letzte "Hinweise".</span><span class="sxs-lookup"><span data-stu-id="7b07d-148">17:15-17:30: Final Remarks.</span></span>
