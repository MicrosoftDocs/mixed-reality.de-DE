---
title: Gebietsschemabezogene Kamera
description: Allgemeine Informationen zu den mit Internetzugriff HoloLens frontkamera.
author: wguyman
ms.author: wguyman
ms.date: 02/24/2019
ms.topic: article
keywords: Kamera, Hololens, Farbe Kamera, Front-facing
ms.openlocfilehash: ffcd6faf15dd8556db393237d468a3cdf60e4bdb
ms.sourcegitcommit: 384b0087899cd835a3a965f75c6f6c607c9edd1b
ms.translationtype: MT
ms.contentlocale: de-DE
ms.lasthandoff: 04/12/2019
ms.locfileid: "59596324"
---
# <a name="locatable-camera"></a><span data-ttu-id="2cb13-104">Gebietsschemabezogene Kamera</span><span class="sxs-lookup"><span data-stu-id="2cb13-104">Locatable camera</span></span>

<span data-ttu-id="2cb13-105">HoloLens enthält, eine Welt gerichteten Kamera, die auf der Vorderseite des Geräts, das kann apps finden Sie unter der Benutzer bereitgestellt wird.</span><span class="sxs-lookup"><span data-stu-id="2cb13-105">HoloLens includes a world-facing camera mounted on the front of the device which enables apps to see what the user sees.</span></span> <span data-ttu-id="2cb13-106">Entwickler haben Zugriff auf und Kontrolle der Kamera, genauso wie für die Color-Kameras auf Smartphones, tragbare Geräte und Desktops.</span><span class="sxs-lookup"><span data-stu-id="2cb13-106">Developers have access to and control of the camera just as they would for color cameras on smartphones, portables, or desktops.</span></span> <span data-ttu-id="2cb13-107">Die gleichen universelle Windows [medienaufzeichnung](https://msdn.microsoft.com/library/windows/apps/windows.media.capture.mediacapture.aspx) und Windows Media Foundation-APIs, die an mobile Geräte und Desktops arbeiten HoloLens.</span><span class="sxs-lookup"><span data-stu-id="2cb13-107">The same universal windows [media capture](https://msdn.microsoft.com/library/windows/apps/windows.media.capture.mediacapture.aspx) and windows media foundation APIs that work on mobile and desktop work on HoloLens.</span></span> <span data-ttu-id="2cb13-108">Unity [hat auch diese Windows-APIs umschlossen](locatable-camera-in-unity.md) abstrahieren einfache Verwendung der Kamera auf HoloLens für Aufgaben wie dauert regulären Fotos und Videos (mit oder ohne Hologramme), und suchen die Position der Kamera in und Perspektive auf die die Szene.</span><span class="sxs-lookup"><span data-stu-id="2cb13-108">Unity [has also wrapped these windows APIs](locatable-camera-in-unity.md) to abstract simple usage of the camera on HoloLens for tasks such as taking regular photos and videos (with or without holograms) and locating the camera's position in and perspective on the scene.</span></span>

## <a name="device-camera-information"></a><span data-ttu-id="2cb13-109">Kamera-Geräteinformationen</span><span class="sxs-lookup"><span data-stu-id="2cb13-109">Device camera information</span></span>

### <a name="hololens-first-generation"></a><span data-ttu-id="2cb13-110">HoloLens (löschbaren)</span><span class="sxs-lookup"><span data-stu-id="2cb13-110">HoloLens (first-generation)</span></span>

* <span data-ttu-id="2cb13-111">Feste Fokus Foto / (PV) Videokamera, weiß automatischen Lastenausgleich, automatische Offenlegung und vollständigen Verarbeitung pipe</span><span class="sxs-lookup"><span data-stu-id="2cb13-111">Fixed focus photo/video (PV) camera, with auto white balance, auto exposure, and full image processing pipe</span></span>
* <span data-ttu-id="2cb13-112">Whitepaper leuchtet Datenschutz mit Internetzugriff der ganzen Welt, wenn die Kamera aktiv ist.</span><span class="sxs-lookup"><span data-stu-id="2cb13-112">White Privacy LED facing the world will illuminate whenever the camera is active</span></span>
* <span data-ttu-id="2cb13-113">Die Kamera unterstützt die folgenden Modi (alle Modi sind Seitenverhältnis 16:9) auf 30, 24, 20, 15 und 5 f/s:</span><span class="sxs-lookup"><span data-stu-id="2cb13-113">The camera supports the following modes (all modes are 16:9 aspect ratio) at 30, 24, 20, 15, and 5 fps:</span></span>

  |  <span data-ttu-id="2cb13-114">Video</span><span class="sxs-lookup"><span data-stu-id="2cb13-114">Video</span></span>  |  <span data-ttu-id="2cb13-115">Vorschau</span><span class="sxs-lookup"><span data-stu-id="2cb13-115">Preview</span></span>  |  <span data-ttu-id="2cb13-116">Weiterhin</span><span class="sxs-lookup"><span data-stu-id="2cb13-116">Still</span></span>  |  <span data-ttu-id="2cb13-117">Horizontale Sichtfeld (H-Blickfeld)</span><span class="sxs-lookup"><span data-stu-id="2cb13-117">Horizontal Field of View (H-FOV)</span></span> |  <span data-ttu-id="2cb13-118">Empfohlene Verwendung</span><span class="sxs-lookup"><span data-stu-id="2cb13-118">Suggested usage</span></span> | 
  |----------|----------|----------|----------|----------|
  |  <span data-ttu-id="2cb13-119">1280x720</span><span class="sxs-lookup"><span data-stu-id="2cb13-119">1280x720</span></span> |  <span data-ttu-id="2cb13-120">1280x720</span><span class="sxs-lookup"><span data-stu-id="2cb13-120">1280x720</span></span> |  <span data-ttu-id="2cb13-121">1280x720</span><span class="sxs-lookup"><span data-stu-id="2cb13-121">1280x720</span></span> |  <span data-ttu-id="2cb13-122">45deg</span><span class="sxs-lookup"><span data-stu-id="2cb13-122">45deg</span></span>  |  <span data-ttu-id="2cb13-123">Mithilfe von videostabilisierung (Standardmodus)</span><span class="sxs-lookup"><span data-stu-id="2cb13-123">(default mode with video stabilization)</span></span> | 
  |  <span data-ttu-id="2cb13-124">Nicht zutreffend</span><span class="sxs-lookup"><span data-stu-id="2cb13-124">N/A</span></span> |  <span data-ttu-id="2cb13-125">Nicht zutreffend</span><span class="sxs-lookup"><span data-stu-id="2cb13-125">N/A</span></span> |  <span data-ttu-id="2cb13-126">2048x1152</span><span class="sxs-lookup"><span data-stu-id="2cb13-126">2048x1152</span></span> |  <span data-ttu-id="2cb13-127">67deg</span><span class="sxs-lookup"><span data-stu-id="2cb13-127">67deg</span></span> |  <span data-ttu-id="2cb13-128">Standbild der höchsten Auflösung</span><span class="sxs-lookup"><span data-stu-id="2cb13-128">Highest resolution still image</span></span> | 
  |  <span data-ttu-id="2cb13-129">1408x792</span><span class="sxs-lookup"><span data-stu-id="2cb13-129">1408x792</span></span> |  <span data-ttu-id="2cb13-130">1408x792</span><span class="sxs-lookup"><span data-stu-id="2cb13-130">1408x792</span></span> |  <span data-ttu-id="2cb13-131">1408x792</span><span class="sxs-lookup"><span data-stu-id="2cb13-131">1408x792</span></span> |  <span data-ttu-id="2cb13-132">48deg</span><span class="sxs-lookup"><span data-stu-id="2cb13-132">48deg</span></span> |  <span data-ttu-id="2cb13-133">Overscan (Auffüllung)-Lösung vor der videostabilisierung</span><span class="sxs-lookup"><span data-stu-id="2cb13-133">Overscan (padding) resolution before video stabilization</span></span> | 
  |  <span data-ttu-id="2cb13-134">1344x756</span><span class="sxs-lookup"><span data-stu-id="2cb13-134">1344x756</span></span> |  <span data-ttu-id="2cb13-135">1344x756</span><span class="sxs-lookup"><span data-stu-id="2cb13-135">1344x756</span></span> |  <span data-ttu-id="2cb13-136">1344x756</span><span class="sxs-lookup"><span data-stu-id="2cb13-136">1344x756</span></span> |  <span data-ttu-id="2cb13-137">67deg</span><span class="sxs-lookup"><span data-stu-id="2cb13-137">67deg</span></span> |  <span data-ttu-id="2cb13-138">Große Blickfeld Videomodus mit overscan</span><span class="sxs-lookup"><span data-stu-id="2cb13-138">Large FOV video mode with overscan</span></span> | 
  |  <span data-ttu-id="2cb13-139">896x504</span><span class="sxs-lookup"><span data-stu-id="2cb13-139">896x504</span></span> |  <span data-ttu-id="2cb13-140">896x504</span><span class="sxs-lookup"><span data-stu-id="2cb13-140">896x504</span></span> |  <span data-ttu-id="2cb13-141">896x504</span><span class="sxs-lookup"><span data-stu-id="2cb13-141">896x504</span></span> |  <span data-ttu-id="2cb13-142">48deg</span><span class="sxs-lookup"><span data-stu-id="2cb13-142">48deg</span></span> |  <span data-ttu-id="2cb13-143">Energieeffiziente / -Modus mit niedriger Auflösung für Image Verarbeitungsaufgaben.</span><span class="sxs-lookup"><span data-stu-id="2cb13-143">Low power / Low resolution mode for image processing tasks</span></span> | 

### <a name="hololens-2"></a><span data-ttu-id="2cb13-144">HoloLens 2</span><span class="sxs-lookup"><span data-stu-id="2cb13-144">HoloLens 2</span></span>

* <span data-ttu-id="2cb13-145">Autofokus Foto/Video (PV) Kamera mit weißen automatischen Lastenausgleich, automatische Offenlegung und vollständigen Verarbeitung pipe</span><span class="sxs-lookup"><span data-stu-id="2cb13-145">Auto-focus photo/video (PV) camera, with auto white balance, auto exposure, and full image processing pipe</span></span>
* <span data-ttu-id="2cb13-146">Whitepaper leuchtet Datenschutz mit Internetzugriff der ganzen Welt, wenn die Kamera aktiv ist.</span><span class="sxs-lookup"><span data-stu-id="2cb13-146">White Privacy LED facing the world will illuminate whenever the camera is active</span></span>
* <span data-ttu-id="2cb13-147">Die Kamera unterstützt die folgenden Modi (alle video Modi sind Seitenverhältnis 16:9):</span><span class="sxs-lookup"><span data-stu-id="2cb13-147">The camera supports the following modes (all video modes are 16:9 aspect ratio):</span></span>

  >[!NOTE]
  ><span data-ttu-id="2cb13-148">Diese Modi unterliegen noch Änderungen, die vor der allgemeinen Verfügbarkeit von HoloLens 2.</span><span class="sxs-lookup"><span data-stu-id="2cb13-148">These modes are subject to change prior to HoloLens 2 general availability.</span></span>

  |  <span data-ttu-id="2cb13-149">Video</span><span class="sxs-lookup"><span data-stu-id="2cb13-149">Video</span></span>  |  <span data-ttu-id="2cb13-150">Vorschau</span><span class="sxs-lookup"><span data-stu-id="2cb13-150">Preview</span></span>  |  <span data-ttu-id="2cb13-151">Weiterhin</span><span class="sxs-lookup"><span data-stu-id="2cb13-151">Still</span></span>  |  <span data-ttu-id="2cb13-152">Frameraten</span><span class="sxs-lookup"><span data-stu-id="2cb13-152">Frame rates</span></span>  |  <span data-ttu-id="2cb13-153">Horizontale Sichtfeld (H-Blickfeld)</span><span class="sxs-lookup"><span data-stu-id="2cb13-153">Horizontal Field of View (H-FOV)</span></span> |  <span data-ttu-id="2cb13-154">Empfohlene Verwendung</span><span class="sxs-lookup"><span data-stu-id="2cb13-154">Suggested usage</span></span> | 
  |----------|----------|----------|----------|----------|----------|
  |  <span data-ttu-id="2cb13-155">1920x1080</span><span class="sxs-lookup"><span data-stu-id="2cb13-155">1920x1080</span></span> |  <span data-ttu-id="2cb13-156">1920x1080</span><span class="sxs-lookup"><span data-stu-id="2cb13-156">1920x1080</span></span> |  <span data-ttu-id="2cb13-157">Nicht zutreffend</span><span class="sxs-lookup"><span data-stu-id="2cb13-157">N/A</span></span> |  <span data-ttu-id="2cb13-158">30, 15 f/s</span><span class="sxs-lookup"><span data-stu-id="2cb13-158">30, 15 fps</span></span>  |  <span data-ttu-id="2cb13-159">54deg</span><span class="sxs-lookup"><span data-stu-id="2cb13-159">54deg</span></span>  |  <span data-ttu-id="2cb13-160">Mithilfe von videostabilisierung (Standardmodus)</span><span class="sxs-lookup"><span data-stu-id="2cb13-160">(default mode with video stabilization)</span></span> | 
  |  <span data-ttu-id="2cb13-161">Nicht zutreffend</span><span class="sxs-lookup"><span data-stu-id="2cb13-161">N/A</span></span> |  <span data-ttu-id="2cb13-162">Nicht zutreffend</span><span class="sxs-lookup"><span data-stu-id="2cb13-162">N/A</span></span> |  <span data-ttu-id="2cb13-163">3904X2196</span><span class="sxs-lookup"><span data-stu-id="2cb13-163">3904X2196</span></span> |  <span data-ttu-id="2cb13-164">Nicht zutreffend</span><span class="sxs-lookup"><span data-stu-id="2cb13-164">N/A</span></span>  |  <span data-ttu-id="2cb13-165">64deg</span><span class="sxs-lookup"><span data-stu-id="2cb13-165">64deg</span></span> |  <span data-ttu-id="2cb13-166">Standbild der höchsten Auflösung</span><span class="sxs-lookup"><span data-stu-id="2cb13-166">Highest resolution still image</span></span> | 
  |  <span data-ttu-id="2cb13-167">2272x1278</span><span class="sxs-lookup"><span data-stu-id="2cb13-167">2272x1278</span></span> |  <span data-ttu-id="2cb13-168">2272x1278</span><span class="sxs-lookup"><span data-stu-id="2cb13-168">2272x1278</span></span> |  <span data-ttu-id="2cb13-169">Nicht zutreffend</span><span class="sxs-lookup"><span data-stu-id="2cb13-169">N/A</span></span> |  <span data-ttu-id="2cb13-170">30, 15 f/s</span><span class="sxs-lookup"><span data-stu-id="2cb13-170">30, 15 fps</span></span>  |  <span data-ttu-id="2cb13-171">64deg</span><span class="sxs-lookup"><span data-stu-id="2cb13-171">64deg</span></span> |  <span data-ttu-id="2cb13-172">Overscan (Auffüllung)-Lösung vor der videostabilisierung</span><span class="sxs-lookup"><span data-stu-id="2cb13-172">Overscan (padding) resolution before video stabilization</span></span> | 
  |  <span data-ttu-id="2cb13-173">1952x1100</span><span class="sxs-lookup"><span data-stu-id="2cb13-173">1952x1100</span></span> |  <span data-ttu-id="2cb13-174">1952x1100</span><span class="sxs-lookup"><span data-stu-id="2cb13-174">1952x1100</span></span> |  <span data-ttu-id="2cb13-175">1952x1100</span><span class="sxs-lookup"><span data-stu-id="2cb13-175">1952x1100</span></span>  |  <span data-ttu-id="2cb13-176">30, 15 f/s</span><span class="sxs-lookup"><span data-stu-id="2cb13-176">30, 15 fps</span></span>  |  <span data-ttu-id="2cb13-177">64deg</span><span class="sxs-lookup"><span data-stu-id="2cb13-177">64deg</span></span> |  <span data-ttu-id="2cb13-178">Hoher Qualität</span><span class="sxs-lookup"><span data-stu-id="2cb13-178">High-quality streaming</span></span> | 
  |  <span data-ttu-id="2cb13-179">1280x720</span><span class="sxs-lookup"><span data-stu-id="2cb13-179">1280x720</span></span> |  <span data-ttu-id="2cb13-180">1280x720</span><span class="sxs-lookup"><span data-stu-id="2cb13-180">1280x720</span></span> |  <span data-ttu-id="2cb13-181">Nicht zutreffend</span><span class="sxs-lookup"><span data-stu-id="2cb13-181">N/A</span></span> |  <span data-ttu-id="2cb13-182">30, 15, 5 f/s</span><span class="sxs-lookup"><span data-stu-id="2cb13-182">30, 15, 5 fps</span></span>  |  <span data-ttu-id="2cb13-183">64deg</span><span class="sxs-lookup"><span data-stu-id="2cb13-183">64deg</span></span> |  <span data-ttu-id="2cb13-184">Niedrige Power bzw. Beschlusses Modus für das streaming und Aufgaben der bildverarbeitung</span><span class="sxs-lookup"><span data-stu-id="2cb13-184">Low power/resolution mode for streaming and image processing tasks</span></span> | 

## <a name="locating-the-device-camera-in-the-world"></a><span data-ttu-id="2cb13-185">Suchen die Kamera des Geräts in der ganzen Welt</span><span class="sxs-lookup"><span data-stu-id="2cb13-185">Locating the Device Camera in the World</span></span>

<span data-ttu-id="2cb13-186">Wenn HoloLens Fotos und Videos verweist, enthalten die aufgezeichneten Frames die Position der Kamera in der ganzen Welt als auch die perspektivische Projektion der Kamera.</span><span class="sxs-lookup"><span data-stu-id="2cb13-186">When HoloLens takes photos and videos, the captured frames include the location of the camera in the world, as well as the perspective projection of the camera.</span></span> <span data-ttu-id="2cb13-187">Dadurch können Anwendungen, Grund, über die Position der Kamera in der realen Welt ergänzte imaging-Szenarien.</span><span class="sxs-lookup"><span data-stu-id="2cb13-187">This allows applications to reason about the position of the camera in the real world for augmented imaging scenarios.</span></span> <span data-ttu-id="2cb13-188">Entwickler können ihre eigenen Szenarien, die mit ihren bevorzugten bildverarbeitung oder einen benutzerdefinierten Computer Vision Bibliotheken kreativ zurücksetzen.</span><span class="sxs-lookup"><span data-stu-id="2cb13-188">Developers can creatively roll their own scenarios using their favorite image processing or custom computer vision libraries.</span></span>

<span data-ttu-id="2cb13-189">"Kamera" an anderer Stelle im HoloLens Dokumentation bezieht sich möglicherweise auf die "virtuelle Spiel Kamera" (die Frustums der app rendert).</span><span class="sxs-lookup"><span data-stu-id="2cb13-189">"Camera" elsewhere in HoloLens documentation may refer to the "virtual game camera" (the frustum the app renders to).</span></span> <span data-ttu-id="2cb13-190">Es sei denn, die andernfalls gekennzeichnet ist, bezieht sich "Kamera" auf dieser Seite auf der realen Welt RGB-Farbe Kamera ein.</span><span class="sxs-lookup"><span data-stu-id="2cb13-190">Unless denoted otherwise, "camera" on this page refers to the real-world RGB color camera.</span></span>

<span data-ttu-id="2cb13-191">Die Details auf dieser Seite Abdeckung [Media Foundation Attribute](https://msdn.microsoft.com/library/windows/desktop/mt740395(v=vs.85).aspx), es gibt jedoch auch APIs, um die Kamera systeminternen Funktionen mit pull [WinRT-APIs](https://msdn.microsoft.com/library/windows/apps/windows.media.devices.core.cameraintrinsics).</span><span class="sxs-lookup"><span data-stu-id="2cb13-191">The details on this page cover [Media Foundation Attributes](https://msdn.microsoft.com/library/windows/desktop/mt740395(v=vs.85).aspx), however there are also APIs to pull camera intrinsics using [WinRT APIs](https://msdn.microsoft.com/library/windows/apps/windows.media.devices.core.cameraintrinsics).</span></span>  

### <a name="images-with-coordinate-systems"></a><span data-ttu-id="2cb13-192">Images mit Koordinatensysteme</span><span class="sxs-lookup"><span data-stu-id="2cb13-192">Images with Coordinate Systems</span></span>

<span data-ttu-id="2cb13-193">Jedes Bild-Frame (ob Fotos oder Videos) enthält, sowie zwei wichtige Transformationen in einem Koordinatensystem.</span><span class="sxs-lookup"><span data-stu-id="2cb13-193">Each image frame (whether photo or video) includes a coordinate system, as well as two important transforms.</span></span> <span data-ttu-id="2cb13-194">Die "View" wandeln Sie Zuordnungen aus der angegebenen Koordinatensystem bis zur Kamera und der "Projection" wird von der Kamera Pixel im Bild.</span><span class="sxs-lookup"><span data-stu-id="2cb13-194">The "view" transform maps from the provided coordinate system to the camera, and the "projection" maps from the camera to pixels in the image.</span></span> <span data-ttu-id="2cb13-195">Zusammen definieren diese Transformationen für jedes Pixel ein Strahl im 3D-Raum, die den Pfad repräsentiert, die von der Photonen, die das Pixel erzeugt.</span><span class="sxs-lookup"><span data-stu-id="2cb13-195">Together, these transforms define for each pixel a ray in 3D space representing the path taken by the photons that produced the pixel.</span></span> <span data-ttu-id="2cb13-196">Diese Strahlung können auf andere Inhalte in der app verknüpft werden, durch die Transformation von Koordinatensystem des Frames abrufen, auf einige andere Koordinatensystem (z. B. aus einem [feststehende Verweisrahmen](coordinate-systems.md#stationary-frame-of-reference)).</span><span class="sxs-lookup"><span data-stu-id="2cb13-196">These rays can be related to other content in the app by obtaining the transform from the frame's coordinate system to some other coordinate system (e.g. from a [stationary frame of reference](coordinate-systems.md#stationary-frame-of-reference)).</span></span> <span data-ttu-id="2cb13-197">Zusammenfassend lässt sich sagen, bietet der einzelnen Bild-Frame Folgendes:</span><span class="sxs-lookup"><span data-stu-id="2cb13-197">To summarize, each image frame provides the following:</span></span>
* <span data-ttu-id="2cb13-198">Die Pixeldaten (im Format der RGB-/ NV12/JPEG/usw.)</span><span class="sxs-lookup"><span data-stu-id="2cb13-198">Pixel Data (in RGB/NV12/JPEG/etc. format)</span></span>
* <span data-ttu-id="2cb13-199">3 Teile der Metadaten (gespeichert als [IMFAttributes](https://msdn.microsoft.com/library/windows/desktop/ms704598(v=vs.85).aspx)), die jeden Frame "auffindbaren" machen:</span><span class="sxs-lookup"><span data-stu-id="2cb13-199">3 pieces of metadata (stored as [IMFAttributes](https://msdn.microsoft.com/library/windows/desktop/ms704598(v=vs.85).aspx)) that make each frame "locatable":</span></span>

|  <span data-ttu-id="2cb13-200">Attributname</span><span class="sxs-lookup"><span data-stu-id="2cb13-200">Attribute name</span></span>  |  <span data-ttu-id="2cb13-201">Typ</span><span class="sxs-lookup"><span data-stu-id="2cb13-201">Type</span></span>  |  <span data-ttu-id="2cb13-202">GUID</span><span class="sxs-lookup"><span data-stu-id="2cb13-202">GUID</span></span>  |  <span data-ttu-id="2cb13-203">Beschreibung</span><span class="sxs-lookup"><span data-stu-id="2cb13-203">Description</span></span> | 
|----------|----------|----------|----------|
|  <span data-ttu-id="2cb13-204">MFSampleExtension_Spatial_CameraCoordinateSystem</span><span class="sxs-lookup"><span data-stu-id="2cb13-204">MFSampleExtension_Spatial_CameraCoordinateSystem</span></span>  |  <span data-ttu-id="2cb13-205">IUnknown ([SpatialCoordinateSystem](https://msdn.microsoft.com/library/windows/apps/windows.perception.spatial.spatialcoordinatesystem.aspx))</span><span class="sxs-lookup"><span data-stu-id="2cb13-205">IUnknown ([SpatialCoordinateSystem](https://msdn.microsoft.com/library/windows/apps/windows.perception.spatial.spatialcoordinatesystem.aspx))</span></span>  |  <span data-ttu-id="2cb13-206">{9D13C82F-2199-4E67-91CD-D1A4181F2534}</span><span class="sxs-lookup"><span data-stu-id="2cb13-206">{9D13C82F-2199-4E67-91CD-D1A4181F2534}</span></span>  |  <span data-ttu-id="2cb13-207">Speichert die [Koordinatensystem](coordinate-systems-in-directx.md) des aufgezeichneten Frames</span><span class="sxs-lookup"><span data-stu-id="2cb13-207">Stores the [coordinate system](coordinate-systems-in-directx.md) of the captured frame</span></span> | 
|  <span data-ttu-id="2cb13-208">MFSampleExtension_Spatial_CameraViewTransform</span><span class="sxs-lookup"><span data-stu-id="2cb13-208">MFSampleExtension_Spatial_CameraViewTransform</span></span>  |  <span data-ttu-id="2cb13-209">Blob ([Matrix4x4](https://msdn.microsoft.com/library/windows/apps/windows.foundation.numerics.matrix4x4.aspx))</span><span class="sxs-lookup"><span data-stu-id="2cb13-209">Blob ([Matrix4x4](https://msdn.microsoft.com/library/windows/apps/windows.foundation.numerics.matrix4x4.aspx))</span></span>  |  <span data-ttu-id="2cb13-210">{4E251FA4-830F-4770-859A-4B8D99AA809B}</span><span class="sxs-lookup"><span data-stu-id="2cb13-210">{4E251FA4-830F-4770-859A-4B8D99AA809B}</span></span>  |  <span data-ttu-id="2cb13-211">Speichert der Kamera systemexterne Transformation im Koordinatensystem</span><span class="sxs-lookup"><span data-stu-id="2cb13-211">Stores the camera's extrinsic transform in the coordinate system</span></span> | 
|  <span data-ttu-id="2cb13-212">MFSampleExtension_Spatial_CameraProjectionTransform</span><span class="sxs-lookup"><span data-stu-id="2cb13-212">MFSampleExtension_Spatial_CameraProjectionTransform</span></span>  |  <span data-ttu-id="2cb13-213">Blob ([Matrix4x4](https://msdn.microsoft.com/library/windows/apps/windows.foundation.numerics.matrix4x4.aspx))</span><span class="sxs-lookup"><span data-stu-id="2cb13-213">Blob ([Matrix4x4](https://msdn.microsoft.com/library/windows/apps/windows.foundation.numerics.matrix4x4.aspx))</span></span>  |  <span data-ttu-id="2cb13-214">{47F9FCB5-2A02-4F26-A477-792FDF95886A}</span><span class="sxs-lookup"><span data-stu-id="2cb13-214">{47F9FCB5-2A02-4F26-A477-792FDF95886A}</span></span>  |  <span data-ttu-id="2cb13-215">Speichert die Projektion Transformation der Kamera</span><span class="sxs-lookup"><span data-stu-id="2cb13-215">Stores the camera's projection transform</span></span> | 

<span data-ttu-id="2cb13-216">Die Transformation für die Projektion stellt die inhärenten Eigenschaften (als zentraler Länge Mittelpunkt der Projektion, neigen) den Fokus auf ein Image-Ebene, die von-1 bis + 1, in der X- und Y-Achse erweitert zugeordnet.</span><span class="sxs-lookup"><span data-stu-id="2cb13-216">The projection transform represents the intrinsic properties (focal length, center of projection, skew) of the lens mapped onto an image plane that extends from -1 to +1 in both the X and Y axis.</span></span>

```
Matrix4x4 format          Terms
   m11 m12 m13 m14      fx    0   0   0
   m21 m22 m23 m24     skew  fy   0   0
   m31 m32 m33 m34      cx   cy   A  -1
   m41 m42 m43 m44       0    0   B   0
```

<span data-ttu-id="2cb13-217">Verschiedene Anwendungen müssen unterschiedliche Koordinatensysteme.</span><span class="sxs-lookup"><span data-stu-id="2cb13-217">Different applications will have different coordinate systems.</span></span> <span data-ttu-id="2cb13-218">Hier ist eine Übersicht über die Vorgehensweise zum Suchen eines Pixels Kamera für eine einzelne Anwendung:</span><span class="sxs-lookup"><span data-stu-id="2cb13-218">Here's an overview of the flow to locate a camera pixel for a single application:</span></span>

![Transformationen angewendet werden, um die Kamera Koordinatensysteme](images/pvcameratransform5-500px.png)

### <a name="camera-to-application-specified-coordinate-system"></a><span data-ttu-id="2cb13-220">Kamera Koordinatensystem anwendungsspezifische</span><span class="sxs-lookup"><span data-stu-id="2cb13-220">Camera to Application-specified Coordinate System</span></span>

<span data-ttu-id="2cb13-221">Um auf Ihre Anwendung/globales Koordinatensystem aus dem 'CameraView' und "CameraCoordinateSystem" zu wechseln, benötigen Sie Folgendes:</span><span class="sxs-lookup"><span data-stu-id="2cb13-221">To go from the 'CameraView' and 'CameraCoordinateSystem' to your application/world coordinate system, you'll need the following:</span></span>

<span data-ttu-id="2cb13-222">[Gebietsschemabezogene Kamera in Unity](locatable-camera-in-unity.md): CameraToWorldMatrix wird automatisch von PhotoCaptureFrame-Klasse bereitgestellt, (sodass Sie nicht über die Transformationen CameraCoordinateSystem machen müssen).</span><span class="sxs-lookup"><span data-stu-id="2cb13-222">[Locatable camera in Unity](locatable-camera-in-unity.md): CameraToWorldMatrix is automatically provided by PhotoCaptureFrame class(so you don't need to worry about the CameraCoordinateSystem transforms).</span></span>

<span data-ttu-id="2cb13-223">[Gebietsschemabezogene Kamera in DirectX](locatable-camera-in-directx.md): Zeigt die recht einfache Möglichkeit zum Abfragen von der Transformation zwischen Koordinatensystem der Kamera und Ihrer eigenen Anwendung Coordinate system(s).</span><span class="sxs-lookup"><span data-stu-id="2cb13-223">[Locatable camera in DirectX](locatable-camera-in-directx.md): Shows the fairly straightforward way to query for the transform between the camera's coordinate system and your own application coordinate system(s).</span></span>

### <a name="application-specified-coordinate-system-to-pixel-coordinates"></a><span data-ttu-id="2cb13-224">Koordinatensystem in Pixelkoordinaten anwendungsspezifische</span><span class="sxs-lookup"><span data-stu-id="2cb13-224">Application-specified Coordinate System to Pixel Coordinates</span></span>

<span data-ttu-id="2cb13-225">Angenommen, Sie verwenden möchten, suchen oder an einer bestimmten 3d Position auf ein kamerabild Zeichnen:</span><span class="sxs-lookup"><span data-stu-id="2cb13-225">Let's say you wanted to find or draw at a specific 3d location on a camera image:</span></span>

<span data-ttu-id="2cb13-226">Die Ansichts- und Projektionstransformation Transformationen, während die beiden Matrizen 4 x 4 müssen etwas anders verwendet werden.</span><span class="sxs-lookup"><span data-stu-id="2cb13-226">The view and projection transforms, while both 4x4 matrices, need to be utilized slightly differently.</span></span> <span data-ttu-id="2cb13-227">Nämlich nach dem Ausführen der Projektion an, eine würde "normalisieren, indem Sie w', dieser zusätzliche Schritt in der Projektion simuliert, wie mehrere 3d Speicherorte als 2d denselben Speicherort auf einem Bildschirm ergeben können (d. h. wird alles an einem bestimmten Strahl auf demselben Pixel angezeigt).</span><span class="sxs-lookup"><span data-stu-id="2cb13-227">Namely after performing the Projection, one would 'normalize by w', this extra step in the projection simulates how multiple different 3d locations can end up as the same 2d location on a screen (i.e. anything along a certain ray will show up on the same pixel).</span></span> <span data-ttu-id="2cb13-228">Daher wichtige Punkte (im shadercode):</span><span class="sxs-lookup"><span data-stu-id="2cb13-228">So key points (in shader code):</span></span>

```
// Usual 3d math:
 float4x4 WorldToCamera = inverse( CameraToWorld );
 float4 CameraSpacePos = mul( WorldToCamera, float4( WorldSpacePos.xyz, 1 ) ); // use 1 as the W component
 // Projection math:
 float4 ImagePosUnnormalized = mul( CameraProjection, float4( CameraSpacePos.xyz, 1 ) ); // use 1 as the W component
 float2 ImagePosProjected = ImagePosUnnormalized.xy / ImagePosUnnormalized.w; // normalize by W, gives -1 to 1 space
 float2 ImagePosZeroToOne = ( ImagePosProjected * 0.5 ) + float2( 0.5, 0.5 ); // good for GPU textures
 int2 PixelPos = int2( ImagePosZeroToOne.x * ImageWidth, ( 1 - ImagePosZeroToOne.y ) * ImageHeight ); // good for CPU textures
```

### <a name="pixel-to-application-specified-coordinate-system"></a><span data-ttu-id="2cb13-229">Pixel, um das Koordinatensystem anwendungsspezifische</span><span class="sxs-lookup"><span data-stu-id="2cb13-229">Pixel to Application-specified Coordinate System</span></span>

<span data-ttu-id="2cb13-230">Vom Pixel ist globale Koordinaten etwas komplizierter:</span><span class="sxs-lookup"><span data-stu-id="2cb13-230">Going from pixel to world coordinates is a little trickier:</span></span>

```
float2 ImagePosZeroToOne = float2( PixelPos.x / ImageWidth, 1.0 - (PixelPos.y / ImageHeight ) );
 float2 ImagePosProjected = ( ( ImagePosZeroToOne * 2.0 ) - float2(1,1) ); // -1 to 1 space
 float3 CameraSpacePos = UnProjectVector( Projection, float3( ImagePosProjected, 1) );
 float3 WorldSpaceRayPoint1 = mul( CameraToWorld, float4(0,0,0,1) ); // camera location in world space
 float3 WorldSpaceRayPoint2 = mul( CameraToWorld, CameraSpacePos ); // ray point in world space
```

<span data-ttu-id="2cb13-231">Wird definiert, in denen UnProject als:</span><span class="sxs-lookup"><span data-stu-id="2cb13-231">Where we define UnProject as:</span></span>

```
public static Vector3 UnProjectVector(Matrix4x4 proj, Vector3 to)
 {
   Vector3 from = new Vector3(0, 0, 0);
   var axsX = proj.GetRow(0);
   var axsY = proj.GetRow(1);
   var axsZ = proj.GetRow(2);
   from.z = to.z / axsZ.z;
   from.y = (to.y - (from.z * axsY.z)) / axsY.y;
   from.x = (to.x - (from.z * axsX.z)) / axsX.x;
   return from;
 }
```

<span data-ttu-id="2cb13-232">Um die tatsächlichen World-Position eines Punkts zu suchen, Sie benötigen entweder: zwei Welt Strahlen und suchen Sie nach ihrer Schnittmenge oder eine bekannte Größe der Punkte.</span><span class="sxs-lookup"><span data-stu-id="2cb13-232">To find the actual world location of a point, you'll need either: two world rays and find their intersection, or a known size of the points.</span></span>

### <a name="distortion-error"></a><span data-ttu-id="2cb13-233">Verzerrung-Fehler</span><span class="sxs-lookup"><span data-stu-id="2cb13-233">Distortion Error</span></span>

<span data-ttu-id="2cb13-234">Auf HoloLens sind die Videos und weiterhin Image Streams unverfälschten in das System die Image-Verarbeitungspipeline, bevor die Frames der Anwendung zur Verfügung gestellt werden (die Vorschau des Datenstroms enthält die ursprünglichen verzerrt Frames).</span><span class="sxs-lookup"><span data-stu-id="2cb13-234">On HoloLens, the video and still image streams are undistorted in the system's image processing pipeline before the frames are made available to the application (the preview stream contains the original distorted frames).</span></span> <span data-ttu-id="2cb13-235">Da nur die Projektionsmatrix verfügbar gemacht werden, Anwendungen müssen davon ausgehen Bild-Frames stellen eine perfekte Pinhole Kamera, die Undistortion funktionieren jedoch in der Image-Prozessor möglicherweise einen Fehler von bis zu 10 Pixel weiterhin lassen, wenn die Projektionsmatrix in Verwendung die Frame-Metadaten.</span><span class="sxs-lookup"><span data-stu-id="2cb13-235">Because only the projection matrix is made available, applications must assume image frames represent a perfect pinhole camera, however the undistortion function in the image processor may still leave an error of up to 10 pixels when using the projection matrix in the frame metadata.</span></span> <span data-ttu-id="2cb13-236">In vielen Fällen – dieser Fehler wird spielt keine Rolle, aber wenn Sie Hologramme, die reale Welt Poster/Marker, z. B. ausrichten sind und Sie feststellen, dass eine < 10px offset (etwa 11mm für Hologramme positioniert-Zähler sofort 2) dieser Verzerrung Fehler könnte die Ursache sein.</span><span class="sxs-lookup"><span data-stu-id="2cb13-236">In many use cases, this error will not matter, but if you are aligning holograms to real world posters/markers, for example, and you notice a <10px offset (roughly 11mm for holograms positioned 2 meters away) this distortion error could be the cause.</span></span>

## <a name="locatable-camera-usage-scenarios"></a><span data-ttu-id="2cb13-237">Szenarien für die Verwendung gebietsschemabezogene Kamera</span><span class="sxs-lookup"><span data-stu-id="2cb13-237">Locatable Camera Usage Scenarios</span></span>

### <a name="show-a-photo-or-video-in-the-world-where-it-was-captured"></a><span data-ttu-id="2cb13-238">Anzeigen eines Fotos oder Videos in der ganzen Welt, in dem er erfasst wurde</span><span class="sxs-lookup"><span data-stu-id="2cb13-238">Show a photo or video in the world where it was captured</span></span>

<span data-ttu-id="2cb13-239">Die Kamera des Geräts Frames verfügen über eine "Kamera, World"-Transformation, die verwendet werden kann, um anzuzeigen, genau, in dem das Gerät wurde bei der das Image erstellt wurde.</span><span class="sxs-lookup"><span data-stu-id="2cb13-239">The Device Camera frames come with a "Camera To World" transform, that can be used to show exactly where the device was when the image was taken.</span></span> <span data-ttu-id="2cb13-240">Zum Beispiel könnten Sie positionieren ein kleines holographic Symbol an dieser Stelle (CameraToWorld.MultiplyPoint(Vector3.zero)) und sogar zeichnen einen kleinen Pfeil in die Richtung von die Kamera (CameraToWorld.MultiplyVector(Vector3.forward)). konfrontiert wurde</span><span class="sxs-lookup"><span data-stu-id="2cb13-240">For example you could position a small holographic icon at this location (CameraToWorld.MultiplyPoint(Vector3.zero)) and even draw a little arrow in the direction that the camera was facing (CameraToWorld.MultiplyVector(Vector3.forward)).</span></span>

### <a name="painting-the-world-using-a-camera-shader"></a><span data-ttu-id="2cb13-241">Zeichnen der Welt über eine Kamera-shader</span><span class="sxs-lookup"><span data-stu-id="2cb13-241">Painting the world using a camera shader</span></span>

<span data-ttu-id="2cb13-242">In diesem Abschnitt erstellen wir ein Material "Shader", Farben, die abhängig von die ganzen Welt, in denen sie in der Ansicht für eine Kamera des Geräts angezeigt wurde.</span><span class="sxs-lookup"><span data-stu-id="2cb13-242">In this section we'll create a material 'shader' that colors the world based on where it showed up in a device camera's view.</span></span> <span data-ttu-id="2cb13-243">Wir lassen jetzt effektiv ist, dass jeder Vertex, deren Speicherort relativ zur Kamera herausfinden wird, und klicken Sie dann jedes Pixel, die die Projektionsmatrix Abbildung verwendet werden Out welches Texel image zugeordnet ist.</span><span class="sxs-lookup"><span data-stu-id="2cb13-243">Effectively what we'll do is that every vertex will figure out its location relative to the camera, and then every pixel will utilize the 'projection matrix' to figure out which image texel it is associated with.</span></span> <span data-ttu-id="2cb13-244">Schließlich und optional werden wir die Ecken des Bilds, das es mehr als ein Traum-ähnliche Arbeitsspeicher angezeigt wird eingeblendet:</span><span class="sxs-lookup"><span data-stu-id="2cb13-244">Lastly, and optionally, we'll fade out the corners of the image to make it appear more as a dream-like memory:</span></span>

```
// In the vertex shader:
 float4 worldSpace = mul( ObjectToWorld, float4( vertexPos.xyz, 1));
 float4 cameraSpace = mul( CameraWorldToLocal, float4(worldSpace.xyz, 1));

 // In the pixel shader:
 float4 unprojectedTex = mul( CameraProjection, float4( cameraSpace .xyz, 1));
 float2 projectedTex = (unprojectedTex.xy / unprojectedTex.w);
 float2 unitTexcoord = ((projectedTex * 0.5) + float4(0.5, 0.5, 0, 0));
 float4 cameraTextureColor = tex2D(_CameraTex, unitTexcoord);
 // Fade out edges for better look:
 float pctInView = saturate((1.0 - length(projectedTex.xy)) * 3.0);
 float4 finalColor = float4( cameraTextureColor.rgb, pctInView );
```

### <a name="tag--pattern--poster--object-tracking"></a><span data-ttu-id="2cb13-245">Tag / Pattern / Poster / Objektverfolgung</span><span class="sxs-lookup"><span data-stu-id="2cb13-245">Tag / Pattern / Poster / Object Tracking</span></span>

<span data-ttu-id="2cb13-246">Viele mixed Reality-Anwendungen verwenden eine erkennbare Bild oder ein visual Muster zum Erstellen eines nachverfolgbare Punkts im Bereich.</span><span class="sxs-lookup"><span data-stu-id="2cb13-246">Many mixed reality applications use a recognizable image or visual pattern to create a trackable point in space.</span></span> <span data-ttu-id="2cb13-247">Dies wird dann zum Rendern verwendet Objekte relativ zum, die zeigen, oder erstellen Sie einen bekannten Speicherort.</span><span class="sxs-lookup"><span data-stu-id="2cb13-247">This is then used to render objects relative to that point or create a known location.</span></span> <span data-ttu-id="2cb13-248">Einige Verwendungsmöglichkeiten für HoloLens gehören, suchen, die ein Objekt der realen Welt mit Fiducials (z. B. eine TV-Monitor mit einem QR-Code) gekennzeichnet, platzieren Hologramme über Fiducials und visuell Kopplung mit nicht-HoloLens-Geräten wie Tablets, die für die Kommunikation mit HoloLens über eingerichtet haben Wi-Fi.</span><span class="sxs-lookup"><span data-stu-id="2cb13-248">Some uses for HoloLens include finding a real world object tagged with fiducials (e.g. a TV monitor with a QR code), placing holograms over fiducials, and visually pairing with non-HoloLens devices like tablets that have been setup to communicate with HoloLens via Wi-Fi.</span></span>

<span data-ttu-id="2cb13-249">Um ein visual-Muster erkennen, und legen Sie das Objekt im Raum, Anwendungen, benötigen Sie Folgendes:</span><span class="sxs-lookup"><span data-stu-id="2cb13-249">To recognize a visual pattern, and then place that object in the applications world space, you'll need a few things:</span></span>
1. <span data-ttu-id="2cb13-250">Ein Bild Muster Anerkennung Toolkit, z. B. QR-Code "," AR-Tags "," Gesicht Finder "," Kreis-nachverfolgungsmodule, OCR usw.</span><span class="sxs-lookup"><span data-stu-id="2cb13-250">An image pattern recognition toolkit, such as QR code, AR tags, face finder, circle trackers, OCR etc.</span></span>
2. <span data-ttu-id="2cb13-251">Bild-Frames zur Laufzeit sammeln und diese an die Anerkennung Ebene übergeben</span><span class="sxs-lookup"><span data-stu-id="2cb13-251">Collect image frames at runtime, and pass them to the recognition layer</span></span>
3. <span data-ttu-id="2cb13-252">Unproject auftraten Bild wieder in die Welt Positionen und wahrscheinlich Welt Strahlung an.</span><span class="sxs-lookup"><span data-stu-id="2cb13-252">Unproject their image locations back into world positions, or likely world rays.</span></span> <span data-ttu-id="2cb13-253">Unter</span><span class="sxs-lookup"><span data-stu-id="2cb13-253">See</span></span>
4. <span data-ttu-id="2cb13-254">Positionieren Sie Ihre virtuellen Modelle über diese Standorte weltweit</span><span class="sxs-lookup"><span data-stu-id="2cb13-254">Position your virtual models over these world locations</span></span>

<span data-ttu-id="2cb13-255">Einige wichtige Image Verarbeitung Links:</span><span class="sxs-lookup"><span data-stu-id="2cb13-255">Some important image processing links:</span></span>
* [<span data-ttu-id="2cb13-256">OpenCV</span><span class="sxs-lookup"><span data-stu-id="2cb13-256">OpenCV</span></span>](http://opencv.org/)
* [<span data-ttu-id="2cb13-257">Qr-Tags</span><span class="sxs-lookup"><span data-stu-id="2cb13-257">QR Tags</span></span>](https://en.wikipedia.org/wiki/QR_code)
* [<span data-ttu-id="2cb13-258">FaceSDK</span><span class="sxs-lookup"><span data-stu-id="2cb13-258">FaceSDK</span></span>](http://research.microsoft.com/projects/facesdk/)
* [<span data-ttu-id="2cb13-259">Microsoft Translator</span><span class="sxs-lookup"><span data-stu-id="2cb13-259">Microsoft Translator</span></span>](https://www.microsoft.com/translator/business)

<span data-ttu-id="2cb13-260">Halten eine interaktive Anwendung Framerate ist wichtig, insbesondere beim Umgang mit Algorithmen für die Erkennung langer Image.</span><span class="sxs-lookup"><span data-stu-id="2cb13-260">Keeping an interactive application frame-rate is critical, especially when dealing with long-running image recognition algorithms.</span></span> <span data-ttu-id="2cb13-261">Aus diesem Grund verwenden wir im Allgemeinen im folgenden Format ein:</span><span class="sxs-lookup"><span data-stu-id="2cb13-261">For this reason we commonly use the following pattern:</span></span>
1. <span data-ttu-id="2cb13-262">Hauptthread: verwaltet das Kameraobjekt</span><span class="sxs-lookup"><span data-stu-id="2cb13-262">Main Thread: manages the camera object</span></span>
2. <span data-ttu-id="2cb13-263">Hauptthread: neue Anforderungen-Frames (Async)</span><span class="sxs-lookup"><span data-stu-id="2cb13-263">Main Thread: requests new frames (async)</span></span>
3. <span data-ttu-id="2cb13-264">Hauptthread: Übergeben von neuen Frames zum Nachverfolgen von Threads</span><span class="sxs-lookup"><span data-stu-id="2cb13-264">Main Thread: pass new frames to tracking thread</span></span>
4. <span data-ttu-id="2cb13-265">Überwachung-Thread: verarbeitet, Bild, um die wichtigsten Punkte zu sammeln</span><span class="sxs-lookup"><span data-stu-id="2cb13-265">Tracking Thread: processes image to collect key points</span></span>
5. <span data-ttu-id="2cb13-266">Hauptthread: verschiebt virtuelle Modell entsprechend finden Sie wichtige Punkte</span><span class="sxs-lookup"><span data-stu-id="2cb13-266">Main Thread: moves virtual model to match found key points</span></span>
6. <span data-ttu-id="2cb13-267">Hauptthread: Wiederholen Sie Schritt 2</span><span class="sxs-lookup"><span data-stu-id="2cb13-267">Main Thread: repeat from step 2</span></span>

<span data-ttu-id="2cb13-268">Einige Images-Marker-Systeme bieten nur einen einzelnen Pixels-Speicherort (andere bieten die vollständigen Transformation in diesem Fall in diesem Abschnitt nicht benötigt wird), das ist gleichbedeutend mit einem Strahl von möglichen Speicherorten.</span><span class="sxs-lookup"><span data-stu-id="2cb13-268">Some image marker systems only provide a single pixel location (others provide the full transform in which case this section will not be needed), which equates to a ray of possible locations.</span></span> <span data-ttu-id="2cb13-269">Rufen Sie an zentraler Stelle 3d können dann mehrere Strahlung nutzen und finden das endgültige Ergebnis, indem deren ungefähre Schnittmenge.</span><span class="sxs-lookup"><span data-stu-id="2cb13-269">To get to a single 3d location we can then leverage multiple rays and find the final result by their approximate intersection.</span></span> <span data-ttu-id="2cb13-270">Zu diesem Zweck müssen Sie Folgendes ausführen:</span><span class="sxs-lookup"><span data-stu-id="2cb13-270">To do this you'll need to:</span></span>
1. <span data-ttu-id="2cb13-271">Abrufen einer Schleife, die jetzt mehrere Kamera Abbilder erfassen</span><span class="sxs-lookup"><span data-stu-id="2cb13-271">Get a loop going collecting multiple camera images</span></span>
2. <span data-ttu-id="2cb13-272">Suchen der [verknüpften zeigt für Feature](#pixel-to-application-specified-coordinate-system), und deren Strahlung World</span><span class="sxs-lookup"><span data-stu-id="2cb13-272">Find the [associated feature points](#pixel-to-application-specified-coordinate-system), and their world rays</span></span>
3. <span data-ttu-id="2cb13-273">Wenn Sie ein Wörterbuch von Features, mit mehreren Welt Strahlung, haben können Sie den folgenden Code, um für die Schnittmenge dieser Strahlung zu lösen:</span><span class="sxs-lookup"><span data-stu-id="2cb13-273">When you have a dictionary of features, each with multiple world rays, you can use the following code to solve for the intersection of those rays:</span></span>

```
public static Vector3 ClosestPointBetweenRays(
   Vector3 point1, Vector3 normalizedDirection1,
   Vector3 point2, Vector3 normalizedDirection2) {
   float directionProjection = Vector3.Dot(normalizedDirection1, normalizedDirection2);
   if (directionProjection == 1) {
     return point1; // parallel lines
   }
   float projection1 = Vector3.Dot(point2 - point1, normalizedDirection1);
   float projection2 = Vector3.Dot(point2 - point1, normalizedDirection2);
   float distanceAlongLine1 = (projection1 - directionProjection * projection2) / (1 - directionProjection * directionProjection);
   float distanceAlongLine2 = (projection2 - directionProjection * projection1) / (directionProjection * directionProjection - 1);
   Vector3 pointOnLine1 = point1 + distanceAlongLine1 * normalizedDirection1;
   Vector3 pointOnLine2 = point2 + distanceAlongLine2 * normalizedDirection2;
   return Vector3.Lerp(pointOnLine2, pointOnLine1, 0.5f);
 }
```

<span data-ttu-id="2cb13-274">Wenn mindestens zwei überwachte Tag-Standorten, können Sie eine modelled Szene entsprechend das aktuellen Benutzer-Szenario positionieren.</span><span class="sxs-lookup"><span data-stu-id="2cb13-274">Given two or more tracked tag locations, you can position a modelled scene to fit the users current scenario.</span></span> <span data-ttu-id="2cb13-275">Wenn Sie Schwerkraft wird davon ausgegangen, müssen Sie drei Tags stellen dafür.</span><span class="sxs-lookup"><span data-stu-id="2cb13-275">If you can't assume gravity, then you'll need three tag locations.</span></span> <span data-ttu-id="2cb13-276">In vielen Fällen, die wir verwenden ein einfaches Farbschema, in dem weiße Kugeln in Echtzeit darstellen, nachverfolgt Tag-Standorte, und blaue Kugeln modelliert Tag-Orte darstellen, dadurch kann der Benutzer an der die Ausrichtung Qualität visuell zu messen.</span><span class="sxs-lookup"><span data-stu-id="2cb13-276">In many cases we use a simple color scheme where white spheres represent real-time tracked tag locations, and blue spheres represent modelled tag locations, this allows the user to visually gauge the alignment quality.</span></span> <span data-ttu-id="2cb13-277">Es wird davon ausgegangen folgende Setup alle unsere Anwendungen:</span><span class="sxs-lookup"><span data-stu-id="2cb13-277">We assume the following setup in all our applications:</span></span>
* <span data-ttu-id="2cb13-278">Mindestens zwei modelliert Tag-Standorten</span><span class="sxs-lookup"><span data-stu-id="2cb13-278">Two or more modelled tag locations</span></span>
* <span data-ttu-id="2cb13-279">Eine "Kalibrierung Raum" auf, das in der Szene das übergeordnete Element der tags</span><span class="sxs-lookup"><span data-stu-id="2cb13-279">One 'calibration space' which in the scene is the parent of the tags</span></span>
* <span data-ttu-id="2cb13-280">Bezeichner der Kamera-Funktion</span><span class="sxs-lookup"><span data-stu-id="2cb13-280">Camera feature identifier</span></span>
* <span data-ttu-id="2cb13-281">Verhalten, das verschiebt Bereich Kalibrierung der Anpassung an die modelled Tags mit den Tags in Echtzeit (wir sind darauf achten, die den übergeordneten Bereich, nicht die modelled Marker selbst zu verschieben, da andere Connect Positionen bezogen auf sie ist).</span><span class="sxs-lookup"><span data-stu-id="2cb13-281">Behavior which moves the calibration space to align the modelled tags with the real-time tags (we are careful to move the parent space, not the modelled markers themselves, because other connect is positions relative to them).</span></span>

```
// In the two tags case:
 Vector3 idealDelta = (realTags[1].EstimatedWorldPos - realTags[0].EstimatedWorldPos);
 Vector3 curDelta = (modelledTags[1].transform.position - modelledTags[0].transform.position);
 if (IsAssumeGravity) {
   idealDelta.y = 0;
   curDelta.y = 0;
 }
 Quaternion deltaRot = Quaternion.FromToRotation(curDelta, idealDelta);
 trans.rotation = Quaternion.LookRotation(deltaRot * trans.forward, trans.up);
 trans.position += realTags[0].EstimatedWorldPos - modelledTags[0].transform.position;
```

### <a name="render-holograms-from-the-cameras-position"></a><span data-ttu-id="2cb13-282">Rendern von Hologramme aus die Position der Kamera</span><span class="sxs-lookup"><span data-stu-id="2cb13-282">Render holograms from the Camera's position</span></span>

<span data-ttu-id="2cb13-283">Hinweis: Wenn Sie versuchen, Ihre eigenen erstellen [Mixed Reality-Erfassung (MRC)](mixed-reality-capture.md), die Hologramme mit der Kamera-Datenstrom kombiniert, können Sie die [MRC Effekte](mixed-reality-capture-for-developers.md) oder aktivieren Sie die Eigenschaft ShowHolograms in [ Gebietsschemabezogene Kamera in Unity](locatable-camera-in-unity.md).</span><span class="sxs-lookup"><span data-stu-id="2cb13-283">Note: If you are trying to create your own [Mixed reality capture (MRC)](mixed-reality-capture.md), which blends holograms with the Camera stream, you can use the [MRC effects](mixed-reality-capture-for-developers.md) or enable the showHolograms property in [Locatable camera in Unity](locatable-camera-in-unity.md).</span></span>

<span data-ttu-id="2cb13-284">Wenn Sie eine besondere Render direkt auf den RGB-Kamera-Datenstrom möchten, ist es möglich, Hologramme im Raum aus die Position der Kamera mit einer videofeed synchron zu rendern, um eine benutzerdefinierte – Hologramm Aufzeichnung/live-Vorschau bereitzustellen.</span><span class="sxs-lookup"><span data-stu-id="2cb13-284">If you'd like to do a special render directly on the RGB Camera stream, it's possible to render holograms in space from the Camera's position in sync with a video feed in order to provide a custom hologram recording/live preview.</span></span>

<span data-ttu-id="2cb13-285">In Skype dazu wir der remote-Client anzeigen, was die HoloLens-Benutzers angezeigt wird, und für die Interaktion mit der gleichen Hologramme ermöglichen.</span><span class="sxs-lookup"><span data-stu-id="2cb13-285">In Skype, we do this to show the remote client what the HoloLens user is seeing and allow them to interact with the same holograms.</span></span> <span data-ttu-id="2cb13-286">Vor dem Senden über die einzelnen Videoframes, über den Dienst Skype, nehmen wir die entsprechenden Kamera-Daten des Frames.</span><span class="sxs-lookup"><span data-stu-id="2cb13-286">Before sending over each video frame through the Skype service, we grab each frame's corresponding camera data.</span></span> <span data-ttu-id="2cb13-287">Wir dann Verpacken der Kamera systemexterne und systeminterne-Metadaten mit des Videoframes und senden Sie sie über die Skype-Dienst.</span><span class="sxs-lookup"><span data-stu-id="2cb13-287">We then package the camera's extrinsic and intrinsic metadata with the video frame and then send it over the Skype service.</span></span>

<span data-ttu-id="2cb13-288">Auf der Empfängerseite haben mithilfe von Unity wir bereits alle die Hologramme im des Benutzers, der die HoloLens-Raum mit dem gleichen Koordinatensystem synchronisiert.</span><span class="sxs-lookup"><span data-stu-id="2cb13-288">On the receiving side, using Unity, we've already synced all of the holograms in the HoloLens user's space using the same coordinate system.</span></span> <span data-ttu-id="2cb13-289">Dadurch können wir der Kamera-systemexterne-Metadaten verwenden, um die Unity-Kamera in den genauen Ort der Welt (in Bezug auf die restlichen den Hologramme) zu platzieren, das der Benutzer HoloLens ständigen wurde, wenn sich dieses video Frame erfasst wurde, und verwenden die Kamera systeminterne Informationen Stellen Sie sicher, dass die Sicht identisch ist.</span><span class="sxs-lookup"><span data-stu-id="2cb13-289">This allows us to use the camera's extrinsic metadata to place the Unity camera in the exact place in the world (relative to the rest of the holograms) that the HoloLens user was standing when that video frame was captured, and use the camera intrinsic information to ensure the view is the same.</span></span>

<span data-ttu-id="2cb13-290">Nachdem wir die Kamera ordnungsgemäß eingerichtet haben, kombiniert welche die Kamera auf den Frame angezeigt, die wir von Skype wird erhalten, erstellen eine mixed Reality-Ansicht der HoloLens der Benutzer sieht mit Graphics.Blit Hologramme.</span><span class="sxs-lookup"><span data-stu-id="2cb13-290">Once we have the camera set up properly, we combine what holograms the camera sees onto the frame we received from Skype, creating a mixed reality view of what the HoloLens user sees using Graphics.Blit.</span></span>

```cs
private void OnFrameReceived(Texture frameTexture, Vector3 cameraPosition, Quaternion cameraRotation, Matrix4x4 cameraProjectionMatrix)
{
    //set material that will be blitted onto the RenderTexture
    this.compositeMaterial.SetTexture(CompositeRenderer.CameraTextureMaterialProperty, frameTexture);
    //set the camera to be that of the HoloLens's device camera
    this.Camera.transform.position = cameraPosition;
    this.Camera.transform.rotation = cameraRotation;
    this.Camera.projectionMatrix = cameraProjectionMatrix;
    //trigger the Graphics's Blit now that the frame and camera are set up
    this.TextureReady = false;
}
private void OnRenderImage(RenderTexture source, RenderTexture destination)
{
    if (!this.TextureReady)
    {
        Graphics.Blit(source, destination, this.compositeMaterial);
        this.TextureReady = true;
    }
}
```

### <a name="track-or-identify-tagged-stationary-or-moving-real-world-objectsfaces-using-leds-or-other-recognizer-libraries"></a><span data-ttu-id="2cb13-291">Nachverfolgen oder stationär markiert zu identifizieren oder beweglichen reale Objekte/Gesichtern, LEDs oder andere Bibliotheken Erkennung</span><span class="sxs-lookup"><span data-stu-id="2cb13-291">Track or Identify Tagged Stationary or Moving real-world objects/faces using LEDs or other recognizer libraries</span></span>

<span data-ttu-id="2cb13-292">Beispiele:</span><span class="sxs-lookup"><span data-stu-id="2cb13-292">Examples:</span></span>
* <span data-ttu-id="2cb13-293">Industrielle Roboter mit LEDs (oder QR-Codes für das Verschieben von langsamer Objekte)</span><span class="sxs-lookup"><span data-stu-id="2cb13-293">Industrial robots with LEDs (or QR codes for slower moving objects)</span></span>
* <span data-ttu-id="2cb13-294">Identifizierung und die Erkennung von Objekten im Raum</span><span class="sxs-lookup"><span data-stu-id="2cb13-294">Identify and recognize objects in the room</span></span>
* <span data-ttu-id="2cb13-295">Identifizierung und die Erkennung von Personen im Raum (z. B. direkte holographic Kontaktkarten in Gesichtern)</span><span class="sxs-lookup"><span data-stu-id="2cb13-295">Identify and recognize people in the room (e.g. place holographic contact cards over faces)</span></span>

## <a name="see-also"></a><span data-ttu-id="2cb13-296">Siehe auch</span><span class="sxs-lookup"><span data-stu-id="2cb13-296">See also</span></span>
* [<span data-ttu-id="2cb13-297">Gebietsschemabezogene Kamera in DirectX</span><span class="sxs-lookup"><span data-stu-id="2cb13-297">Locatable camera in DirectX</span></span>](locatable-camera-in-directx.md)
* [<span data-ttu-id="2cb13-298">Gebietsschemabezogene Kamera in Unity</span><span class="sxs-lookup"><span data-stu-id="2cb13-298">Locatable camera in Unity</span></span>](locatable-camera-in-unity.md)
* [<span data-ttu-id="2cb13-299">Mixed Reality-Erfassung</span><span class="sxs-lookup"><span data-stu-id="2cb13-299">Mixed reality capture</span></span>](mixed-reality-capture.md)
* [<span data-ttu-id="2cb13-300">Mixed Reality-Erfassung für Entwickler</span><span class="sxs-lookup"><span data-stu-id="2cb13-300">Mixed reality capture for developers</span></span>](mixed-reality-capture-for-developers.md)
* [<span data-ttu-id="2cb13-301">Medienaufzeichnung Einführung</span><span class="sxs-lookup"><span data-stu-id="2cb13-301">Media capture introduction</span></span>](https://msdn.microsoft.com/library/windows/apps/mt243896.aspx)
