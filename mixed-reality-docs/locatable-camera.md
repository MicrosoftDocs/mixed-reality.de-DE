---
title: Gebietsschemabezogene Kamera
description: Allgemeine Informationen über die frontkamera HoloLens, wie es funktioniert und die Profile und Lösungen, die Entwicklern zur Verfügung.
author: cdedmonds
ms.author: wguyman, cdedmonds
ms.date: 06/12/2019
ms.topic: article
keywords: Kamera, Hololens, Farbe Kamera, Front-facing
ms.openlocfilehash: f661fc82fbeab9a870e8ccf7044c9bb375bed7e3
ms.sourcegitcommit: 30246ab9b9be44a3c707061753e53d4bf401eb6b
ms.translationtype: MT
ms.contentlocale: de-DE
ms.lasthandoff: 06/22/2019
ms.locfileid: "67326289"
---
# <a name="locatable-camera"></a><span data-ttu-id="e8a54-104">Gebietsschemabezogene Kamera</span><span class="sxs-lookup"><span data-stu-id="e8a54-104">Locatable camera</span></span>

<span data-ttu-id="e8a54-105">HoloLens enthält, eine Welt gerichteten Kamera, die auf der Vorderseite des Geräts, das kann apps finden Sie unter der Benutzer bereitgestellt wird.</span><span class="sxs-lookup"><span data-stu-id="e8a54-105">HoloLens includes a world-facing camera mounted on the front of the device which enables apps to see what the user sees.</span></span> <span data-ttu-id="e8a54-106">Entwickler haben Zugriff auf und Kontrolle der Kamera, genauso wie für die Color-Kameras auf Smartphones, tragbare Geräte und Desktops.</span><span class="sxs-lookup"><span data-stu-id="e8a54-106">Developers have access to and control of the camera just as they would for color cameras on smartphones, portables, or desktops.</span></span> <span data-ttu-id="e8a54-107">Die gleichen universelle Windows [medienaufzeichnung](https://msdn.microsoft.com/library/windows/apps/windows.media.capture.mediacapture.aspx) und Windows Media Foundation-APIs, die an mobile Geräte und Desktops arbeiten HoloLens.</span><span class="sxs-lookup"><span data-stu-id="e8a54-107">The same universal windows [media capture](https://msdn.microsoft.com/library/windows/apps/windows.media.capture.mediacapture.aspx) and windows media foundation APIs that work on mobile and desktop work on HoloLens.</span></span> <span data-ttu-id="e8a54-108">Unity [hat auch diese Windows-APIs umschlossen](locatable-camera-in-unity.md) abstrahieren einfache Verwendung der Kamera auf HoloLens für Aufgaben wie dauert regulären Fotos und Videos (mit oder ohne Hologramme), und suchen die Position der Kamera in und Perspektive auf die die Szene.</span><span class="sxs-lookup"><span data-stu-id="e8a54-108">Unity [has also wrapped these windows APIs](locatable-camera-in-unity.md) to abstract simple usage of the camera on HoloLens for tasks such as taking regular photos and videos (with or without holograms) and locating the camera's position in and perspective on the scene.</span></span>

## <a name="device-camera-information"></a><span data-ttu-id="e8a54-109">Kamera-Geräteinformationen</span><span class="sxs-lookup"><span data-stu-id="e8a54-109">Device camera information</span></span>

### <a name="hololens-first-generation"></a><span data-ttu-id="e8a54-110">HoloLens (löschbaren)</span><span class="sxs-lookup"><span data-stu-id="e8a54-110">HoloLens (first-generation)</span></span>

* <span data-ttu-id="e8a54-111">Feste Fokus Foto / (PV) Videokamera, weiß automatischen Lastenausgleich, automatische Offenlegung und vollständigen Verarbeitung pipe</span><span class="sxs-lookup"><span data-stu-id="e8a54-111">Fixed focus photo/video (PV) camera, with auto white balance, auto exposure, and full image processing pipe</span></span>
* <span data-ttu-id="e8a54-112">Whitepaper leuchtet Datenschutz mit Internetzugriff der ganzen Welt, wenn die Kamera aktiv ist.</span><span class="sxs-lookup"><span data-stu-id="e8a54-112">White Privacy LED facing the world will illuminate whenever the camera is active</span></span>
* <span data-ttu-id="e8a54-113">Die Kamera unterstützt die folgenden Modi (alle Modi sind Seitenverhältnis 16:9) auf 30, 24, 20, 15 und 5 f/s:</span><span class="sxs-lookup"><span data-stu-id="e8a54-113">The camera supports the following modes (all modes are 16:9 aspect ratio) at 30, 24, 20, 15, and 5 fps:</span></span>

  |  <span data-ttu-id="e8a54-114">Video</span><span class="sxs-lookup"><span data-stu-id="e8a54-114">Video</span></span>  |  <span data-ttu-id="e8a54-115">Vorschau</span><span class="sxs-lookup"><span data-stu-id="e8a54-115">Preview</span></span>  |  <span data-ttu-id="e8a54-116">Weiterhin</span><span class="sxs-lookup"><span data-stu-id="e8a54-116">Still</span></span>  |  <span data-ttu-id="e8a54-117">Horizontale Sichtfeld (H-Blickfeld)</span><span class="sxs-lookup"><span data-stu-id="e8a54-117">Horizontal Field of View (H-FOV)</span></span> |  <span data-ttu-id="e8a54-118">Empfohlene Verwendung</span><span class="sxs-lookup"><span data-stu-id="e8a54-118">Suggested usage</span></span> | 
  |----------|----------|----------|----------|----------|
  |  <span data-ttu-id="e8a54-119">1280x720</span><span class="sxs-lookup"><span data-stu-id="e8a54-119">1280x720</span></span> |  <span data-ttu-id="e8a54-120">1280x720</span><span class="sxs-lookup"><span data-stu-id="e8a54-120">1280x720</span></span> |  <span data-ttu-id="e8a54-121">1280x720</span><span class="sxs-lookup"><span data-stu-id="e8a54-121">1280x720</span></span> |  <span data-ttu-id="e8a54-122">45deg</span><span class="sxs-lookup"><span data-stu-id="e8a54-122">45deg</span></span>  |  <span data-ttu-id="e8a54-123">Mithilfe von videostabilisierung (Standardmodus)</span><span class="sxs-lookup"><span data-stu-id="e8a54-123">(default mode with video stabilization)</span></span> | 
  |  <span data-ttu-id="e8a54-124">Nicht zutreffend</span><span class="sxs-lookup"><span data-stu-id="e8a54-124">N/A</span></span> |  <span data-ttu-id="e8a54-125">Nicht zutreffend</span><span class="sxs-lookup"><span data-stu-id="e8a54-125">N/A</span></span> |  <span data-ttu-id="e8a54-126">2048x1152</span><span class="sxs-lookup"><span data-stu-id="e8a54-126">2048x1152</span></span> |  <span data-ttu-id="e8a54-127">67deg</span><span class="sxs-lookup"><span data-stu-id="e8a54-127">67deg</span></span> |  <span data-ttu-id="e8a54-128">Standbild der höchsten Auflösung</span><span class="sxs-lookup"><span data-stu-id="e8a54-128">Highest resolution still image</span></span> | 
  |  <span data-ttu-id="e8a54-129">1408x792</span><span class="sxs-lookup"><span data-stu-id="e8a54-129">1408x792</span></span> |  <span data-ttu-id="e8a54-130">1408x792</span><span class="sxs-lookup"><span data-stu-id="e8a54-130">1408x792</span></span> |  <span data-ttu-id="e8a54-131">1408x792</span><span class="sxs-lookup"><span data-stu-id="e8a54-131">1408x792</span></span> |  <span data-ttu-id="e8a54-132">48deg</span><span class="sxs-lookup"><span data-stu-id="e8a54-132">48deg</span></span> |  <span data-ttu-id="e8a54-133">Overscan (Auffüllung)-Lösung vor der videostabilisierung</span><span class="sxs-lookup"><span data-stu-id="e8a54-133">Overscan (padding) resolution before video stabilization</span></span> | 
  |  <span data-ttu-id="e8a54-134">1344x756</span><span class="sxs-lookup"><span data-stu-id="e8a54-134">1344x756</span></span> |  <span data-ttu-id="e8a54-135">1344x756</span><span class="sxs-lookup"><span data-stu-id="e8a54-135">1344x756</span></span> |  <span data-ttu-id="e8a54-136">1344x756</span><span class="sxs-lookup"><span data-stu-id="e8a54-136">1344x756</span></span> |  <span data-ttu-id="e8a54-137">67deg</span><span class="sxs-lookup"><span data-stu-id="e8a54-137">67deg</span></span> |  <span data-ttu-id="e8a54-138">Große Blickfeld Videomodus mit overscan</span><span class="sxs-lookup"><span data-stu-id="e8a54-138">Large FOV video mode with overscan</span></span> | 
  |  <span data-ttu-id="e8a54-139">896x504</span><span class="sxs-lookup"><span data-stu-id="e8a54-139">896x504</span></span> |  <span data-ttu-id="e8a54-140">896x504</span><span class="sxs-lookup"><span data-stu-id="e8a54-140">896x504</span></span> |  <span data-ttu-id="e8a54-141">896x504</span><span class="sxs-lookup"><span data-stu-id="e8a54-141">896x504</span></span> |  <span data-ttu-id="e8a54-142">48deg</span><span class="sxs-lookup"><span data-stu-id="e8a54-142">48deg</span></span> |  <span data-ttu-id="e8a54-143">Energieeffiziente / -Modus mit niedriger Auflösung für Image Verarbeitungsaufgaben.</span><span class="sxs-lookup"><span data-stu-id="e8a54-143">Low power / Low resolution mode for image processing tasks</span></span> | 

### <a name="hololens-2"></a><span data-ttu-id="e8a54-144">HoloLens 2</span><span class="sxs-lookup"><span data-stu-id="e8a54-144">HoloLens 2</span></span>

* <span data-ttu-id="e8a54-145">Autofokus Foto/Video (PV) Kamera mit weißen automatischen Lastenausgleich, automatische Offenlegung und vollständigen Verarbeitung pipe</span><span class="sxs-lookup"><span data-stu-id="e8a54-145">Auto-focus photo/video (PV) camera, with auto white balance, auto exposure, and full image processing pipe</span></span>
* <span data-ttu-id="e8a54-146">Whitepaper leuchtet Datenschutz mit Internetzugriff der ganzen Welt, wenn die Kamera aktiv ist.</span><span class="sxs-lookup"><span data-stu-id="e8a54-146">White Privacy LED facing the world will illuminate whenever the camera is active</span></span>
* <span data-ttu-id="e8a54-147">Die Kamera unterstützt die folgenden Modi (alle video Modi sind Seitenverhältnis 16:9):</span><span class="sxs-lookup"><span data-stu-id="e8a54-147">The camera supports the following modes (all video modes are 16:9 aspect ratio):</span></span>

  >[!NOTE]
  ><span data-ttu-id="e8a54-148">Diese Modi unterliegen noch Änderungen, die vor der allgemeinen Verfügbarkeit von HoloLens 2.</span><span class="sxs-lookup"><span data-stu-id="e8a54-148">These modes are subject to change prior to HoloLens 2 general availability.</span></span>

  |  <span data-ttu-id="e8a54-149">Video</span><span class="sxs-lookup"><span data-stu-id="e8a54-149">Video</span></span>  |  <span data-ttu-id="e8a54-150">Vorschau</span><span class="sxs-lookup"><span data-stu-id="e8a54-150">Preview</span></span>  |  <span data-ttu-id="e8a54-151">Weiterhin</span><span class="sxs-lookup"><span data-stu-id="e8a54-151">Still</span></span>  |  <span data-ttu-id="e8a54-152">Frameraten</span><span class="sxs-lookup"><span data-stu-id="e8a54-152">Frame rates</span></span>  |  <span data-ttu-id="e8a54-153">Horizontale Sichtfeld (H-Blickfeld)</span><span class="sxs-lookup"><span data-stu-id="e8a54-153">Horizontal Field of View (H-FOV)</span></span> |  <span data-ttu-id="e8a54-154">Empfohlene Verwendung</span><span class="sxs-lookup"><span data-stu-id="e8a54-154">Suggested usage</span></span> | 
  |----------|----------|----------|----------|----------|----------|
  |  <span data-ttu-id="e8a54-155">1920x1080</span><span class="sxs-lookup"><span data-stu-id="e8a54-155">1920x1080</span></span> |  <span data-ttu-id="e8a54-156">1920x1080</span><span class="sxs-lookup"><span data-stu-id="e8a54-156">1920x1080</span></span> |  <span data-ttu-id="e8a54-157">Nicht zutreffend</span><span class="sxs-lookup"><span data-stu-id="e8a54-157">N/A</span></span> |  <span data-ttu-id="e8a54-158">30, 15 f/s</span><span class="sxs-lookup"><span data-stu-id="e8a54-158">30, 15 fps</span></span>  |  <span data-ttu-id="e8a54-159">54deg</span><span class="sxs-lookup"><span data-stu-id="e8a54-159">54deg</span></span>  |  <span data-ttu-id="e8a54-160">Mithilfe von videostabilisierung (Standardmodus)</span><span class="sxs-lookup"><span data-stu-id="e8a54-160">(default mode with video stabilization)</span></span> | 
  |  <span data-ttu-id="e8a54-161">Nicht zutreffend</span><span class="sxs-lookup"><span data-stu-id="e8a54-161">N/A</span></span> |  <span data-ttu-id="e8a54-162">Nicht zutreffend</span><span class="sxs-lookup"><span data-stu-id="e8a54-162">N/A</span></span> |  <span data-ttu-id="e8a54-163">3904X2196</span><span class="sxs-lookup"><span data-stu-id="e8a54-163">3904X2196</span></span> |  <span data-ttu-id="e8a54-164">Nicht zutreffend</span><span class="sxs-lookup"><span data-stu-id="e8a54-164">N/A</span></span>  |  <span data-ttu-id="e8a54-165">64deg</span><span class="sxs-lookup"><span data-stu-id="e8a54-165">64deg</span></span> |  <span data-ttu-id="e8a54-166">Standbild der höchsten Auflösung</span><span class="sxs-lookup"><span data-stu-id="e8a54-166">Highest resolution still image</span></span> | 
  |  <span data-ttu-id="e8a54-167">2272x1278</span><span class="sxs-lookup"><span data-stu-id="e8a54-167">2272x1278</span></span> |  <span data-ttu-id="e8a54-168">2272x1278</span><span class="sxs-lookup"><span data-stu-id="e8a54-168">2272x1278</span></span> |  <span data-ttu-id="e8a54-169">Nicht zutreffend</span><span class="sxs-lookup"><span data-stu-id="e8a54-169">N/A</span></span> |  <span data-ttu-id="e8a54-170">30, 15 f/s</span><span class="sxs-lookup"><span data-stu-id="e8a54-170">30, 15 fps</span></span>  |  <span data-ttu-id="e8a54-171">64deg</span><span class="sxs-lookup"><span data-stu-id="e8a54-171">64deg</span></span> |  <span data-ttu-id="e8a54-172">Overscan (Auffüllung)-Lösung vor der videostabilisierung</span><span class="sxs-lookup"><span data-stu-id="e8a54-172">Overscan (padding) resolution before video stabilization</span></span> | 
  |  <span data-ttu-id="e8a54-173">1952x1100</span><span class="sxs-lookup"><span data-stu-id="e8a54-173">1952x1100</span></span> |  <span data-ttu-id="e8a54-174">1952x1100</span><span class="sxs-lookup"><span data-stu-id="e8a54-174">1952x1100</span></span> |  <span data-ttu-id="e8a54-175">1952x1100</span><span class="sxs-lookup"><span data-stu-id="e8a54-175">1952x1100</span></span>  |  <span data-ttu-id="e8a54-176">30, 15 f/s</span><span class="sxs-lookup"><span data-stu-id="e8a54-176">30, 15 fps</span></span>  |  <span data-ttu-id="e8a54-177">64deg</span><span class="sxs-lookup"><span data-stu-id="e8a54-177">64deg</span></span> |  <span data-ttu-id="e8a54-178">Hoher Qualität</span><span class="sxs-lookup"><span data-stu-id="e8a54-178">High-quality streaming</span></span> | 
  |  <span data-ttu-id="e8a54-179">1280x720</span><span class="sxs-lookup"><span data-stu-id="e8a54-179">1280x720</span></span> |  <span data-ttu-id="e8a54-180">1280x720</span><span class="sxs-lookup"><span data-stu-id="e8a54-180">1280x720</span></span> |  <span data-ttu-id="e8a54-181">Nicht zutreffend</span><span class="sxs-lookup"><span data-stu-id="e8a54-181">N/A</span></span> |  <span data-ttu-id="e8a54-182">30, 15, 5 f/s</span><span class="sxs-lookup"><span data-stu-id="e8a54-182">30, 15, 5 fps</span></span>  |  <span data-ttu-id="e8a54-183">64deg</span><span class="sxs-lookup"><span data-stu-id="e8a54-183">64deg</span></span> |  <span data-ttu-id="e8a54-184">Niedrige Power bzw. Beschlusses Modus für das streaming und Aufgaben der bildverarbeitung</span><span class="sxs-lookup"><span data-stu-id="e8a54-184">Low power/resolution mode for streaming and image processing tasks</span></span> | 

## <a name="locating-the-device-camera-in-the-world"></a><span data-ttu-id="e8a54-185">Suchen die Kamera des Geräts in der ganzen Welt</span><span class="sxs-lookup"><span data-stu-id="e8a54-185">Locating the Device Camera in the World</span></span>

<span data-ttu-id="e8a54-186">Wenn HoloLens Fotos und Videos verweist, enthalten die aufgezeichneten Frames die Position der Kamera in der ganzen Welt als auch die codelens-Modell der Kamera.</span><span class="sxs-lookup"><span data-stu-id="e8a54-186">When HoloLens takes photos and videos, the captured frames include the location of the camera in the world, as well as the lens model of the camera.</span></span> <span data-ttu-id="e8a54-187">Dadurch können Anwendungen, Grund, über die Position der Kamera in der realen Welt ergänzte imaging-Szenarien.</span><span class="sxs-lookup"><span data-stu-id="e8a54-187">This allows applications to reason about the position of the camera in the real world for augmented imaging scenarios.</span></span> <span data-ttu-id="e8a54-188">Entwickler können ihre eigenen Szenarien, die mit ihren bevorzugten bildverarbeitung oder einen benutzerdefinierten Computer Vision Bibliotheken kreativ zurücksetzen.</span><span class="sxs-lookup"><span data-stu-id="e8a54-188">Developers can creatively roll their own scenarios using their favorite image processing or custom computer vision libraries.</span></span>

<span data-ttu-id="e8a54-189">"Kamera" an anderer Stelle im HoloLens Dokumentation bezieht sich möglicherweise auf die "virtuelle Spiel Kamera" (die Frustums der app rendert).</span><span class="sxs-lookup"><span data-stu-id="e8a54-189">"Camera" elsewhere in HoloLens documentation may refer to the "virtual game camera" (the frustum the app renders to).</span></span> <span data-ttu-id="e8a54-190">Es sei denn, die andernfalls gekennzeichnet ist, bezieht sich "Kamera" auf dieser Seite auf der realen Welt RGB-Farbe Kamera ein.</span><span class="sxs-lookup"><span data-stu-id="e8a54-190">Unless denoted otherwise, "camera" on this page refers to the real-world RGB color camera.</span></span>

<span data-ttu-id="e8a54-191">Die Details auf dieser Seite Cover mithilfe der [MediaFrameReference](https://docs.microsoft.com/en-us/uwp/api/windows.media.capture.frames.mediaframereference) Klasse, aber es gibt auch APIs zum Pull-Kamera systeminterne Funktionen und Standorten mithilfe von [Media Foundation Attribute](https://msdn.microsoft.com/library/windows/desktop/mt740395(v=vs.85).aspx).</span><span class="sxs-lookup"><span data-stu-id="e8a54-191">The details on this page cover using the [MediaFrameReference](https://docs.microsoft.com/en-us/uwp/api/windows.media.capture.frames.mediaframereference) class, however there are also APIs to pull camera intrinsics and locations using [Media Foundation Attributes](https://msdn.microsoft.com/library/windows/desktop/mt740395(v=vs.85).aspx).</span></span> <span data-ttu-id="e8a54-192">Finden Sie in der [Holographic Gesicht Beispiel für den Überwachungsprofil](https://github.com/Microsoft/Windows-universal-samples/tree/master/Samples/HolographicFaceTracking) für Weitere Informationen.</span><span class="sxs-lookup"><span data-stu-id="e8a54-192">Please refer to the [Holographic face tracking sample](https://github.com/Microsoft/Windows-universal-samples/tree/master/Samples/HolographicFaceTracking) for more information.</span></span>

### <a name="images-with-coordinate-systems"></a><span data-ttu-id="e8a54-193">Images mit Koordinatensysteme</span><span class="sxs-lookup"><span data-stu-id="e8a54-193">Images with Coordinate Systems</span></span>

<span data-ttu-id="e8a54-194">Jedes Bild-Frame (, ob Fotos oder Videos) umfasst eine [SpatialCoordinateSystem](https://docs.microsoft.com/en-us/uwp/api/windows.perception.spatial.spatialcoordinatesystem) Stamm der Kamera zum Zeitpunkt der Erfassung, die mithilfe von zugegriffen werden kann die [Koordinatensystem](https://docs.microsoft.com/en-us/uwp/api/windows.media.capture.frames.mediaframereference.coordinatesystem#Windows_Media_Capture_Frames_MediaFrameReference_CoordinateSystem) Eigenschaft Ihre [MediaFrameReference](https://docs.microsoft.com/en-us/uwp/api/Windows.Media.Capture.Frames.MediaFrameReference).</span><span class="sxs-lookup"><span data-stu-id="e8a54-194">Each image frame (whether photo or video) includes a [SpatialCoordinateSystem](https://docs.microsoft.com/en-us/uwp/api/windows.perception.spatial.spatialcoordinatesystem) rooted at the camera at the time of capture which can be accessed using the [CoordinateSystem](https://docs.microsoft.com/en-us/uwp/api/windows.media.capture.frames.mediaframereference.coordinatesystem#Windows_Media_Capture_Frames_MediaFrameReference_CoordinateSystem) property of your [MediaFrameReference](https://docs.microsoft.com/en-us/uwp/api/Windows.Media.Capture.Frames.MediaFrameReference).</span></span> <span data-ttu-id="e8a54-195">Darüber hinaus jeder Frame enthält eine Beschreibung des Modells Linse Kamera, die im befinden die [CameraIntrinsics](https://docs.microsoft.com/en-us/uwp/api/windows.media.capture.frames.videomediaframe.cameraintrinsics#Windows_Media_Capture_Frames_VideoMediaFrame_CameraIntrinsics) Eigenschaft.</span><span class="sxs-lookup"><span data-stu-id="e8a54-195">In addition, each frame contains a description of the camera lens model which can be found in the [CameraIntrinsics](https://docs.microsoft.com/en-us/uwp/api/windows.media.capture.frames.videomediaframe.cameraintrinsics#Windows_Media_Capture_Frames_VideoMediaFrame_CameraIntrinsics) property.</span></span> <span data-ttu-id="e8a54-196">Zusammen definieren diese Transformationen für jedes Pixel ein Strahl im 3D-Raum, die den Pfad repräsentiert, die von der Photonen, die das Pixel erzeugt.</span><span class="sxs-lookup"><span data-stu-id="e8a54-196">Together, these transforms define for each pixel a ray in 3D space representing the path taken by the photons that produced the pixel.</span></span> <span data-ttu-id="e8a54-197">Diese Strahlung können auf andere Inhalte in der app verknüpft werden, durch die Transformation von Koordinatensystem des Frames abrufen, auf einige andere Koordinatensystem (z. B. aus einem [feststehende Verweisrahmen](coordinate-systems.md#stationary-frame-of-reference)).</span><span class="sxs-lookup"><span data-stu-id="e8a54-197">These rays can be related to other content in the app by obtaining the transform from the frame's coordinate system to some other coordinate system (e.g. from a [stationary frame of reference](coordinate-systems.md#stationary-frame-of-reference)).</span></span> <span data-ttu-id="e8a54-198">Zusammenfassend lässt sich sagen, bietet der einzelnen Bild-Frame Folgendes:</span><span class="sxs-lookup"><span data-stu-id="e8a54-198">To summarize, each image frame provides the following:</span></span>
* <span data-ttu-id="e8a54-199">Die Pixeldaten (im Format der RGB-/ NV12/JPEG/usw.)</span><span class="sxs-lookup"><span data-stu-id="e8a54-199">Pixel Data (in RGB/NV12/JPEG/etc. format)</span></span>
* <span data-ttu-id="e8a54-200">Ein [SpatialCoordinateSystem](https://docs.microsoft.com/en-us/uwp/api/windows.perception.spatial.spatialcoordinatesystem) aus dem Speicherort der Erfassung</span><span class="sxs-lookup"><span data-stu-id="e8a54-200">A [SpatialCoordinateSystem](https://docs.microsoft.com/en-us/uwp/api/windows.perception.spatial.spatialcoordinatesystem) from the location of capture</span></span>
* <span data-ttu-id="e8a54-201">Ein [CameraIntrinsics](https://docs.microsoft.com/en-us/uwp/api/windows.media.capture.frames.videomediaframe.cameraintrinsics#Windows_Media_Capture_Frames_VideoMediaFrame_CameraIntrinsics) Klasse, die den Fokus Modus der Kamera enthält.</span><span class="sxs-lookup"><span data-stu-id="e8a54-201">A [CameraIntrinsics](https://docs.microsoft.com/en-us/uwp/api/windows.media.capture.frames.videomediaframe.cameraintrinsics#Windows_Media_Capture_Frames_VideoMediaFrame_CameraIntrinsics) class containing the lens mode of the camera</span></span>

### <a name="camera-to-application-specified-coordinate-system"></a><span data-ttu-id="e8a54-202">Kamera Koordinatensystem anwendungsspezifische</span><span class="sxs-lookup"><span data-stu-id="e8a54-202">Camera to Application-specified Coordinate System</span></span>

<span data-ttu-id="e8a54-203">Um auf Ihre Anwendung/globales Koordinatensystem aus dem 'CameraIntrinsics' und "CameraCoordinateSystem" zu wechseln, benötigen Sie Folgendes:</span><span class="sxs-lookup"><span data-stu-id="e8a54-203">To go from the 'CameraIntrinsics' and 'CameraCoordinateSystem' to your application/world coordinate system, you'll need the following:</span></span>

<span data-ttu-id="e8a54-204">[Gebietsschemabezogene Kamera in Unity](locatable-camera-in-unity.md): CameraToWorldMatrix wird automatisch von PhotoCaptureFrame-Klasse bereitgestellt, (sodass Sie nicht über die Transformationen CameraCoordinateSystem machen müssen).</span><span class="sxs-lookup"><span data-stu-id="e8a54-204">[Locatable camera in Unity](locatable-camera-in-unity.md): CameraToWorldMatrix is automatically provided by PhotoCaptureFrame class(so you don't need to worry about the CameraCoordinateSystem transforms).</span></span>

<span data-ttu-id="e8a54-205">[Gebietsschemabezogene Kamera in DirectX](locatable-camera-in-directx.md): Zeigt die recht einfache Möglichkeit zum Abfragen von der Transformation zwischen Koordinatensystem der Kamera und Ihrer eigenen Anwendung Coordinate system(s).</span><span class="sxs-lookup"><span data-stu-id="e8a54-205">[Locatable camera in DirectX](locatable-camera-in-directx.md): Shows the fairly straightforward way to query for the transform between the camera's coordinate system and your own application coordinate system(s).</span></span>

### <a name="distortion-error"></a><span data-ttu-id="e8a54-206">Verzerrung-Fehler</span><span class="sxs-lookup"><span data-stu-id="e8a54-206">Distortion Error</span></span>

<span data-ttu-id="e8a54-207">Auf HoloLens sind die Videos und weiterhin Image Streams unverfälschten in das System die Image-Verarbeitungspipeline, bevor die Frames der Anwendung zur Verfügung gestellt werden (die Vorschau des Datenstroms enthält die ursprünglichen verzerrt Frames).</span><span class="sxs-lookup"><span data-stu-id="e8a54-207">On HoloLens, the video and still image streams are undistorted in the system's image processing pipeline before the frames are made available to the application (the preview stream contains the original distorted frames).</span></span> <span data-ttu-id="e8a54-208">Da nur die CameraIntrinsics zur Verfügung gestellt werden, Anwendungen müssen davon ausgehen Bild-Frames stellen eine perfekte Pinhole Kamera, die Undistortion funktionieren jedoch in der Image-Prozessor können weiterhin lassen Fehler von bis zu 10 Pixel für HoloLens (löschbaren) Wenn die CameraIntrinsics in den Frame-Metadaten verwenden zu können.</span><span class="sxs-lookup"><span data-stu-id="e8a54-208">Because only the CameraIntrinsics are made available, applications must assume image frames represent a perfect pinhole camera, however the undistortion function in the image processor may still leave an error of up to 10 pixels on HoloLens (first-generation) when using the CameraIntrinsics in the frame metadata.</span></span> <span data-ttu-id="e8a54-209">In vielen Fällen – dieser Fehler wird spielt keine Rolle, aber wenn Sie Hologramme, die reale Welt Poster/Marker, z. B. ausrichten sind und Sie feststellen, dass eine < 10px offset (etwa 11mm für Hologramme positioniert-Zähler sofort 2) dieser Verzerrung Fehler könnte die Ursache sein.</span><span class="sxs-lookup"><span data-stu-id="e8a54-209">In many use cases, this error will not matter, but if you are aligning holograms to real world posters/markers, for example, and you notice a <10px offset (roughly 11mm for holograms positioned 2 meters away) this distortion error could be the cause.</span></span> 

## <a name="locatable-camera-usage-scenarios"></a><span data-ttu-id="e8a54-210">Szenarien für die Verwendung gebietsschemabezogene Kamera</span><span class="sxs-lookup"><span data-stu-id="e8a54-210">Locatable Camera Usage Scenarios</span></span>

### <a name="show-a-photo-or-video-in-the-world-where-it-was-captured"></a><span data-ttu-id="e8a54-211">Anzeigen eines Fotos oder Videos in der ganzen Welt, in dem er erfasst wurde</span><span class="sxs-lookup"><span data-stu-id="e8a54-211">Show a photo or video in the world where it was captured</span></span>

<span data-ttu-id="e8a54-212">Die Kamera des Geräts Frames verfügen über eine "Kamera, World"-Transformation, die verwendet werden kann, um anzuzeigen, genau, in dem das Gerät wurde bei der das Image erstellt wurde.</span><span class="sxs-lookup"><span data-stu-id="e8a54-212">The Device Camera frames come with a "Camera To World" transform, that can be used to show exactly where the device was when the image was taken.</span></span> <span data-ttu-id="e8a54-213">Zum Beispiel könnten Sie positionieren ein kleines holographic Symbol an dieser Stelle (CameraToWorld.MultiplyPoint(Vector3.zero)) und sogar zeichnen einen kleinen Pfeil in die Richtung von die Kamera (CameraToWorld.MultiplyVector(Vector3.forward)). konfrontiert wurde</span><span class="sxs-lookup"><span data-stu-id="e8a54-213">For example you could position a small holographic icon at this location (CameraToWorld.MultiplyPoint(Vector3.zero)) and even draw a little arrow in the direction that the camera was facing (CameraToWorld.MultiplyVector(Vector3.forward)).</span></span>

### <a name="tag--pattern--poster--object-tracking"></a><span data-ttu-id="e8a54-214">Tag / Pattern / Poster / Objektverfolgung</span><span class="sxs-lookup"><span data-stu-id="e8a54-214">Tag / Pattern / Poster / Object Tracking</span></span>

<span data-ttu-id="e8a54-215">Viele mixed Reality-Anwendungen verwenden eine erkennbare Bild oder ein visual Muster zum Erstellen eines nachverfolgbare Punkts im Bereich.</span><span class="sxs-lookup"><span data-stu-id="e8a54-215">Many mixed reality applications use a recognizable image or visual pattern to create a trackable point in space.</span></span> <span data-ttu-id="e8a54-216">Dies wird dann zum Rendern verwendet Objekte relativ zum, die zeigen, oder erstellen Sie einen bekannten Speicherort.</span><span class="sxs-lookup"><span data-stu-id="e8a54-216">This is then used to render objects relative to that point or create a known location.</span></span> <span data-ttu-id="e8a54-217">Einige Verwendungsmöglichkeiten für HoloLens gehören, suchen, die ein Objekt der realen Welt mit Fiducials (z. B. eine TV-Monitor mit einem QR-Code) gekennzeichnet, platzieren Hologramme über Fiducials und visuell Kopplung mit nicht-HoloLens-Geräten wie Tablets, die für die Kommunikation mit HoloLens über eingerichtet haben Wi-Fi.</span><span class="sxs-lookup"><span data-stu-id="e8a54-217">Some uses for HoloLens include finding a real world object tagged with fiducials (e.g. a TV monitor with a QR code), placing holograms over fiducials, and visually pairing with non-HoloLens devices like tablets that have been setup to communicate with HoloLens via Wi-Fi.</span></span>

<span data-ttu-id="e8a54-218">Um ein visual-Muster erkennen, und legen Sie das Objekt im Raum, Anwendungen, benötigen Sie Folgendes:</span><span class="sxs-lookup"><span data-stu-id="e8a54-218">To recognize a visual pattern, and then place that object in the applications world space, you'll need a few things:</span></span>
1. <span data-ttu-id="e8a54-219">Ein Bild Muster Anerkennung Toolkit, z. B. QR-Code "," AR-Tags "," Gesicht Finder "," Kreis-nachverfolgungsmodule, OCR usw.</span><span class="sxs-lookup"><span data-stu-id="e8a54-219">An image pattern recognition toolkit, such as QR code, AR tags, face finder, circle trackers, OCR etc.</span></span>
2. <span data-ttu-id="e8a54-220">Bild-Frames zur Laufzeit sammeln und diese an die Anerkennung Ebene übergeben</span><span class="sxs-lookup"><span data-stu-id="e8a54-220">Collect image frames at runtime, and pass them to the recognition layer</span></span>
3. <span data-ttu-id="e8a54-221">Unproject auftraten Bild wieder in die Welt Positionen und wahrscheinlich Welt Strahlung an.</span><span class="sxs-lookup"><span data-stu-id="e8a54-221">Unproject their image locations back into world positions, or likely world rays.</span></span> <span data-ttu-id="e8a54-222">Unter</span><span class="sxs-lookup"><span data-stu-id="e8a54-222">See</span></span>
4. <span data-ttu-id="e8a54-223">Positionieren Sie Ihre virtuellen Modelle über diese Standorte weltweit</span><span class="sxs-lookup"><span data-stu-id="e8a54-223">Position your virtual models over these world locations</span></span>

<span data-ttu-id="e8a54-224">Einige wichtige Image Verarbeitung Links:</span><span class="sxs-lookup"><span data-stu-id="e8a54-224">Some important image processing links:</span></span>
* [<span data-ttu-id="e8a54-225">OpenCV</span><span class="sxs-lookup"><span data-stu-id="e8a54-225">OpenCV</span></span>](http://opencv.org/)
* [<span data-ttu-id="e8a54-226">Qr-Tags</span><span class="sxs-lookup"><span data-stu-id="e8a54-226">QR Tags</span></span>](https://en.wikipedia.org/wiki/QR_code)
* [<span data-ttu-id="e8a54-227">FaceSDK</span><span class="sxs-lookup"><span data-stu-id="e8a54-227">FaceSDK</span></span>](http://research.microsoft.com/projects/facesdk/)
* [<span data-ttu-id="e8a54-228">Microsoft Translator</span><span class="sxs-lookup"><span data-stu-id="e8a54-228">Microsoft Translator</span></span>](https://www.microsoft.com/translator/business)

<span data-ttu-id="e8a54-229">Halten eine interaktive Anwendung Framerate ist wichtig, insbesondere beim Umgang mit Algorithmen für die Erkennung langer Image.</span><span class="sxs-lookup"><span data-stu-id="e8a54-229">Keeping an interactive application frame-rate is critical, especially when dealing with long-running image recognition algorithms.</span></span> <span data-ttu-id="e8a54-230">Aus diesem Grund verwenden wir im Allgemeinen im folgenden Format ein:</span><span class="sxs-lookup"><span data-stu-id="e8a54-230">For this reason we commonly use the following pattern:</span></span>
1. <span data-ttu-id="e8a54-231">Hauptthread: verwaltet das Kameraobjekt</span><span class="sxs-lookup"><span data-stu-id="e8a54-231">Main Thread: manages the camera object</span></span>
2. <span data-ttu-id="e8a54-232">Hauptthread: neue Anforderungen-Frames (Async)</span><span class="sxs-lookup"><span data-stu-id="e8a54-232">Main Thread: requests new frames (async)</span></span>
3. <span data-ttu-id="e8a54-233">Hauptthread: Übergeben von neuen Frames zum Nachverfolgen von Threads</span><span class="sxs-lookup"><span data-stu-id="e8a54-233">Main Thread: pass new frames to tracking thread</span></span>
4. <span data-ttu-id="e8a54-234">Überwachung-Thread: verarbeitet, Bild, um die wichtigsten Punkte zu sammeln</span><span class="sxs-lookup"><span data-stu-id="e8a54-234">Tracking Thread: processes image to collect key points</span></span>
5. <span data-ttu-id="e8a54-235">Hauptthread: verschiebt virtuelle Modell entsprechend finden Sie wichtige Punkte</span><span class="sxs-lookup"><span data-stu-id="e8a54-235">Main Thread: moves virtual model to match found key points</span></span>
6. <span data-ttu-id="e8a54-236">Hauptthread: Wiederholen Sie Schritt 2</span><span class="sxs-lookup"><span data-stu-id="e8a54-236">Main Thread: repeat from step 2</span></span>

<span data-ttu-id="e8a54-237">Einige Images-Marker-Systeme bieten nur einen einzelnen Pixels-Speicherort (andere bieten die vollständigen Transformation in diesem Fall in diesem Abschnitt nicht benötigt wird), das ist gleichbedeutend mit einem Strahl von möglichen Speicherorten.</span><span class="sxs-lookup"><span data-stu-id="e8a54-237">Some image marker systems only provide a single pixel location (others provide the full transform in which case this section will not be needed), which equates to a ray of possible locations.</span></span> <span data-ttu-id="e8a54-238">Rufen Sie an zentraler Stelle 3d können dann mehrere Strahlung nutzen und finden das endgültige Ergebnis, indem deren ungefähre Schnittmenge.</span><span class="sxs-lookup"><span data-stu-id="e8a54-238">To get to a single 3d location we can then leverage multiple rays and find the final result by their approximate intersection.</span></span> <span data-ttu-id="e8a54-239">Zu diesem Zweck müssen Sie Folgendes ausführen:</span><span class="sxs-lookup"><span data-stu-id="e8a54-239">To do this you'll need to:</span></span>
1. <span data-ttu-id="e8a54-240">Abrufen einer Schleife, die jetzt mehrere Kamera Abbilder erfassen</span><span class="sxs-lookup"><span data-stu-id="e8a54-240">Get a loop going collecting multiple camera images</span></span>
2. <span data-ttu-id="e8a54-241">Hier finden Sie das entsprechende Feature Punkte und deren Strahlung world</span><span class="sxs-lookup"><span data-stu-id="e8a54-241">Find the associated feature points, and their world rays</span></span>
3. <span data-ttu-id="e8a54-242">Wenn Sie ein Wörterbuch von Features, mit mehreren Welt Strahlung, haben können Sie den folgenden Code, um für die Schnittmenge dieser Strahlung zu lösen:</span><span class="sxs-lookup"><span data-stu-id="e8a54-242">When you have a dictionary of features, each with multiple world rays, you can use the following code to solve for the intersection of those rays:</span></span>

```
public static Vector3 ClosestPointBetweenRays(
   Vector3 point1, Vector3 normalizedDirection1,
   Vector3 point2, Vector3 normalizedDirection2) {
   float directionProjection = Vector3.Dot(normalizedDirection1, normalizedDirection2);
   if (directionProjection == 1) {
     return point1; // parallel lines
   }
   float projection1 = Vector3.Dot(point2 - point1, normalizedDirection1);
   float projection2 = Vector3.Dot(point2 - point1, normalizedDirection2);
   float distanceAlongLine1 = (projection1 - directionProjection * projection2) / (1 - directionProjection * directionProjection);
   float distanceAlongLine2 = (projection2 - directionProjection * projection1) / (directionProjection * directionProjection - 1);
   Vector3 pointOnLine1 = point1 + distanceAlongLine1 * normalizedDirection1;
   Vector3 pointOnLine2 = point2 + distanceAlongLine2 * normalizedDirection2;
   return Vector3.Lerp(pointOnLine2, pointOnLine1, 0.5f);
 }
```

<span data-ttu-id="e8a54-243">Wenn mindestens zwei überwachte Tag-Standorten, können Sie eine modelled Szene entsprechend das aktuellen Benutzer-Szenario positionieren.</span><span class="sxs-lookup"><span data-stu-id="e8a54-243">Given two or more tracked tag locations, you can position a modelled scene to fit the users current scenario.</span></span> <span data-ttu-id="e8a54-244">Wenn Sie Schwerkraft wird davon ausgegangen, müssen Sie drei Tags stellen dafür.</span><span class="sxs-lookup"><span data-stu-id="e8a54-244">If you can't assume gravity, then you'll need three tag locations.</span></span> <span data-ttu-id="e8a54-245">In vielen Fällen, die wir verwenden ein einfaches Farbschema, in dem weiße Kugeln in Echtzeit darstellen, nachverfolgt Tag-Standorte, und blaue Kugeln modelliert Tag-Orte darstellen, dadurch kann der Benutzer an der die Ausrichtung Qualität visuell zu messen.</span><span class="sxs-lookup"><span data-stu-id="e8a54-245">In many cases we use a simple color scheme where white spheres represent real-time tracked tag locations, and blue spheres represent modelled tag locations, this allows the user to visually gauge the alignment quality.</span></span> <span data-ttu-id="e8a54-246">Es wird davon ausgegangen folgende Setup alle unsere Anwendungen:</span><span class="sxs-lookup"><span data-stu-id="e8a54-246">We assume the following setup in all our applications:</span></span>
* <span data-ttu-id="e8a54-247">Mindestens zwei modelliert Tag-Standorten</span><span class="sxs-lookup"><span data-stu-id="e8a54-247">Two or more modelled tag locations</span></span>
* <span data-ttu-id="e8a54-248">Eine "Kalibrierung Raum" auf, das in der Szene das übergeordnete Element der tags</span><span class="sxs-lookup"><span data-stu-id="e8a54-248">One 'calibration space' which in the scene is the parent of the tags</span></span>
* <span data-ttu-id="e8a54-249">Bezeichner der Kamera-Funktion</span><span class="sxs-lookup"><span data-stu-id="e8a54-249">Camera feature identifier</span></span>
* <span data-ttu-id="e8a54-250">Verhalten, das verschiebt Bereich Kalibrierung der Anpassung an die modelled Tags mit den Tags in Echtzeit (wir sind darauf achten, die den übergeordneten Bereich, nicht die modelled Marker selbst zu verschieben, da andere Connect Positionen bezogen auf sie ist).</span><span class="sxs-lookup"><span data-stu-id="e8a54-250">Behavior which moves the calibration space to align the modelled tags with the real-time tags (we are careful to move the parent space, not the modelled markers themselves, because other connect is positions relative to them).</span></span>

```
// In the two tags case:
 Vector3 idealDelta = (realTags[1].EstimatedWorldPos - realTags[0].EstimatedWorldPos);
 Vector3 curDelta = (modelledTags[1].transform.position - modelledTags[0].transform.position);
 if (IsAssumeGravity) {
   idealDelta.y = 0;
   curDelta.y = 0;
 }
 Quaternion deltaRot = Quaternion.FromToRotation(curDelta, idealDelta);
 trans.rotation = Quaternion.LookRotation(deltaRot * trans.forward, trans.up);
 trans.position += realTags[0].EstimatedWorldPos - modelledTags[0].transform.position;
```

### <a name="track-or-identify-tagged-stationary-or-moving-real-world-objectsfaces-using-leds-or-other-recognizer-libraries"></a><span data-ttu-id="e8a54-251">Nachverfolgen oder stationär markiert zu identifizieren oder beweglichen reale Objekte/Gesichtern, LEDs oder andere Bibliotheken Erkennung</span><span class="sxs-lookup"><span data-stu-id="e8a54-251">Track or Identify Tagged Stationary or Moving real-world objects/faces using LEDs or other recognizer libraries</span></span>

<span data-ttu-id="e8a54-252">Beispiele:</span><span class="sxs-lookup"><span data-stu-id="e8a54-252">Examples:</span></span>
* <span data-ttu-id="e8a54-253">Industrielle Roboter mit LEDs (oder QR-Codes für das Verschieben von langsamer Objekte)</span><span class="sxs-lookup"><span data-stu-id="e8a54-253">Industrial robots with LEDs (or QR codes for slower moving objects)</span></span>
* <span data-ttu-id="e8a54-254">Identifizierung und die Erkennung von Objekten im Raum</span><span class="sxs-lookup"><span data-stu-id="e8a54-254">Identify and recognize objects in the room</span></span>
* <span data-ttu-id="e8a54-255">Identifizierung und die Erkennung von Personen im Raum (z. B. direkte holographic Kontaktkarten in Gesichtern)</span><span class="sxs-lookup"><span data-stu-id="e8a54-255">Identify and recognize people in the room (e.g. place holographic contact cards over faces)</span></span>

## <a name="see-also"></a><span data-ttu-id="e8a54-256">Siehe auch</span><span class="sxs-lookup"><span data-stu-id="e8a54-256">See also</span></span>
* [<span data-ttu-id="e8a54-257">Ausrichtbare Kamera in DirectX</span><span class="sxs-lookup"><span data-stu-id="e8a54-257">Locatable camera in DirectX</span></span>](locatable-camera-in-directx.md)
* [<span data-ttu-id="e8a54-258">Ausrichtbare Kamera in Unity</span><span class="sxs-lookup"><span data-stu-id="e8a54-258">Locatable camera in Unity</span></span>](locatable-camera-in-unity.md)
* [<span data-ttu-id="e8a54-259">Mixed Reality-Aufnahme</span><span class="sxs-lookup"><span data-stu-id="e8a54-259">Mixed reality capture</span></span>](mixed-reality-capture.md)
* [<span data-ttu-id="e8a54-260">Mixed Reality-Aufnahme für Entwickler</span><span class="sxs-lookup"><span data-stu-id="e8a54-260">Mixed reality capture for developers</span></span>](mixed-reality-capture-for-developers.md)
* [<span data-ttu-id="e8a54-261">Medienaufzeichnung Einführung</span><span class="sxs-lookup"><span data-stu-id="e8a54-261">Media capture introduction</span></span>](https://msdn.microsoft.com/library/windows/apps/mt243896.aspx)
* [<span data-ttu-id="e8a54-262">Beispiel zur nachverfolgung holographic gesichtserkennung</span><span class="sxs-lookup"><span data-stu-id="e8a54-262">Holographic face tracking sample</span></span>](https://github.com/Microsoft/Windows-universal-samples/tree/master/Samples/HolographicFaceTracking)
