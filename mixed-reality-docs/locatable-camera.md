---
title: Ausrichtbare Kamera
description: Allgemeine Informationen zu der hololens-Front-Kamera, ihrer Funktionsweise und den Profilen und Auflösungen, die Entwicklern zur Verfügung stehen.
author: cdedmonds
ms.author: wguyman
ms.date: 06/12/2019
ms.topic: article
keywords: Kamera, hololens, Farbkamera, Vorderseite, hololens 2, CV, Maschinelles sehen, Zeichen, Marker, QR-Code, QR, Foto, Video
ms.openlocfilehash: b8e9d926db09d277b3fde7572dd68257599c8d5e
ms.sourcegitcommit: 09d9fa153cd9072f60e33a5f83ced8167496fcd7
ms.translationtype: MT
ms.contentlocale: de-DE
ms.lasthandoff: 05/18/2020
ms.locfileid: "83520015"
---
# <a name="locatable-camera"></a><span data-ttu-id="a7505-104">Ausrichtbare Kamera</span><span class="sxs-lookup"><span data-stu-id="a7505-104">Locatable camera</span></span>

<span data-ttu-id="a7505-105">Hololens enthält eine weltweit eingebundene Kamera, die auf der Vorderseite des Geräts bereitgestellt wird. Dadurch können apps erkennen, was der Benutzer sieht.</span><span class="sxs-lookup"><span data-stu-id="a7505-105">HoloLens includes a world-facing camera mounted on the front of the device, which enables apps to see what the user sees.</span></span> <span data-ttu-id="a7505-106">Entwickler haben Zugriff auf und die Steuerung der Kamera, ebenso wie bei Farbkameras auf Smartphones, portables oder Desktops.</span><span class="sxs-lookup"><span data-stu-id="a7505-106">Developers have access to and control of the camera, just as they would for color cameras on smartphones, portables, or desktops.</span></span> <span data-ttu-id="a7505-107">Die gleichen universellen Windows [Media Capture](https://msdn.microsoft.com/library/windows/apps/windows.media.capture.mediacapture.aspx) -und Windows Media Foundation-APIs, die auf mobilen und Desktop-apps funktionieren, funktionieren in hololens.</span><span class="sxs-lookup"><span data-stu-id="a7505-107">The same universal windows [media capture](https://msdn.microsoft.com/library/windows/apps/windows.media.capture.mediacapture.aspx) and windows media foundation APIs that work on mobile and desktop work on HoloLens.</span></span> <span data-ttu-id="a7505-108">Unity [hat diese Windows-APIs ebenfalls umschließt](locatable-camera-in-unity.md) , um die einfache Verwendung der Kamera in hololens für Aufgaben wie das nehmen von regulären Fotos und Videos (mit oder ohne holograms) zu abstrahieren und die Position der Kamera in der Szene zu ermitteln.</span><span class="sxs-lookup"><span data-stu-id="a7505-108">Unity [has also wrapped these windows APIs](locatable-camera-in-unity.md) to abstract simple usage of the camera on HoloLens for tasks such as taking regular photos and videos (with or without holograms) and locating the camera's position in and perspective on the scene.</span></span>

## <a name="device-camera-information"></a><span data-ttu-id="a7505-109">Gerätekamera Informationen</span><span class="sxs-lookup"><span data-stu-id="a7505-109">Device camera information</span></span>

### <a name="hololens-first-generation"></a><span data-ttu-id="a7505-110">Hololens (erste Generation)</span><span class="sxs-lookup"><span data-stu-id="a7505-110">HoloLens (first-generation)</span></span>

* <span data-ttu-id="a7505-111">Mit dem automatischen Leerraum, dem automatischen verfügbar machen und der Pipeline für die vollständige Bildverarbeitung fixierte Foto-/Video-Kamera (PV).</span><span class="sxs-lookup"><span data-stu-id="a7505-111">Fixed focus photo/video (PV) camera with auto white balance, auto exposure, and full image processing pipeline.</span></span>
* <span data-ttu-id="a7505-112">Die Welt der weißen Datenschutz wird immer dann beleuchtet, wenn die Kamera aktiv ist.</span><span class="sxs-lookup"><span data-stu-id="a7505-112">White Privacy LED facing the world will illuminate whenever the camera is active</span></span>
* <span data-ttu-id="a7505-113">Die Kamera unterstützt die folgenden Modi (alle Modi sind 16:9-Seitenverhältnis) bei 30, 24, 20, 15 und 5 fps:</span><span class="sxs-lookup"><span data-stu-id="a7505-113">The camera supports the following modes (all modes are 16:9 aspect ratio) at 30, 24, 20, 15, and 5 fps:</span></span>

  |  <span data-ttu-id="a7505-114">Video</span><span class="sxs-lookup"><span data-stu-id="a7505-114">Video</span></span>  |  <span data-ttu-id="a7505-115">Vorschau</span><span class="sxs-lookup"><span data-stu-id="a7505-115">Preview</span></span>  |  <span data-ttu-id="a7505-116">Auch</span><span class="sxs-lookup"><span data-stu-id="a7505-116">Still</span></span>  |  <span data-ttu-id="a7505-117">Horizontales Feld der Ansicht (H-FOV)</span><span class="sxs-lookup"><span data-stu-id="a7505-117">Horizontal Field of View (H-FOV)</span></span> |  <span data-ttu-id="a7505-118">Empfohlene Verwendung</span><span class="sxs-lookup"><span data-stu-id="a7505-118">Suggested usage</span></span> | 
  |----------|----------|----------|----------|----------|
  |  <span data-ttu-id="a7505-119">1.280 x 720</span><span class="sxs-lookup"><span data-stu-id="a7505-119">1280x720</span></span> |  <span data-ttu-id="a7505-120">1.280 x 720</span><span class="sxs-lookup"><span data-stu-id="a7505-120">1280x720</span></span> |  <span data-ttu-id="a7505-121">1.280 x 720</span><span class="sxs-lookup"><span data-stu-id="a7505-121">1280x720</span></span> |  <span data-ttu-id="a7505-122">45deg</span><span class="sxs-lookup"><span data-stu-id="a7505-122">45deg</span></span>  |  <span data-ttu-id="a7505-123">(Standardmodus mit Videostabilisierung)</span><span class="sxs-lookup"><span data-stu-id="a7505-123">(default mode with video stabilization)</span></span> | 
  |  <span data-ttu-id="a7505-124">–</span><span class="sxs-lookup"><span data-stu-id="a7505-124">N/A</span></span> |  <span data-ttu-id="a7505-125">–</span><span class="sxs-lookup"><span data-stu-id="a7505-125">N/A</span></span> |  <span data-ttu-id="a7505-126">2048x1152</span><span class="sxs-lookup"><span data-stu-id="a7505-126">2048x1152</span></span> |  <span data-ttu-id="a7505-127">67deg</span><span class="sxs-lookup"><span data-stu-id="a7505-127">67deg</span></span> |  <span data-ttu-id="a7505-128">Bild mit der höchsten Auflösung</span><span class="sxs-lookup"><span data-stu-id="a7505-128">Highest resolution still image</span></span> | 
  |  <span data-ttu-id="a7505-129">1408x792</span><span class="sxs-lookup"><span data-stu-id="a7505-129">1408x792</span></span> |  <span data-ttu-id="a7505-130">1408x792</span><span class="sxs-lookup"><span data-stu-id="a7505-130">1408x792</span></span> |  <span data-ttu-id="a7505-131">1408x792</span><span class="sxs-lookup"><span data-stu-id="a7505-131">1408x792</span></span> |  <span data-ttu-id="a7505-132">48deg</span><span class="sxs-lookup"><span data-stu-id="a7505-132">48deg</span></span> |  <span data-ttu-id="a7505-133">Überprüfung (Padding) vor der Videostabilisierung</span><span class="sxs-lookup"><span data-stu-id="a7505-133">Overscan (padding) resolution before video stabilization</span></span> | 
  |  <span data-ttu-id="a7505-134">1344x756</span><span class="sxs-lookup"><span data-stu-id="a7505-134">1344x756</span></span> |  <span data-ttu-id="a7505-135">1344x756</span><span class="sxs-lookup"><span data-stu-id="a7505-135">1344x756</span></span> |  <span data-ttu-id="a7505-136">1344x756</span><span class="sxs-lookup"><span data-stu-id="a7505-136">1344x756</span></span> |  <span data-ttu-id="a7505-137">67deg</span><span class="sxs-lookup"><span data-stu-id="a7505-137">67deg</span></span> |  <span data-ttu-id="a7505-138">Großer FOV-Videomodus mit Overscan</span><span class="sxs-lookup"><span data-stu-id="a7505-138">Large FOV video mode with overscan</span></span> | 
  |  <span data-ttu-id="a7505-139">896x504</span><span class="sxs-lookup"><span data-stu-id="a7505-139">896x504</span></span> |  <span data-ttu-id="a7505-140">896x504</span><span class="sxs-lookup"><span data-stu-id="a7505-140">896x504</span></span> |  <span data-ttu-id="a7505-141">896x504</span><span class="sxs-lookup"><span data-stu-id="a7505-141">896x504</span></span> |  <span data-ttu-id="a7505-142">48deg</span><span class="sxs-lookup"><span data-stu-id="a7505-142">48deg</span></span> |  <span data-ttu-id="a7505-143">Niedriger Energie-/tieflösungmodus für Abbild Verarbeitungsaufgaben</span><span class="sxs-lookup"><span data-stu-id="a7505-143">Low power / Low resolution mode for image processing tasks</span></span> | 

### <a name="hololens-2"></a><span data-ttu-id="a7505-144">HoloLens 2</span><span class="sxs-lookup"><span data-stu-id="a7505-144">HoloLens 2</span></span>

* <span data-ttu-id="a7505-145">Auto-Fokus Foto/Video-Kamera (PV) mit automatischem Leerraum, automatischer Verfügbarkeit und vollständiger Bild Verarbeitungs Pipeline.</span><span class="sxs-lookup"><span data-stu-id="a7505-145">Auto-focus photo/video (PV) camera with auto white balance, auto exposure, and full image processing pipeline.</span></span>
* <span data-ttu-id="a7505-146">Die Welt der weißen Datenschutz wird immer dann beleuchtet, wenn die Kamera aktiv ist.</span><span class="sxs-lookup"><span data-stu-id="a7505-146">White Privacy LED facing the world will illuminate whenever the camera is active.</span></span>
* <span data-ttu-id="a7505-147">Hololens 2 unterstützt verschiedene Kameraprofile.</span><span class="sxs-lookup"><span data-stu-id="a7505-147">HoloLens 2 supports different camera profiles.</span></span> <span data-ttu-id="a7505-148">Erfahren Sie, wie [Sie Kamerafunktionen ermitteln und auswählen](https://docs.microsoft.com//windows/uwp/audio-video-camera/camera-profiles)können.</span><span class="sxs-lookup"><span data-stu-id="a7505-148">Learn how to [discover and select camera capabilities](https://docs.microsoft.com//windows/uwp/audio-video-camera/camera-profiles).</span></span>
* <span data-ttu-id="a7505-149">Die Kamera unterstützt die folgenden Profile und Auflösungen (alle Video Modi sind 16:9-Seitenverhältnis):</span><span class="sxs-lookup"><span data-stu-id="a7505-149">The camera supports the following profiles and resolutions (all video modes are 16:9 aspect ratio):</span></span>
  
  | <span data-ttu-id="a7505-150">Profil</span><span class="sxs-lookup"><span data-stu-id="a7505-150">Profile</span></span>                                         | <span data-ttu-id="a7505-151">Video</span><span class="sxs-lookup"><span data-stu-id="a7505-151">Video</span></span>     | <span data-ttu-id="a7505-152">Vorschau</span><span class="sxs-lookup"><span data-stu-id="a7505-152">Preview</span></span>   | <span data-ttu-id="a7505-153">Auch</span><span class="sxs-lookup"><span data-stu-id="a7505-153">Still</span></span>     | <span data-ttu-id="a7505-154">Frameraten</span><span class="sxs-lookup"><span data-stu-id="a7505-154">Frame rates</span></span> | <span data-ttu-id="a7505-155">Horizontales Feld der Ansicht (H-FOV)</span><span class="sxs-lookup"><span data-stu-id="a7505-155">Horizontal Field of View (H-FOV)</span></span> | <span data-ttu-id="a7505-156">Empfohlene Verwendung</span><span class="sxs-lookup"><span data-stu-id="a7505-156">Suggested usage</span></span>                             |
  |-------------------------------------------------|-----------|-----------|-----------|-------------|----------------------------------|---------------------------------------------|
  | <span data-ttu-id="a7505-157">Legacy, 0 balancedvideoandphoto, 100</span><span class="sxs-lookup"><span data-stu-id="a7505-157">Legacy,0  BalancedVideoAndPhoto,100</span></span>             | <span data-ttu-id="a7505-158">2272x1278</span><span class="sxs-lookup"><span data-stu-id="a7505-158">2272x1278</span></span> | <span data-ttu-id="a7505-159">2272x1278</span><span class="sxs-lookup"><span data-stu-id="a7505-159">2272x1278</span></span> |           | <span data-ttu-id="a7505-160">15, 30</span><span class="sxs-lookup"><span data-stu-id="a7505-160">15,30</span></span>       | <span data-ttu-id="a7505-161">64,69</span><span class="sxs-lookup"><span data-stu-id="a7505-161">64.69</span></span>                            | <span data-ttu-id="a7505-162">Videoaufzeichnung mit hoher Qualität</span><span class="sxs-lookup"><span data-stu-id="a7505-162">High quality video recording</span></span>                |
  | <span data-ttu-id="a7505-163">Legacy, 0 balancedvideoandphoto, 100</span><span class="sxs-lookup"><span data-stu-id="a7505-163">Legacy,0  BalancedVideoAndPhoto,100</span></span>             | <span data-ttu-id="a7505-164">896x504</span><span class="sxs-lookup"><span data-stu-id="a7505-164">896x504</span></span>   | <span data-ttu-id="a7505-165">896x504</span><span class="sxs-lookup"><span data-stu-id="a7505-165">896x504</span></span>   |           | <span data-ttu-id="a7505-166">15, 30</span><span class="sxs-lookup"><span data-stu-id="a7505-166">15,30</span></span>       | <span data-ttu-id="a7505-167">64,69</span><span class="sxs-lookup"><span data-stu-id="a7505-167">64.69</span></span>                            | <span data-ttu-id="a7505-168">Vorschau Datenstrom für hochwertige Foto Erfassung</span><span class="sxs-lookup"><span data-stu-id="a7505-168">Preview stream for high quality photo capture</span></span> |
  | <span data-ttu-id="a7505-169">Legacy, 0 balancedvideoandphoto, 100</span><span class="sxs-lookup"><span data-stu-id="a7505-169">Legacy,0  BalancedVideoAndPhoto,100</span></span>             |           |           | <span data-ttu-id="a7505-170">3904x2196</span><span class="sxs-lookup"><span data-stu-id="a7505-170">3904x2196</span></span> |             | <span data-ttu-id="a7505-171">64,69</span><span class="sxs-lookup"><span data-stu-id="a7505-171">64.69</span></span>                            | <span data-ttu-id="a7505-172">Foto Erfassung mit hoher Qualität</span><span class="sxs-lookup"><span data-stu-id="a7505-172">High quality photo capture</span></span>                  |
  | <span data-ttu-id="a7505-173">Balancedvideoandphoto, 120</span><span class="sxs-lookup"><span data-stu-id="a7505-173">BalancedVideoAndPhoto,120</span></span>                       | <span data-ttu-id="a7505-174">1952x1100</span><span class="sxs-lookup"><span data-stu-id="a7505-174">1952x1100</span></span> | <span data-ttu-id="a7505-175">1952x1100</span><span class="sxs-lookup"><span data-stu-id="a7505-175">1952x1100</span></span> | <span data-ttu-id="a7505-176">1952x1100</span><span class="sxs-lookup"><span data-stu-id="a7505-176">1952x1100</span></span> | <span data-ttu-id="a7505-177">15, 30</span><span class="sxs-lookup"><span data-stu-id="a7505-177">15,30</span></span>       | <span data-ttu-id="a7505-178">64,69</span><span class="sxs-lookup"><span data-stu-id="a7505-178">64.69</span></span>                            | <span data-ttu-id="a7505-179">Szenarios mit langer Laufzeit</span><span class="sxs-lookup"><span data-stu-id="a7505-179">Long duration scenarios</span></span>                     |
  | <span data-ttu-id="a7505-180">Balancedvideoandphoto, 120</span><span class="sxs-lookup"><span data-stu-id="a7505-180">BalancedVideoAndPhoto,120</span></span>                       | <span data-ttu-id="a7505-181">1504x846</span><span class="sxs-lookup"><span data-stu-id="a7505-181">1504x846</span></span>  | <span data-ttu-id="a7505-182">1504x846</span><span class="sxs-lookup"><span data-stu-id="a7505-182">1504x846</span></span>  |           | <span data-ttu-id="a7505-183">15, 30</span><span class="sxs-lookup"><span data-stu-id="a7505-183">15,30</span></span>       | <span data-ttu-id="a7505-184">64,69</span><span class="sxs-lookup"><span data-stu-id="a7505-184">64.69</span></span>                            | <span data-ttu-id="a7505-185">Szenarios mit langer Laufzeit</span><span class="sxs-lookup"><span data-stu-id="a7505-185">Long duration scenarios</span></span>                     |
  | <span data-ttu-id="a7505-186">Videokonferenzen, 100</span><span class="sxs-lookup"><span data-stu-id="a7505-186">VideoConferencing,100</span></span>                           | <span data-ttu-id="a7505-187">1952x1100</span><span class="sxs-lookup"><span data-stu-id="a7505-187">1952x1100</span></span> | <span data-ttu-id="a7505-188">1952x1100</span><span class="sxs-lookup"><span data-stu-id="a7505-188">1952x1100</span></span> | <span data-ttu-id="a7505-189">1952x1100</span><span class="sxs-lookup"><span data-stu-id="a7505-189">1952x1100</span></span> | <span data-ttu-id="a7505-190">15, 30, 60</span><span class="sxs-lookup"><span data-stu-id="a7505-190">15,30,60</span></span>    | <span data-ttu-id="a7505-191">64,69</span><span class="sxs-lookup"><span data-stu-id="a7505-191">64.69</span></span>                            | <span data-ttu-id="a7505-192">Video Konferenzen, Szenarios mit langer Laufzeit</span><span class="sxs-lookup"><span data-stu-id="a7505-192">Video conferencing, long duration scenarios</span></span> |
  | <span data-ttu-id="a7505-193">Videokonferenzen, 100</span><span class="sxs-lookup"><span data-stu-id="a7505-193">Videoconferencing,100</span></span>                           | <span data-ttu-id="a7505-194">1504x846</span><span class="sxs-lookup"><span data-stu-id="a7505-194">1504x846</span></span>  | <span data-ttu-id="a7505-195">1504x846</span><span class="sxs-lookup"><span data-stu-id="a7505-195">1504x846</span></span>  |           | <span data-ttu-id="a7505-196">5, 15, 30, 60</span><span class="sxs-lookup"><span data-stu-id="a7505-196">5,15,30,60</span></span>  | <span data-ttu-id="a7505-197">64,69</span><span class="sxs-lookup"><span data-stu-id="a7505-197">64.69</span></span>                            | <span data-ttu-id="a7505-198">Video Konferenzen, Szenarios mit langer Laufzeit</span><span class="sxs-lookup"><span data-stu-id="a7505-198">Video conferencing, long duration scenarios</span></span> |
  | <span data-ttu-id="a7505-199">Videoconferencing, 100 balancedvideoandphoto, 120</span><span class="sxs-lookup"><span data-stu-id="a7505-199">Videoconferencing,100 BalancedVideoAndPhoto,120</span></span> | <span data-ttu-id="a7505-200">1920x1080</span><span class="sxs-lookup"><span data-stu-id="a7505-200">1920x1080</span></span> | <span data-ttu-id="a7505-201">1920x1080</span><span class="sxs-lookup"><span data-stu-id="a7505-201">1920x1080</span></span> | <span data-ttu-id="a7505-202">1920x1080</span><span class="sxs-lookup"><span data-stu-id="a7505-202">1920x1080</span></span> | <span data-ttu-id="a7505-203">15, 30</span><span class="sxs-lookup"><span data-stu-id="a7505-203">15,30</span></span>       | <span data-ttu-id="a7505-204">64,69</span><span class="sxs-lookup"><span data-stu-id="a7505-204">64.69</span></span>                            | <span data-ttu-id="a7505-205">Video Konferenzen, Szenarios mit langer Laufzeit</span><span class="sxs-lookup"><span data-stu-id="a7505-205">Video conferencing, long duration scenarios</span></span> |
  | <span data-ttu-id="a7505-206">Videoconferencing, 100 balancedvideoandphoto, 120</span><span class="sxs-lookup"><span data-stu-id="a7505-206">Videoconferencing,100 BalancedVideoAndPhoto,120</span></span> | <span data-ttu-id="a7505-207">1.280 x 720</span><span class="sxs-lookup"><span data-stu-id="a7505-207">1280x720</span></span>  | <span data-ttu-id="a7505-208">1.280 x 720</span><span class="sxs-lookup"><span data-stu-id="a7505-208">1280x720</span></span>  | <span data-ttu-id="a7505-209">1.280 x 720</span><span class="sxs-lookup"><span data-stu-id="a7505-209">1280x720</span></span>  | <span data-ttu-id="a7505-210">15, 30</span><span class="sxs-lookup"><span data-stu-id="a7505-210">15,30</span></span>       | <span data-ttu-id="a7505-211">64,69</span><span class="sxs-lookup"><span data-stu-id="a7505-211">64.69</span></span>                            | <span data-ttu-id="a7505-212">Video Konferenzen, Szenarios mit langer Laufzeit</span><span class="sxs-lookup"><span data-stu-id="a7505-212">Video conferencing, long duration scenarios</span></span> |
  | <span data-ttu-id="a7505-213">Videoconferencing, 100 balancedvideoandphoto, 120</span><span class="sxs-lookup"><span data-stu-id="a7505-213">Videoconferencing,100 BalancedVideoAndPhoto,120</span></span> | <span data-ttu-id="a7505-214">1128x636</span><span class="sxs-lookup"><span data-stu-id="a7505-214">1128x636</span></span>  |           |           | <span data-ttu-id="a7505-215">15, 30</span><span class="sxs-lookup"><span data-stu-id="a7505-215">15,30</span></span>       | <span data-ttu-id="a7505-216">64,69</span><span class="sxs-lookup"><span data-stu-id="a7505-216">64.69</span></span>                            | <span data-ttu-id="a7505-217">Video Konferenzen, Szenarios mit langer Laufzeit</span><span class="sxs-lookup"><span data-stu-id="a7505-217">Video conferencing, long duration scenarios</span></span> |
  | <span data-ttu-id="a7505-218">Videoconferencing, 100 balancedvideoandphoto, 120</span><span class="sxs-lookup"><span data-stu-id="a7505-218">Videoconferencing,100 BalancedVideoAndPhoto,120</span></span> | <span data-ttu-id="a7505-219">960 × 540</span><span class="sxs-lookup"><span data-stu-id="a7505-219">960x540</span></span>   |           |           | <span data-ttu-id="a7505-220">15, 30</span><span class="sxs-lookup"><span data-stu-id="a7505-220">15,30</span></span>       | <span data-ttu-id="a7505-221">64,69</span><span class="sxs-lookup"><span data-stu-id="a7505-221">64.69</span></span>                            | <span data-ttu-id="a7505-222">Video Konferenzen, Szenarios mit langer Laufzeit</span><span class="sxs-lookup"><span data-stu-id="a7505-222">Video conferencing, long duration scenarios</span></span> |
  | <span data-ttu-id="a7505-223">Videoconferencing, 100 balancedvideoandphoto, 120</span><span class="sxs-lookup"><span data-stu-id="a7505-223">Videoconferencing,100 BalancedVideoAndPhoto,120</span></span> | <span data-ttu-id="a7505-224">760x428</span><span class="sxs-lookup"><span data-stu-id="a7505-224">760x428</span></span>   |           |           | <span data-ttu-id="a7505-225">15, 30</span><span class="sxs-lookup"><span data-stu-id="a7505-225">15,30</span></span>       | <span data-ttu-id="a7505-226">64,69</span><span class="sxs-lookup"><span data-stu-id="a7505-226">64.69</span></span>                            | <span data-ttu-id="a7505-227">Video Konferenzen, Szenarios mit langer Laufzeit</span><span class="sxs-lookup"><span data-stu-id="a7505-227">Video conferencing, long duration scenarios</span></span> |
  | <span data-ttu-id="a7505-228">Videoconferencing, 100 balancedvideoandphoto, 120</span><span class="sxs-lookup"><span data-stu-id="a7505-228">Videoconferencing,100 BalancedVideoAndPhoto,120</span></span> | <span data-ttu-id="a7505-229">640x360</span><span class="sxs-lookup"><span data-stu-id="a7505-229">640x360</span></span>   |           |           | <span data-ttu-id="a7505-230">15, 30</span><span class="sxs-lookup"><span data-stu-id="a7505-230">15,30</span></span>       | <span data-ttu-id="a7505-231">64,69</span><span class="sxs-lookup"><span data-stu-id="a7505-231">64.69</span></span>                            | <span data-ttu-id="a7505-232">Video Konferenzen, Szenarios mit langer Laufzeit</span><span class="sxs-lookup"><span data-stu-id="a7505-232">Video conferencing, long duration scenarios</span></span> |
  | <span data-ttu-id="a7505-233">Videoconferencing, 100 balancedvideoandphoto, 120</span><span class="sxs-lookup"><span data-stu-id="a7505-233">Videoconferencing,100 BalancedVideoAndPhoto,120</span></span> | <span data-ttu-id="a7505-234">500 x 282</span><span class="sxs-lookup"><span data-stu-id="a7505-234">500x282</span></span>   |           |           | <span data-ttu-id="a7505-235">15, 30</span><span class="sxs-lookup"><span data-stu-id="a7505-235">15,30</span></span>       | <span data-ttu-id="a7505-236">64,69</span><span class="sxs-lookup"><span data-stu-id="a7505-236">64.69</span></span>                            | <span data-ttu-id="a7505-237">Video Konferenzen, Szenarios mit langer Laufzeit</span><span class="sxs-lookup"><span data-stu-id="a7505-237">Video conferencing, long duration scenarios</span></span> |
  | <span data-ttu-id="a7505-238">Videoconferencing, 100 balancedvideoandphoto, 120</span><span class="sxs-lookup"><span data-stu-id="a7505-238">Videoconferencing,100 BalancedVideoAndPhoto,120</span></span> | <span data-ttu-id="a7505-239">424x240</span><span class="sxs-lookup"><span data-stu-id="a7505-239">424x240</span></span>   |           |           | <span data-ttu-id="a7505-240">15, 30</span><span class="sxs-lookup"><span data-stu-id="a7505-240">15,30</span></span>       | <span data-ttu-id="a7505-241">64,69</span><span class="sxs-lookup"><span data-stu-id="a7505-241">64.69</span></span>                            | <span data-ttu-id="a7505-242">Video Konferenzen, Szenarios mit langer Laufzeit</span><span class="sxs-lookup"><span data-stu-id="a7505-242">Video conferencing, long duration scenarios</span></span> |

>[!NOTE]
><span data-ttu-id="a7505-243">Kunden können die [gemischte Reality-Erfassung](mixed-reality-capture.md) nutzen, um Videos oder Fotos Ihrer APP zu erstellen, die Hologramme und Videostabilisierung enthalten.</span><span class="sxs-lookup"><span data-stu-id="a7505-243">Customers can leverage [mixed reality capture](mixed-reality-capture.md) to take videos or photos of your app, which include holograms and video stabilization.</span></span>
>
><span data-ttu-id="a7505-244">Als Entwickler sollten Sie beim Erstellen Ihrer APP berücksichtigen, dass Sie beim Erfassen von Inhalten so gut wie möglich aussehen sollten.</span><span class="sxs-lookup"><span data-stu-id="a7505-244">As a developer, there are considerations you should take into account when creating your app if you want it to look as good as possible when a customer captures content.</span></span> <span data-ttu-id="a7505-245">Sie können die gemischte Reality-Erfassung auch direkt in Ihrer APP aktivieren (und anpassen).</span><span class="sxs-lookup"><span data-stu-id="a7505-245">You can also enable (and customize) mixed reality capture from directly within your app.</span></span> <span data-ttu-id="a7505-246">Weitere Informationen finden Sie unter [Mixed Reality Capture für Entwickler](mixed-reality-capture-for-developers.md).</span><span class="sxs-lookup"><span data-stu-id="a7505-246">Learn more at [mixed reality capture for developers](mixed-reality-capture-for-developers.md).</span></span>

## <a name="locating-the-device-camera-in-the-world"></a><span data-ttu-id="a7505-247">Auffinden der Gerätekamera weltweit</span><span class="sxs-lookup"><span data-stu-id="a7505-247">Locating the Device Camera in the World</span></span>

<span data-ttu-id="a7505-248">Wenn hololens Fotos und Videos aufnimmt, beinhalten die erfassten Frames den Ort der Kamera auf der Welt und das Modell der Kamera.</span><span class="sxs-lookup"><span data-stu-id="a7505-248">When HoloLens takes photos and videos, the captured frames include the location of the camera in the world, as well as the lens model of the camera.</span></span> <span data-ttu-id="a7505-249">Dies ermöglicht es Anwendungen, die Position der Kamera in der realen Welt für erweiterte Abbild Erstellungs Szenarios zu untersuchen.</span><span class="sxs-lookup"><span data-stu-id="a7505-249">This allows applications to reason about the position of the camera in the real world for augmented imaging scenarios.</span></span> <span data-ttu-id="a7505-250">Entwickler können Ihre eigenen Szenarien mithilfe Ihrer bevorzugten Bildverarbeitung oder Ihrer benutzerdefinierten Maschinelles Sehen-Bibliotheken kreativ gestalten.</span><span class="sxs-lookup"><span data-stu-id="a7505-250">Developers can creatively roll their own scenarios using their favorite image processing or custom computer vision libraries.</span></span>

<span data-ttu-id="a7505-251">"Kamera" an anderer Stelle in der hololens-Dokumentation bezieht sich auf die "virtuelle Spiel Kamera" (die Frustration, in der die APP rendert).</span><span class="sxs-lookup"><span data-stu-id="a7505-251">"Camera" elsewhere in HoloLens documentation may refer to the "virtual game camera" (the frustum the app renders to).</span></span> <span data-ttu-id="a7505-252">Sofern nicht anders angegeben, bezieht sich "Kamera" auf dieser Seite auf die tatsächliche RGB-Farbkamera.</span><span class="sxs-lookup"><span data-stu-id="a7505-252">Unless denoted otherwise, "camera" on this page refers to the real-world RGB color camera.</span></span>

### <a name="using-unity"></a><span data-ttu-id="a7505-253">Verwendung von Unity</span><span class="sxs-lookup"><span data-stu-id="a7505-253">Using Unity</span></span>

<span data-ttu-id="a7505-254">Befolgen Sie die Anweisungen im Artikel "cameraintrinsics" und "cameracoordinatesystem [" in Ihr](locatable-camera-in-unity.md) Anwendungs-/World-Koordinatensystem.</span><span class="sxs-lookup"><span data-stu-id="a7505-254">To go from the 'CameraIntrinsics' and 'CameraCoordinateSystem' to your application/world coordinate system, follow the instructions in the [Locatable camera in Unity](locatable-camera-in-unity.md) article.</span></span>  <span data-ttu-id="a7505-255">Cameratoworldmatrix wird automatisch von der photocaptureframe-Klasse bereitgestellt, sodass Sie sich keine Gedanken über die unten beschriebenen cameracoordinatesystem-Transformationen machen müssen.</span><span class="sxs-lookup"><span data-stu-id="a7505-255">CameraToWorldMatrix is automatically provided by PhotoCaptureFrame class, and so you don't need to worry about the CameraCoordinateSystem transforms discussed below.</span></span>

### <a name="using-mediaframereference"></a><span data-ttu-id="a7505-256">Verwenden von mediaframereferenzierung</span><span class="sxs-lookup"><span data-stu-id="a7505-256">Using MediaFrameReference</span></span>

<span data-ttu-id="a7505-257">Diese Anweisungen gelten, wenn Sie die [mediaframereferenzierungsklasse](https://docs.microsoft.com//uwp/api/windows.media.capture.frames.mediaframereference) zum Lesen von Bildframes von der Kamera verwenden.</span><span class="sxs-lookup"><span data-stu-id="a7505-257">These instructions apply if you are using the [MediaFrameReference](https://docs.microsoft.com//uwp/api/windows.media.capture.frames.mediaframereference) class to read image frames from the camera.</span></span>

<span data-ttu-id="a7505-258">Jeder Bild Rahmen (egal ob Foto oder Video) enthält ein [spatialcoordinatesystem](https://docs.microsoft.com//uwp/api/windows.perception.spatial.spatialcoordinatesystem) , das zum Zeitpunkt der Erfassung auf der Kamera verankert ist, auf die mit der [CoordinateSystem](https://docs.microsoft.com//uwp/api/windows.media.capture.frames.mediaframereference.coordinatesystem#Windows_Media_Capture_Frames_MediaFrameReference_CoordinateSystem) -Eigenschaft von [mediaframereferenziert](https://docs.microsoft.com//uwp/api/Windows.Media.Capture.Frames.MediaFrameReference)werden kann.</span><span class="sxs-lookup"><span data-stu-id="a7505-258">Each image frame (whether photo or video) includes a [SpatialCoordinateSystem](https://docs.microsoft.com//uwp/api/windows.perception.spatial.spatialcoordinatesystem) rooted at the camera at the time of capture, which can be accessed using the [CoordinateSystem](https://docs.microsoft.com//uwp/api/windows.media.capture.frames.mediaframereference.coordinatesystem#Windows_Media_Capture_Frames_MediaFrameReference_CoordinateSystem) property of your [MediaFrameReference](https://docs.microsoft.com//uwp/api/Windows.Media.Capture.Frames.MediaFrameReference).</span></span> <span data-ttu-id="a7505-259">Außerdem enthält jeder Frame eine Beschreibung des Kamera Zeichen Modells, das in der Eigenschaft [cameraintrinsics](https://docs.microsoft.com//uwp/api/windows.media.capture.frames.videomediaframe.cameraintrinsics#Windows_Media_Capture_Frames_VideoMediaFrame_CameraIntrinsics) zu finden ist.</span><span class="sxs-lookup"><span data-stu-id="a7505-259">In addition, each frame contains a description of the camera lens model, which can be found in the [CameraIntrinsics](https://docs.microsoft.com//uwp/api/windows.media.capture.frames.videomediaframe.cameraintrinsics#Windows_Media_Capture_Frames_VideoMediaFrame_CameraIntrinsics) property.</span></span> <span data-ttu-id="a7505-260">In der Regel definieren diese Transformationen für jedes Pixel einen Strahl in 3D-Raum, der den Pfad darstellt, der von den Photonen, die das Pixel erzeugt haben, übernommen wird.</span><span class="sxs-lookup"><span data-stu-id="a7505-260">Together, these transforms define for each pixel a ray in 3D space representing the path taken by the photons that produced the pixel.</span></span> <span data-ttu-id="a7505-261">Diese Strahlen können mit anderem Inhalt in der APP verknüpft werden, indem die Transformation aus dem Koordinatensystem des Frames in ein anderes Koordinatensystem (z. b. aus einem [stationären Verweis Rahmen](coordinate-systems.md#stationary-frame-of-reference)) bezogen wird.</span><span class="sxs-lookup"><span data-stu-id="a7505-261">These rays can be related to other content in the app by obtaining the transform from the frame's coordinate system to some other coordinate system (e.g. from a [stationary frame of reference](coordinate-systems.md#stationary-frame-of-reference)).</span></span> <span data-ttu-id="a7505-262">Zusammenfassend bietet jeder Bild Rahmen Folgendes:</span><span class="sxs-lookup"><span data-stu-id="a7505-262">To summarize, each image frame provides the following:</span></span>
* <span data-ttu-id="a7505-263">Pixel Daten (im Format RGB/NV12/JPEG/usw.)</span><span class="sxs-lookup"><span data-stu-id="a7505-263">Pixel Data (in RGB/NV12/JPEG/etc. format)</span></span>
* <span data-ttu-id="a7505-264">Ein [spatialcoordinatesystem](https://docs.microsoft.com//uwp/api/windows.perception.spatial.spatialcoordinatesystem) vom Speicherort der Erfassung</span><span class="sxs-lookup"><span data-stu-id="a7505-264">A [SpatialCoordinateSystem](https://docs.microsoft.com//uwp/api/windows.perception.spatial.spatialcoordinatesystem) from the location of capture</span></span>
* <span data-ttu-id="a7505-265">Eine [cameraintrinsics](https://docs.microsoft.com//uwp/api/windows.media.capture.frames.videomediaframe.cameraintrinsics#Windows_Media_Capture_Frames_VideoMediaFrame_CameraIntrinsics) -Klasse, die den Linsen Modus der Kamera enthält.</span><span class="sxs-lookup"><span data-stu-id="a7505-265">A [CameraIntrinsics](https://docs.microsoft.com//uwp/api/windows.media.capture.frames.videomediaframe.cameraintrinsics#Windows_Media_Capture_Frames_VideoMediaFrame_CameraIntrinsics) class containing the lens mode of the camera</span></span>

<span data-ttu-id="a7505-266">Das [holographicfacetracking-Beispiel](https://github.com/Microsoft/Windows-universal-samples/tree/master/Samples/HolographicFaceTracking) zeigt die relativ unkomplizierte Methode zum Abfragen der Transformation zwischen dem Koordinatensystem der Kamera und ihren eigenen Anwendungs Koordinatensystemen.</span><span class="sxs-lookup"><span data-stu-id="a7505-266">The [HolographicFaceTracking sample](https://github.com/Microsoft/Windows-universal-samples/tree/master/Samples/HolographicFaceTracking) shows the fairly straightforward way to query for the transform between the camera's coordinate system and your own application coordinate systems.</span></span>

### <a name="using-media-foundation"></a><span data-ttu-id="a7505-267">Verwenden von Media Foundation</span><span class="sxs-lookup"><span data-stu-id="a7505-267">Using Media Foundation</span></span>

<span data-ttu-id="a7505-268">Wenn Sie Media Foundation direkt zum Lesen von Bildframes von der Kamera verwenden, können Sie das [MFSampleExtension_CameraExtrinsics-Attribut](https://docs.microsoft.com/windows/win32/medfound/mfsampleextension-cameraextrinsics) jedes Frames und [MFSampleExtension_PinholeCameraIntrinsics-Attribut](https://docs.microsoft.com/windows/win32/medfound/mfsampleextension-pinholecameraintrinsics) verwenden, um die Kamera Rahmen in Bezug auf die anderen Koordinatensysteme Ihrer Anwendung zu lokalisieren, wie im folgenden Beispielcode gezeigt:</span><span class="sxs-lookup"><span data-stu-id="a7505-268">If you are using Media Foundation directly to read image frames from the camera, you can use each frame's [MFSampleExtension_CameraExtrinsics attribute](https://docs.microsoft.com/windows/win32/medfound/mfsampleextension-cameraextrinsics) and [MFSampleExtension_PinholeCameraIntrinsics attribute](https://docs.microsoft.com/windows/win32/medfound/mfsampleextension-pinholecameraintrinsics) to locate camera frames relative to your application's other coordinate systems, as shown in this sample code:</span></span>

```cpp
#include <winrt/windows.perception.spatial.preview.h>
#include <mfapi.h>
#include <mfidl.h>
 
using namespace winrt::Windows::Foundation;
using namespace winrt::Windows::Foundation::Numerics;
using namespace winrt::Windows::Perception;
using namespace winrt::Windows::Perception::Spatial;
using namespace winrt::Windows::Perception::Spatial::Preview;
 
class CameraFrameLocator
{
public:
    struct CameraFrameLocation
    {
        SpatialCoordinateSystem CoordinateSystem;
        float4x4 CameraViewToCoordinateSytemTransform;
        MFPinholeCameraIntrinsics Intrinsics;
    };
 
    std::optional<CameraFrameLocation> TryLocateCameraFrame(IMFSample* pSample)
    {
        MFCameraExtrinsics cameraExtrinsics;
        MFPinholeCameraIntrinsics cameraIntrinsics;
        UINT32 sizeCameraExtrinsics = 0;
        UINT32 sizeCameraIntrinsics = 0;
        UINT64 sampleTimeQpc = 0;
 
        // query sample for calibration and validate
        if (FAILED(pSample->GetUINT64(MFSampleExtension_DeviceTimestamp, &sampleTimeQpc)) ||
            FAILED(pSample->GetBlob(MFSampleExtension_CameraExtrinsics, (UINT8*)& cameraExtrinsics, sizeof(cameraExtrinsics), &sizeCameraExtrinsics)) ||
            FAILED(pSample->GetBlob(MFSampleExtension_PinholeCameraIntrinsics, (UINT8*)& cameraIntrinsics, sizeof(cameraIntrinsics), &sizeCameraIntrinsics)) ||
            (sizeCameraExtrinsics != sizeof(cameraExtrinsics)) ||
            (sizeCameraIntrinsics != sizeof(cameraIntrinsics)) ||
            (cameraExtrinsics.TransformCount == 0))
        {
            return std::nullopt;
        }
 
        // compute extrinsic transform
        const auto& calibratedTransform = cameraExtrinsics.CalibratedTransforms[0];
        const GUID& dynamicNodeId = calibratedTransform.CalibrationId;
        const float4x4 cameraToDynamicNode =
            make_float4x4_from_quaternion(quaternion{ calibratedTransform.Orientation.x, calibratedTransform.Orientation.y, calibratedTransform.Orientation.z, calibratedTransform.Orientation.w }) *
            make_float4x4_translation(calibratedTransform.Position.x, calibratedTransform.Position.y, calibratedTransform.Position.z);
 
        // update locator cache for dynamic node
        if (dynamicNodeId != m_currentDynamicNodeId || !m_locator)
        {
            m_locator = SpatialGraphInteropPreview::CreateLocatorForNode(dynamicNodeId);
            if (!m_locator)
            {
                return std::nullopt;
            }
 
            m_frameOfReference = m_locator.CreateAttachedFrameOfReferenceAtCurrentHeading();
            m_currentDynamicNodeId = dynamicNodeId;
        }
 
        // locate dynamic node
        auto timestamp = PerceptionTimestampHelper::FromSystemRelativeTargetTime(TimeSpanFrodmQpcTicks(sampleTimeQpc));
        auto coordinateSystem = m_frameOfReference.GetStationaryCoordinateSystemAtTimestamp(timestamp);
        auto location = m_locator.TryLocateAtTimestamp(timestamp, coordinateSystem);
        if (!location)
        {
            return std::nullopt;
        }
 
        const float4x4 dynamicNodeToCoordinateSystem = make_float4x4_from_quaternion(location.Orientation()) * make_float4x4_translation(location.Position());
 
        return CameraFrameLocation{ coordinateSystem, cameraToDynamicNode * dynamicNodeToCoordinateSystem, cameraIntrinsics };
    }
 
private:
    GUID m_currentDynamicNodeId{ GUID_NULL };
    SpatialLocator m_locator{ nullptr };
    SpatialLocatorAttachedFrameOfReference m_frameOfReference{ nullptr };
 
    // Convert a duration value from a source tick frequency to a destination tick frequency.
    static inline int64_t SourceDurationTicksToDestDurationTicks(int64_t sourceDurationInTicks, int64_t sourceTicksPerSecond, int64_t destTicksPerSecond)
    {
        int64_t whole = (sourceDurationInTicks / sourceTicksPerSecond) * destTicksPerSecond;                          // 'whole' is rounded down in the target time units.
        int64_t part = (sourceDurationInTicks % sourceTicksPerSecond) * destTicksPerSecond / sourceTicksPerSecond;    // 'part' is the remainder in the target time units.
        return whole + part;
    }
 
    static inline TimeSpan TimeSpanFromQpcTicks(int64_t qpcTicks)
    {
        static const int64_t qpcFrequency = []
        {
            LARGE_INTEGER frequency;
            QueryPerformanceFrequency(&frequency);
            return frequency.QuadPart;
        }();
 
        return TimeSpan{ SourceDurationTicksToDestDurationTicks(qpcTicks, qpcFrequency, winrt::clock::period::den) / winrt::clock::period::num };
    }
};
```

### <a name="distortion-error"></a><span data-ttu-id="a7505-269">Verzerrungs Fehler</span><span class="sxs-lookup"><span data-stu-id="a7505-269">Distortion Error</span></span>

<span data-ttu-id="a7505-270">Bei hololens sind das Video und die bildstreams in der Bild Verarbeitungs Pipeline des Systems unverzerrt, bevor die Frames der Anwendung zur Verfügung gestellt werden (der vorschaustream enthält die ursprünglichen verzerrten Rahmen).</span><span class="sxs-lookup"><span data-stu-id="a7505-270">On HoloLens, the video and still image streams are undistorted in the system's image processing pipeline before the frames are made available to the application (the preview stream contains the original distorted frames).</span></span> <span data-ttu-id="a7505-271">Da nur die cameraintrinsics verfügbar gemacht werden, müssen Anwendungen davon ausgehen, dass Bild Rahmen eine perfekte Kamera darstellen.</span><span class="sxs-lookup"><span data-stu-id="a7505-271">Because only the CameraIntrinsics are made available, applications must assume image frames represent a perfect pinhole camera.</span></span>

<span data-ttu-id="a7505-272">Bei hololens (First-Generation) kann die unzerungs Funktion im Bildprozessor bei Verwendung von "cameraintrinsics" in den Frame-Metadaten weiterhin einen Fehler von bis zu 10 Pixeln hinterlassen.</span><span class="sxs-lookup"><span data-stu-id="a7505-272">On HoloLens (first-generation), the undistortion function in the image processor may still leave an error of up to 10 pixels when using the CameraIntrinsics in the frame metadata.</span></span> <span data-ttu-id="a7505-273">In vielen Anwendungsfällen ist dieser Fehler nicht von Bedeutung. Wenn Sie z. b. Hologramme an realen Poster/Markierungen ausrichten, sehen Sie sich beispielsweise einen <10px-Offset an (ungefähr 11mm für holograms, der 2 Meter entfernt ist), könnte dieser Fehler bei der Verzerrung auftreten.</span><span class="sxs-lookup"><span data-stu-id="a7505-273">In many use cases, this error will not matter, but if you are aligning holograms to real world posters/markers, for example, and you notice a <10px offset (roughly 11mm for holograms positioned 2 meters away), this distortion error could be the cause.</span></span> 

## <a name="locatable-camera-usage-scenarios"></a><span data-ttu-id="a7505-274">Szenarios für die verwendbare Verwendung von Kameras</span><span class="sxs-lookup"><span data-stu-id="a7505-274">Locatable Camera Usage Scenarios</span></span>

### <a name="show-a-photo-or-video-in-the-world-where-it-was-captured"></a><span data-ttu-id="a7505-275">Foto oder Video in der Welt anzeigen, in der es aufgezeichnet wurde</span><span class="sxs-lookup"><span data-stu-id="a7505-275">Show a photo or video in the world where it was captured</span></span>

<span data-ttu-id="a7505-276">Die Gerätekamera Rahmen verfügen über eine "Kamera-an-Welt"-Transformation, die verwendet werden kann, um genau anzuzeigen, wo das Gerät war, als das Abbild erstellt wurde.</span><span class="sxs-lookup"><span data-stu-id="a7505-276">The Device Camera frames come with a "Camera To World" transform, that can be used to show exactly where the device was when the image was taken.</span></span> <span data-ttu-id="a7505-277">Beispielsweise können Sie an dieser Stelle ein kleines Holographic-Symbol positionieren (cameratoworld. multiplypoint (Vector3. Zero)) und sogar einen kleinen Pfeil in der Richtung zeichnen, in der die Kamera angezeigt wurde (cameratoworld. multiplyvector (Vector3. Forward)).</span><span class="sxs-lookup"><span data-stu-id="a7505-277">For example, you could position a small holographic icon at this location (CameraToWorld.MultiplyPoint(Vector3.zero)) and even draw a little arrow in the direction that the camera was facing (CameraToWorld.MultiplyVector(Vector3.forward)).</span></span>

### <a name="tag--pattern--poster--object-tracking"></a><span data-ttu-id="a7505-278">Tag/Muster/Poster/Objektverfolgung</span><span class="sxs-lookup"><span data-stu-id="a7505-278">Tag / Pattern / Poster / Object Tracking</span></span>

<span data-ttu-id="a7505-279">Viele Mixed Reality-Anwendungen verwenden ein erkennbares Bild oder visuelles Muster, um einen standbybaren Punkt im Raum zu schaffen.</span><span class="sxs-lookup"><span data-stu-id="a7505-279">Many mixed reality applications use a recognizable image or visual pattern to create a trackable point in space.</span></span> <span data-ttu-id="a7505-280">Diese wird dann zum Rendering von Objekten in Relation zu diesem Punkt oder zum Erstellen eines bekannten Speicher Orts verwendet.</span><span class="sxs-lookup"><span data-stu-id="a7505-280">This is then used to render objects relative to that point or create a known location.</span></span> <span data-ttu-id="a7505-281">Einige Verwendungsmöglichkeiten für hololens sind u. a. die Suche nach einem realen Objekt, das mit der Verwendung von "(z. b. einem TV-Monitor mit einem QR-Code) gekennzeichnet ist, das Platzieren von holograms über das Produkt und das visuelle koppeln mit Geräten, die für die Kommunikation mit hololens über Wi-Fi eingerichtet wurden.</span><span class="sxs-lookup"><span data-stu-id="a7505-281">Some uses for HoloLens include finding a real world object tagged with fiducials (e.g. a TV monitor with a QR code), placing holograms over fiducials, and visually pairing with non-HoloLens devices like tablets that have been setup to communicate with HoloLens via Wi-Fi.</span></span>

<span data-ttu-id="a7505-282">Um ein visuelles Muster zu erkennen und dieses Objekt dann in den Anwendungs Raum zu versetzen, benötigen Sie einige Dinge:</span><span class="sxs-lookup"><span data-stu-id="a7505-282">To recognize a visual pattern, and then place that object in the applications world space, you'll need a few things:</span></span>
1. <span data-ttu-id="a7505-283">Ein Bildmuster Erkennungs-Toolkit, z. b. QR-Code, AR-Tags, Gesichts Finder, Zirkel Tracker, OCR usw.</span><span class="sxs-lookup"><span data-stu-id="a7505-283">An image pattern recognition toolkit, such as QR code, AR tags, face finder, circle trackers, OCR etc.</span></span>
2. <span data-ttu-id="a7505-284">Bild Rahmen zur Laufzeit erfassen und an die Erkennungs Schicht übergeben</span><span class="sxs-lookup"><span data-stu-id="a7505-284">Collect image frames at runtime, and pass them to the recognition layer</span></span>
3. <span data-ttu-id="a7505-285">Entprojizieren Sie Ihre Image Positionen wieder in die Welt Positionen oder wahrscheinlich weltweit.</span><span class="sxs-lookup"><span data-stu-id="a7505-285">Unproject their image locations back into world positions, or likely world rays.</span></span> 
4. <span data-ttu-id="a7505-286">Positionieren Sie Ihre virtuellen Modelle an den Standorten der Welt.</span><span class="sxs-lookup"><span data-stu-id="a7505-286">Position your virtual models over these world locations</span></span>

<span data-ttu-id="a7505-287">Einige wichtige Bild Verarbeitungs Links:</span><span class="sxs-lookup"><span data-stu-id="a7505-287">Some important image processing links:</span></span>
* [<span data-ttu-id="a7505-288">OpenCV</span><span class="sxs-lookup"><span data-stu-id="a7505-288">OpenCV</span></span>](https://opencv.org/)
* [<span data-ttu-id="a7505-289">QR-Tags</span><span class="sxs-lookup"><span data-stu-id="a7505-289">QR Tags</span></span>](https://en.wikipedia.org/wiki/QR_code)
* [<span data-ttu-id="a7505-290">Fakesdk</span><span class="sxs-lookup"><span data-stu-id="a7505-290">FaceSDK</span></span>](https://research.microsoft.com/projects/facesdk/)
* [<span data-ttu-id="a7505-291">Microsoft Translator</span><span class="sxs-lookup"><span data-stu-id="a7505-291">Microsoft Translator</span></span>](https://www.microsoft.com/translator/business)

<span data-ttu-id="a7505-292">Die Beibehaltung einer interaktiven Anwendungsframe-Rate ist wichtig, insbesondere beim Umgang mit Bild Erkennungsalgorithmen mit langer Laufzeit.</span><span class="sxs-lookup"><span data-stu-id="a7505-292">Keeping an interactive application frame-rate is critical, especially when dealing with long-running image recognition algorithms.</span></span> <span data-ttu-id="a7505-293">Aus diesem Grund verwenden wir in der Regel das folgende Muster:</span><span class="sxs-lookup"><span data-stu-id="a7505-293">For this reason, we commonly use the following pattern:</span></span>
1. <span data-ttu-id="a7505-294">Haupt Thread: verwaltet das Kamera Objekt.</span><span class="sxs-lookup"><span data-stu-id="a7505-294">Main Thread: manages the camera object</span></span>
2. <span data-ttu-id="a7505-295">Haupt Thread: neue Frames anfordern (Async)</span><span class="sxs-lookup"><span data-stu-id="a7505-295">Main Thread: requests new frames (async)</span></span>
3. <span data-ttu-id="a7505-296">Haupt Thread: neue Frames an nach Verfolgungs Thread übergeben</span><span class="sxs-lookup"><span data-stu-id="a7505-296">Main Thread: pass new frames to tracking thread</span></span>
4. <span data-ttu-id="a7505-297">Überwachungs Thread: verarbeitet das Image zum Erfassen von Schlüsselpunkten.</span><span class="sxs-lookup"><span data-stu-id="a7505-297">Tracking Thread: processes image to collect key points</span></span>
5. <span data-ttu-id="a7505-298">Haupt Thread: verschiebt das virtuelle Modell entsprechend der gefundenen wichtigen Punkte.</span><span class="sxs-lookup"><span data-stu-id="a7505-298">Main Thread: moves virtual model to match found key points</span></span>
6. <span data-ttu-id="a7505-299">Haupt Thread: Wiederholen aus Schritt 2</span><span class="sxs-lookup"><span data-stu-id="a7505-299">Main Thread: repeat from step 2</span></span>

<span data-ttu-id="a7505-300">Einige Abbild Markersysteme stellen nur einen einzelnen Pixel Speicherort bereit (andere stellen die vollständige Transformation bereit. in diesem Fall wird dieser Abschnitt nicht benötigt), was einem Ray möglicher Standorte entspricht.</span><span class="sxs-lookup"><span data-stu-id="a7505-300">Some image marker systems only provide a single pixel location (others provide the full transform in which case this section will not be needed), which equates to a ray of possible locations.</span></span> <span data-ttu-id="a7505-301">Um zu einem einzelnen 3D--Speicherort zu gelangen, können wir mehrere Strahlen nutzen und das Endergebnis nach dem ungefähren Schnittpunkt suchen.</span><span class="sxs-lookup"><span data-stu-id="a7505-301">To get to a single 3d location, we can then leverage multiple rays and find the final result by their approximate intersection.</span></span> <span data-ttu-id="a7505-302">Gehen Sie hierzu wie folgt vor:</span><span class="sxs-lookup"><span data-stu-id="a7505-302">To do this, you'll need to:</span></span>
1. <span data-ttu-id="a7505-303">Schleife zum Erfassen mehrerer Kamerabilder</span><span class="sxs-lookup"><span data-stu-id="a7505-303">Get a loop going collecting multiple camera images</span></span>
2. <span data-ttu-id="a7505-304">Suchen der zugehörigen featurepunkte und ihrer weltweiten Strahlen</span><span class="sxs-lookup"><span data-stu-id="a7505-304">Find the associated feature points, and their world rays</span></span>
3. <span data-ttu-id="a7505-305">Wenn Sie ein Wörterbuch mit Features haben, die jeweils über mehrere Welt Strahlen verfügen, können Sie den folgenden Code verwenden, um die Schnittmenge dieser Strahlen zu lösen:</span><span class="sxs-lookup"><span data-stu-id="a7505-305">When you have a dictionary of features, each with multiple world rays, you can use the following code to solve for the intersection of those rays:</span></span>

```
public static Vector3 ClosestPointBetweenRays(
   Vector3 point1, Vector3 normalizedDirection1,
   Vector3 point2, Vector3 normalizedDirection2) {
   float directionProjection = Vector3.Dot(normalizedDirection1, normalizedDirection2);
   if (directionProjection == 1) {
     return point1; // parallel lines
   }
   float projection1 = Vector3.Dot(point2 - point1, normalizedDirection1);
   float projection2 = Vector3.Dot(point2 - point1, normalizedDirection2);
   float distanceAlongLine1 = (projection1 - directionProjection * projection2) / (1 - directionProjection * directionProjection);
   float distanceAlongLine2 = (projection2 - directionProjection * projection1) / (directionProjection * directionProjection - 1);
   Vector3 pointOnLine1 = point1 + distanceAlongLine1 * normalizedDirection1;
   Vector3 pointOnLine2 = point2 + distanceAlongLine2 * normalizedDirection2;
   return Vector3.Lerp(pointOnLine2, pointOnLine1, 0.5f);
 }
```

<span data-ttu-id="a7505-306">Bei zwei oder mehr nach verfolgten tagstandorten können Sie eine modellierte Szene so positionieren, dass Sie dem aktuellen Szenario des Benutzers entspricht.</span><span class="sxs-lookup"><span data-stu-id="a7505-306">Given two or more tracked tag locations, you can position a modelled scene to fit the user's current scenario.</span></span> <span data-ttu-id="a7505-307">Wenn Sie die Schwerkraft nicht annehmen können, benötigen Sie drei Tag-Orte.</span><span class="sxs-lookup"><span data-stu-id="a7505-307">If you can't assume gravity, then you'll need three tag locations.</span></span> <span data-ttu-id="a7505-308">In vielen Fällen wird ein einfaches Farbschema verwendet, bei dem weiße Bereiche in Echtzeit nach verfolgte tagspeicher Orte darstellen und blaue Bereiche modellierte tagspeicher Orte darstellen.</span><span class="sxs-lookup"><span data-stu-id="a7505-308">In many cases, we use a simple color scheme where white spheres represent real-time tracked tag locations, and blue spheres represent modelled tag locations.</span></span> <span data-ttu-id="a7505-309">Dadurch kann der Benutzer die ausrichtungsqualität visuell einschätzen.</span><span class="sxs-lookup"><span data-stu-id="a7505-309">This allows the user to visually gauge the alignment quality.</span></span> <span data-ttu-id="a7505-310">Wir gehen davon aus, dass Sie das folgende Setup in allen Anwendungen ausführen:</span><span class="sxs-lookup"><span data-stu-id="a7505-310">We assume the following setup in all our applications:</span></span>
* <span data-ttu-id="a7505-311">Mindestens zwei modellierte tagspeicher Orte</span><span class="sxs-lookup"><span data-stu-id="a7505-311">Two or more modelled tag locations</span></span>
* <span data-ttu-id="a7505-312">Ein "Kalibrierungs Raum", der in der Szene das übergeordnete Element der Tags ist</span><span class="sxs-lookup"><span data-stu-id="a7505-312">One 'calibration space' which in the scene is the parent of the tags</span></span>
* <span data-ttu-id="a7505-313">Kamera Funktions Bezeichner</span><span class="sxs-lookup"><span data-stu-id="a7505-313">Camera feature identifier</span></span>
* <span data-ttu-id="a7505-314">Das Verhalten, bei dem der Kalibrierungsbereich verschoben wird, um die modellierten Tags mit den Echt Zeit Tags auszurichten (es ist vorsichtig, den übergeordneten Bereich und nicht die modellierten Marker selbst zu verschieben, weil eine andere Verbindung relativ zu diesen Tags ist).</span><span class="sxs-lookup"><span data-stu-id="a7505-314">Behavior which moves the calibration space to align the modelled tags with the real-time tags (we are careful to move the parent space, not the modelled markers themselves, because other connect is positions relative to them).</span></span>

```
// In the two tags case:
 Vector3 idealDelta = (realTags[1].EstimatedWorldPos - realTags[0].EstimatedWorldPos);
 Vector3 curDelta = (modelledTags[1].transform.position - modelledTags[0].transform.position);
 if (IsAssumeGravity) {
   idealDelta.y = 0;
   curDelta.y = 0;
 }
 Quaternion deltaRot = Quaternion.FromToRotation(curDelta, idealDelta);
 trans.rotation = Quaternion.LookRotation(deltaRot * trans.forward, trans.up);
 trans.position += realTags[0].EstimatedWorldPos - modelledTags[0].transform.position;
```

### <a name="track-or-identify-tagged-stationary-or-moving-real-world-objectsfaces-using-leds-or-other-recognizer-libraries"></a><span data-ttu-id="a7505-315">Mithilfe von LEDs oder anderen Erkennungs Bibliotheken nachverfolgen oder identifizieren Sie in der Praxis markierte Objekte/Gesichter in der Praxis</span><span class="sxs-lookup"><span data-stu-id="a7505-315">Track or Identify Tagged Stationary or Moving real-world objects/faces using LEDs or other recognizer libraries</span></span>

<span data-ttu-id="a7505-316">Beispiele:</span><span class="sxs-lookup"><span data-stu-id="a7505-316">Examples:</span></span>
* <span data-ttu-id="a7505-317">Industrieroboter mit LEDs (oder QR-Codes zum langsameren Verschieben von Objekten)</span><span class="sxs-lookup"><span data-stu-id="a7505-317">Industrial robots with LEDs (or QR codes for slower moving objects)</span></span>
* <span data-ttu-id="a7505-318">Identifizieren und erkennen von Objekten im Raum</span><span class="sxs-lookup"><span data-stu-id="a7505-318">Identify and recognize objects in the room</span></span>
* <span data-ttu-id="a7505-319">Personen im Raum identifizieren und erkennen (z. b. Holographic-Kontaktkarten über Flächen platzieren)</span><span class="sxs-lookup"><span data-stu-id="a7505-319">Identify and recognize people in the room (e.g. place holographic contact cards over faces)</span></span>

## <a name="see-also"></a><span data-ttu-id="a7505-320">Siehe auch</span><span class="sxs-lookup"><span data-stu-id="a7505-320">See also</span></span>
* [<span data-ttu-id="a7505-321">Beispiel für eine abrechenbare Kamera</span><span class="sxs-lookup"><span data-stu-id="a7505-321">Locatable camera sample</span></span>](https://github.com/Microsoft/Windows-universal-samples/tree/master/Samples/HolographicFaceTracking)
* [<span data-ttu-id="a7505-322">Ausrichtbare Kamera in Unity</span><span class="sxs-lookup"><span data-stu-id="a7505-322">Locatable camera in Unity</span></span>](locatable-camera-in-unity.md)
* [<span data-ttu-id="a7505-323">Mixed Reality-Aufnahme</span><span class="sxs-lookup"><span data-stu-id="a7505-323">Mixed reality capture</span></span>](mixed-reality-capture.md)
* [<span data-ttu-id="a7505-324">Mixed Reality-Aufnahme für Entwickler</span><span class="sxs-lookup"><span data-stu-id="a7505-324">Mixed reality capture for developers</span></span>](mixed-reality-capture-for-developers.md)
* [<span data-ttu-id="a7505-325">Einführung in Media Capture</span><span class="sxs-lookup"><span data-stu-id="a7505-325">Media capture introduction</span></span>](https://msdn.microsoft.com/library/windows/apps/mt243896.aspx)
* [<span data-ttu-id="a7505-326">Beispiel für die holografische Gesichts Verfolgung</span><span class="sxs-lookup"><span data-stu-id="a7505-326">Holographic face tracking sample</span></span>](https://github.com/Microsoft/Windows-universal-samples/tree/master/Samples/HolographicFaceTracking)
