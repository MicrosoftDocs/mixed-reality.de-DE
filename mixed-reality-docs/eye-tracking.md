---
title: Augenblick
description: Hololens 2 ermöglicht ein neues Maß an Kontext und menschliches Verständnis in der holografischen Benutzerfreundlichkeit, indem Entwicklern die Möglichkeit geboten wird, Informationen zu den Benutzern zu verwenden, die von Benutzern untersucht werden.
author: sostel
ms.author: sostel
ms.date: 04/05/2019
ms.topic: article
keywords: Augen Verfolgung, gemischte Realität, Eingabe, Augenblick
ms.openlocfilehash: 51779b7b210522aa4d19b5a32d7df6ccb2cb3a35
ms.sourcegitcommit: ff330a7e36e5ff7ae0e9a08c0e99eb7f3f81361f
ms.translationtype: MT
ms.contentlocale: de-DE
ms.lasthandoff: 08/28/2019
ms.locfileid: "70122066"
---
# <a name="eye-gaze-on-hololens-2"></a><span data-ttu-id="2343e-104">Blick auf hololens 2</span><span class="sxs-lookup"><span data-stu-id="2343e-104">Eye-gaze on HoloLens 2</span></span>
<span data-ttu-id="2343e-105">Hololens 2 ermöglicht ein neues Maß an Kontext und menschliches Verständnis in der holografischen Benutzerfreundlichkeit, indem Entwicklern die Möglichkeit geboten wird, Informationen zu den Benutzern zu verwenden, die von Benutzern untersucht werden.</span><span class="sxs-lookup"><span data-stu-id="2343e-105">HoloLens 2 allows for a new level of context and human understanding within the holographic experience by providing developers with the ability of using information about what users are looking at.</span></span> <span data-ttu-id="2343e-106">Auf dieser Seite erfahren Entwickler, wie Sie von der Eye-Nachverfolgung für verschiedene Anwendungsfälle profitieren können, und worauf Sie achten müssen, wenn Sie auf Augenblick basierende Benutzeroberflächen entwerfen.</span><span class="sxs-lookup"><span data-stu-id="2343e-106">This page tells developers how they can benefit from eye tracking for various use cases as well as what to look for when designing eye-gaze-based user interfaces.</span></span> 


## <a name="device-support"></a><span data-ttu-id="2343e-107">Unterstützung von Geräten</span><span class="sxs-lookup"><span data-stu-id="2343e-107">Device support</span></span>

<table>
<colgroup>
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
</colgroup>
<tr>
     <td><span data-ttu-id="2343e-108"><strong>Funktion</strong></span><span class="sxs-lookup"><span data-stu-id="2343e-108"><strong>Feature</strong></span></span></td>
     <td><span data-ttu-id="2343e-109"><a href="hololens-hardware-details.md"><strong>HoloLens (1. Generation)</strong></a></span><span class="sxs-lookup"><span data-stu-id="2343e-109"><a href="hololens-hardware-details.md"><strong>HoloLens (1st gen)</strong></a></span></span></td>
     <td><span data-ttu-id="2343e-110"><strong>HoloLens 2</strong></span><span class="sxs-lookup"><span data-stu-id="2343e-110"><strong>HoloLens 2</strong></span></span></td>
     <td><span data-ttu-id="2343e-111"><a href="immersive-headset-hardware-details.md"><strong>Immersive Headsets</strong></a></span><span class="sxs-lookup"><span data-stu-id="2343e-111"><a href="immersive-headset-hardware-details.md"><strong>Immersive headsets</strong></a></span></span></td>
</tr>
<tr>
     <td><span data-ttu-id="2343e-112">Augenblick</span><span class="sxs-lookup"><span data-stu-id="2343e-112">Eye-gaze</span></span></td>
     <td><span data-ttu-id="2343e-113">❌</span><span class="sxs-lookup"><span data-stu-id="2343e-113">❌</span></span></td>
     <td><span data-ttu-id="2343e-114">✔️</span><span class="sxs-lookup"><span data-stu-id="2343e-114">✔️</span></span></td>
     <td><span data-ttu-id="2343e-115">❌</span><span class="sxs-lookup"><span data-stu-id="2343e-115">❌</span></span></td>
</tr>
</table>

## <a name="use-cases"></a><span data-ttu-id="2343e-116">Anwendungsfälle</span><span class="sxs-lookup"><span data-stu-id="2343e-116">Use cases</span></span>
<span data-ttu-id="2343e-117">Mit der Blickverfolgung können Anwendungen in Echtzeit verfolgen, wohin der Benutzer schaut.</span><span class="sxs-lookup"><span data-stu-id="2343e-117">Eye tracking enables applications to track where the user is looking in real time.</span></span> <span data-ttu-id="2343e-118">In den folgenden Anwendungsfällen werden einige Interaktionen beschrieben, die mit der Eye-Nachverfolgung in gemischter Realität möglich sind.</span><span class="sxs-lookup"><span data-stu-id="2343e-118">The following use cases describe some interactions that are possible with eye tracking in mixed reality.</span></span>
<span data-ttu-id="2343e-119">Beachten Sie, dass das [Mixed Reality Toolkit](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) nützlich ist, um einige interessante und leistungsstarke Beispiele für die Verwendung der Eye-Nachverfolgung bereitzustellen, wie z. b. schnelle und mühelose Unterstützung für die Zielauswahl und Automatisches Scrollen durch Text basierend auf das, was der Benutzer sieht.</span><span class="sxs-lookup"><span data-stu-id="2343e-119">Keep in mind that the [Mixed Reality Toolkit](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) is useful for providing several interesting and powerful examples for using eye tracking, such as quick and effortless eye-supported target selections as well as automatically scrolling through text based on what the user looks at.</span></span> 

### <a name="user-intent"></a><span data-ttu-id="2343e-120">Benutzerabsicht</span><span class="sxs-lookup"><span data-stu-id="2343e-120">User intent</span></span>    
<span data-ttu-id="2343e-121">Informationen dazu, wo und was ein Benutzer untersucht, bieten einen leistungsstarken **Kontext für andere Eingaben**, wie z. b. Voice, Hands und Controller.</span><span class="sxs-lookup"><span data-stu-id="2343e-121">Information about where and what a user looks at provides a powerful **context for other inputs**, such as voice, hands and controllers.</span></span>
<span data-ttu-id="2343e-122">Dies kann für verschiedene Aufgaben verwendet werden.</span><span class="sxs-lookup"><span data-stu-id="2343e-122">This can be used for various tasks.</span></span>
<span data-ttu-id="2343e-123">Dies kann z. b. von der schnellen und mühelosen **Ausrichtung** auf die gesamte Szene reichen, indem Sie einfach ein Hologramm betrachten und "Select" (siehe auch [Kopf-und Commit](gaze-and-commit.md)) oder *"put this...".* Ich möchte das – Hologramm platzieren und sagen: *"... vorhanden*sind.</span><span class="sxs-lookup"><span data-stu-id="2343e-123">For example, this can range from quickly and effortlessly **targeting** across the scene by simply looking at a hologram and saying "select" (also see [Head-gaze and commit](gaze-and-commit.md)) or by saying *"put this..."*, then looking over to where the user wants to place the hologram and say *"...there"*.</span></span> <span data-ttu-id="2343e-124">Beispiele hierfür finden Sie in den Artikeln [Mixed Reality Toolkit – Eye-supported Target Selection](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_TargetSelection.html) (Mixed Reality-Toolkit – Blickgestützte Zielauswahl) und [Mixed Reality Toolkit – Eye-supported Target Positioning](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Positioning.html) (Mixed Reality-Toolkit – Blickgestützte Zielpositionierung).</span><span class="sxs-lookup"><span data-stu-id="2343e-124">Examples for this can be found in [Mixed Reality Toolkit - Eye-supported Target Selection](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_TargetSelection.html) and [Mixed Reality Toolkit - Eye-supported Target Positioning](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Positioning.html).</span></span>

<span data-ttu-id="2343e-125">Außerdem kann ein Beispiel für die Benutzer Absicht die Verwendung von Informationen zu den Benutzern, die von Benutzern untersucht werden, beinhalten, um die Einbindung von verkörperten virtuellen Agents und interaktiven holograms</span><span class="sxs-lookup"><span data-stu-id="2343e-125">Additionally, an example for user intent might include using information about what users look at to enhance engagement with embodied virtual agents and interactive holograms.</span></span> <span data-ttu-id="2343e-126">Beispielsweise können virtuelle Agents verfügbare Optionen und ihr Verhalten basierend auf dem aktuell angezeigten Inhalt anpassen.</span><span class="sxs-lookup"><span data-stu-id="2343e-126">For instance, virtual agents might adapt available options and their behavior based on currently viewed content.</span></span> 

### <a name="implicit-actions"></a><span data-ttu-id="2343e-127">Implizite Aktionen</span><span class="sxs-lookup"><span data-stu-id="2343e-127">Implicit actions</span></span>
<span data-ttu-id="2343e-128">Die Kategorie der impliziten Aktionen steht in enger Beziehung zur Benutzerabsicht.</span><span class="sxs-lookup"><span data-stu-id="2343e-128">The category of implicit actions closely relates to user intent.</span></span>
<span data-ttu-id="2343e-129">Die Idee ist, dass holograms oder Benutzeroberflächen Elemente in einer etwas instinstalen Weise reagieren, die nicht einmal so aussieht, als ob der Benutzer mit dem System interagiert, sondern dass das System und der Benutzer synchron sind. Ein Beispiel hierfür ist ein bidirektionaler **automatischer** Bildlauf, bei dem der Benutzer einen langen Text lesen kann, der automatisch mit dem Scrollen beginnt, sobald der Benutzer zum unteren Rand des Textfelds gelangt, damit der Benutzer den Lesevorgang ohne Fingerabdruck durchführt.</span><span class="sxs-lookup"><span data-stu-id="2343e-129">The idea is that holograms or user interface elements react in a somewhat instinctual way that may not even feel like the user is interacting with the system at all, but rather that the system and the user are in sync. One example is **eye-gaze-based auto scroll** where the user can read a long text which automatically starts scrolling once the user gets to the bottom of the textbox to keep the user in the flow of reading without lifting a finger.</span></span>  
<span data-ttu-id="2343e-130">Ein wichtiger Aspekt hierbei ist, dass sich die Scrollgeschwindigkeit an die Lesegeschwindigkeit des Benutzers anpasst.</span><span class="sxs-lookup"><span data-stu-id="2343e-130">A key aspect of this is that the scrolling speed adapts to the reading speed of the user.</span></span>
<span data-ttu-id="2343e-131">Ein weiteres Beispiel sind die **Augen unterstützten Zoom-und Schwenken-** Elemente, bei denen der Benutzer das Gefühl hat, dass er sich genau zu dem befindet, worauf er sich konzentriert</span><span class="sxs-lookup"><span data-stu-id="2343e-131">Another example is **eye-supported zoom and pan** where the user can feel like diving exactly toward what he or she is focused on.</span></span> <span data-ttu-id="2343e-132">Das Auslösen von Zoom und das Steuern der Zoomgeschwindigkeit kann durch die Stimme oder Hand Eingabe gesteuert werden. Dies ist wichtig, um dem Benutzer das Gefühl der Kontrolle zu bieten, ohne dass eine über Überlastung erfolgt.</span><span class="sxs-lookup"><span data-stu-id="2343e-132">Triggering zoom and controlling zoom speed can be controlled by voice or hand input, which is important for providing the user with the feeling of control while avoiding being overwhelmed.</span></span> <span data-ttu-id="2343e-133">Diese Entwurfs Richtlinien werden im folgenden ausführlicher erläutert.</span><span class="sxs-lookup"><span data-stu-id="2343e-133">We will talk about these design guidelines in more detail below.</span></span> <span data-ttu-id="2343e-134">Nach dem vergrößern kann der Benutzer problemlos auf den Kurs einer Straße folgen, um seine Umgebung zu durchsuchen, indem er einfach den Augenblick verwendet.</span><span class="sxs-lookup"><span data-stu-id="2343e-134">Once zoomed in, the user can  smoothly follow, for example, the course of a street to explore his or her neighborhood by simply using their eye-gaze.</span></span>
<span data-ttu-id="2343e-135">Demobeispiele für diese Arten von Interaktion finden Sie im Beispiel [Mixed Reality Toolkit – Eye-supported Navigation](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Navigation.html) (Mixed Reality-Toolkit – Blickgestützte Navigation).</span><span class="sxs-lookup"><span data-stu-id="2343e-135">Demo examples for these types of interactions can be found in the [Mixed Reality Toolkit - Eye-supported Navigation](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Navigation.html) sample.</span></span>

<span data-ttu-id="2343e-136">Zusätzliche Anwendungsfälle für _implizite Aktionen_ können Folgendes umfassen:</span><span class="sxs-lookup"><span data-stu-id="2343e-136">Additional use cases for _implicit actions_ can include:</span></span>
- <span data-ttu-id="2343e-137">**Intelligente Benachrichtigungen**: Ärgern Sie sich auch jedes Mal, wenn Benachrichtigungen dort angezeigt werden, wohin Sie gerade schauen?</span><span class="sxs-lookup"><span data-stu-id="2343e-137">**Smart notifications:** Ever get annoyed by notifications popping up right where you were focusing?</span></span> <span data-ttu-id="2343e-138">Wenn Sie das Konto berücksichtigen, auf das ein Benutzer achten wird, können Sie diese Umgebung verbessern, indem Sie Benachrichtigungen von dem Speicherort der Benutzer auslagern</span><span class="sxs-lookup"><span data-stu-id="2343e-138">Taking into account what a user is paying attention to, you can make this experience better by offsetting notifications from where the user is currently gazing.</span></span> <span data-ttu-id="2343e-139">Dadurch werden Ablenkungen eingeschränkt und automatisch geschlossen, sobald der Benutzer das Lesen abgeschlossen hat.</span><span class="sxs-lookup"><span data-stu-id="2343e-139">This limits distractions and automatically dismisses them once the user is finished reading.</span></span> 
- <span data-ttu-id="2343e-140">**„Aufmerksame“ Hologramme:** Holograms, die bei der Verwendung von auf eine beliebige Weise reagieren.</span><span class="sxs-lookup"><span data-stu-id="2343e-140">**Attentive holograms:** Holograms that subtly react when being gazed upon.</span></span> <span data-ttu-id="2343e-141">Dies kann von leicht leuchtenden Benutzeroberflächen Elementen bis hin zu einer langsam blühenden Blume zu einem virtuellen Haustier reichen, beginnend mit dem Benutzer oder dem Versuch, den Augenblick des Benutzers nach einem längeren Blick zu vermeiden.</span><span class="sxs-lookup"><span data-stu-id="2343e-141">This can range from slightly glowing UI elements to a slowly blooming flower to a virtual pet starting to look back at the user or trying to avoid the user's eye-gaze after a prolonged stare.</span></span> <span data-ttu-id="2343e-142">Diese Interaktion kann ein interessantes Gefühl der Konnektivität und Zufriedenheit in Ihrer Anwendung darstellen.</span><span class="sxs-lookup"><span data-stu-id="2343e-142">This interaction might provide an interesting sense of connectivity and satisfaction in your application.</span></span>

### <a name="attention-tracking"></a><span data-ttu-id="2343e-143">Aufmerksamkeitsverfolgung</span><span class="sxs-lookup"><span data-stu-id="2343e-143">Attention tracking</span></span>   
<span data-ttu-id="2343e-144">Informationen dazu, wo oder was Benutzer sehen, ist ein äußerst leistungsfähiges Tool zum Bewerten der Nutzbarkeit von Entwürfen und zum Erkennen von Problemen in effizienten Workflows.</span><span class="sxs-lookup"><span data-stu-id="2343e-144">Information about where or what users look at is an immensely powerful tool to assess usability of designs, and to identify problems in efficient workflows.</span></span> <span data-ttu-id="2343e-145">Die Visualisierung und Analyse von Augen Nachverfolgung ist eine gängige Vorgehensweise in verschiedenen Anwendungsbereichen.</span><span class="sxs-lookup"><span data-stu-id="2343e-145">Eye tracking visualization and analytics are a common practice in various application areas.</span></span> <span data-ttu-id="2343e-146">Mit hololens 2 bieten wir eine neue Dimension für dieses Verständnis, da 3D holograms in realen Kontexten platziert und entsprechend bewertet werden können.</span><span class="sxs-lookup"><span data-stu-id="2343e-146">With HoloLens 2, we provide a new dimension to this understanding as 3D holograms can be placed in real-world contexts and assessed accordingly.</span></span> <span data-ttu-id="2343e-147">Das [Mixed Reality Toolkit](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) enthält grundlegende Beispiele für das Protokollieren und Laden von Augen Verfolgungs Daten und deren Visualisierung.</span><span class="sxs-lookup"><span data-stu-id="2343e-147">The [Mixed Reality Toolkit](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) provides basic examples for logging and loading eye tracking data and  how to visualize them.</span></span>

<span data-ttu-id="2343e-148">Andere Anwendungen in diesem Bereich können Folgendes umfassen:</span><span class="sxs-lookup"><span data-stu-id="2343e-148">Other applications in this area can include:</span></span> 
-   <span data-ttu-id="2343e-149">**Remote Ansicht für den Augenblick:** Visualisieren Sie, welche Remote Mitarbeiter sich ansehen, um sicherzustellen, dass die Anweisungen ordnungsgemäß verstanden und befolgt werden.</span><span class="sxs-lookup"><span data-stu-id="2343e-149">**Remote eye-gaze visualization:** Visualize what remote collaborators are looking at to ensure whether instructions are correctly understood and followed.</span></span>
-   <span data-ttu-id="2343e-150">**Forschungsstudien zum Benutzerverhalten:** Die Nachverfolgung von Nachrichten kann verwendet werden, um die Art und Weise zu untersuchen, in der Anfänger und Experten Inhalte visuell analysieren, oder wie Ihre Hand-Auge-Koordination für komplexe Aufgaben wie z. b. die Analyse von medizinischen Daten oder betriebsmaschinen funktioniert.</span><span class="sxs-lookup"><span data-stu-id="2343e-150">**User research studies:** Attention tracking can be used to explore the way novice vs. expert users visually analyze content or how their hand-eye-coordination for complex tasks, such as for analysis of medical data or while operating machinery.</span></span>
-   <span data-ttu-id="2343e-151">**Schulungssimulationen und Leistungsüberwachung:** Üben Sie die Ausführung von Aufgaben, und optimieren Sie diese, indem Sie Engpässe im Ausführungsablauf effektiver identifizieren.</span><span class="sxs-lookup"><span data-stu-id="2343e-151">**Training simulations and Performance monitoring:** Practice and optimize the execution of tasks by identifying bottlenecks more effectively in the execution flow.</span></span>
-   <span data-ttu-id="2343e-152">**Entwurfsbewertungen, Werbung und Marktforschung:** Die Augen Verfolgung ist ein gängiges Tool für Marktforschung, wenn Sie Website-und Produktentwürfe evaluieren.</span><span class="sxs-lookup"><span data-stu-id="2343e-152">**Design evaluations, advertisement and marketing research:** Eye tracking is a common tool for market research when evaluating website and product designs.</span></span>

### <a name="additional-use-cases"></a><span data-ttu-id="2343e-153">Weitere Anwendungsfälle</span><span class="sxs-lookup"><span data-stu-id="2343e-153">Additional use cases</span></span>
- <span data-ttu-id="2343e-154">**Spiele:** Wollten Sie jemals übernatürliche Kräfte haben?</span><span class="sxs-lookup"><span data-stu-id="2343e-154">**Gaming:** Ever wanted to have superpowers?</span></span> <span data-ttu-id="2343e-155">Hier kommt Ihre Chance!</span><span class="sxs-lookup"><span data-stu-id="2343e-155">Here's your chance!</span></span> <span data-ttu-id="2343e-156">Sie können holograms durch ein-und ansehen.</span><span class="sxs-lookup"><span data-stu-id="2343e-156">You can levitate holograms by staring at them.</span></span> <span data-ttu-id="2343e-157">Schießen Sie Laserstrahlen aus Ihren Augen.</span><span class="sxs-lookup"><span data-stu-id="2343e-157">Shoot laser beams from your eyes.</span></span> <span data-ttu-id="2343e-158">Verwandeln Sie Feinde in den Stein, oder fixieren Sie Sie.</span><span class="sxs-lookup"><span data-stu-id="2343e-158">Turn enemies into stone or freeze them.</span></span> <span data-ttu-id="2343e-159">Verwenden Sie Ihren Röntgenblick, um Gebäude zu erkunden.</span><span class="sxs-lookup"><span data-stu-id="2343e-159">Use your x-ray vision to explore buildings.</span></span> <span data-ttu-id="2343e-160">Ihrer Phantasie sind keine Grenzen gesetzt!</span><span class="sxs-lookup"><span data-stu-id="2343e-160">Your imagination is the limit!</span></span>  

- <span data-ttu-id="2343e-161">**Ausdrucksstarke Avatare:** Die Eye-Nachverfolgung hilft bei komplexeren 3D-Avataren durch die Verwendung von Live-Eye-nach Verfolgungs Daten, um die Augen des Avatare zu animieren, die den Inhalt des Benutzers angeben.</span><span class="sxs-lookup"><span data-stu-id="2343e-161">**Expressive avatars:** Eye tracking aids in more expressive 3D avatars by using live eye tracking data to animate the avatar's eyes that indicate what the user is looking at.</span></span> 

- <span data-ttu-id="2343e-162">**Texteingabe:** Die Eye-Nachverfolgung kann als Alternative für den Text Eintrag mit geringem Aufwand verwendet werden, insbesondere dann, wenn Sprache oder Hände unpraktisch zu verwenden sind.</span><span class="sxs-lookup"><span data-stu-id="2343e-162">**Text entry:** Eye tracking can be used as an alternative for low-effort text entry, especially when speech or hands are inconvenient to use.</span></span> 


## <a name="available-eye-tracking-data"></a><span data-ttu-id="2343e-163">Verfügbare Augen Verfolgungs Daten</span><span class="sxs-lookup"><span data-stu-id="2343e-163">Available eye tracking data</span></span>
<span data-ttu-id="2343e-164">Bevor wir uns mit den spezifischen Entwurfs Richtlinien für die Interaktion mit Blick auf das Auge befassen, möchten wir kurz auf die Funktionen hinweisen, die von der hololens 2 [Eye Tracking-API](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.eyespose) bereitstellt werden.</span><span class="sxs-lookup"><span data-stu-id="2343e-164">Before going into detail about the specific design guidelines for eye-gaze interaction, we want to briefly point out the capabilities that the HoloLens 2 [Eye Tracking API](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.eyespose) provides.</span></span> <span data-ttu-id="2343e-165">Entwickler erhalten Zugriff auf einen Augenblick Strahl ("Ursprung" und "Richtung") bei ungefähr _30 fps (60 Hz)_ .</span><span class="sxs-lookup"><span data-stu-id="2343e-165">Developers get access to a single eye-gaze ray (gaze origin and direction) at approximately _30 FPS (60 Hz)_.</span></span>
<span data-ttu-id="2343e-166">Ausführlichere Informationen zum Zugreifen auf die Augen Verfolgungs Daten finden Sie in den Entwickler Handbüchern zur Verwendung von [Eye-Blick in DirectX](gaze-in-directx.md) und [im Blickwinkel in Unity](https://aka.ms/mrtk-eyes).</span><span class="sxs-lookup"><span data-stu-id="2343e-166">For more detailed information about how to access eye tracking data, please refer to our developer guides on using [eye-gaze in DirectX](gaze-in-directx.md) and [eye-gaze in Unity](https://aka.ms/mrtk-eyes).</span></span>

<span data-ttu-id="2343e-167">Der vorhergesagte Augenblick liegt ungefähr innerhalb von 1,5 Grad im visuellen Winkel um das eigentliche Ziel (siehe Abbildung unten).</span><span class="sxs-lookup"><span data-stu-id="2343e-167">The predicted eye-gaze is approximately within 1.5 degrees in visual angle around the actual target (see the illustration below).</span></span> <span data-ttu-id="2343e-168">Da geringfügige unveränderungen erwartet werden, sollten Entwickler einen gewissen Rand um diesen niedrigeren Grenzwert planen (z. b. können 2.0-3.0 Grad zu einer viel komfortableren Umgebung führen).</span><span class="sxs-lookup"><span data-stu-id="2343e-168">As slight imprecisions are expected, developers should plan for some margin around this lower bound value (e.g., 2.0-3.0 degrees may result in a much more comfortable experience).</span></span> <span data-ttu-id="2343e-169">Im folgenden wird erläutert, wie Sie die Auswahl kleiner Ziele im folgenden ausführlicher behandeln.</span><span class="sxs-lookup"><span data-stu-id="2343e-169">We will discuss how to address the selection of small targets in more detail below.</span></span> <span data-ttu-id="2343e-170">Damit die Blickverfolgung exakt funktioniert, muss jeder Benutzer eine Benutzerkalibrierung für seine Blickverfolgung durchlaufen.</span><span class="sxs-lookup"><span data-stu-id="2343e-170">For eye tracking to work accurately, each user is required to go through an eye tracking user calibration.</span></span> 

<span data-ttu-id="2343e-171">![Optimale Zielgröße im Abstand von 2 Metern](images/gazetargeting-size-1000px.jpg)</span><span class="sxs-lookup"><span data-stu-id="2343e-171">![Optimal target size at 2 meter distance](images/gazetargeting-size-1000px.jpg)</span></span><br>
<span data-ttu-id="2343e-172">*Optimale Zielgröße bei einer Entfernung von 2 Stunden*</span><span class="sxs-lookup"><span data-stu-id="2343e-172">*Optimal target size at a 2-meter distance*</span></span>

## <a name="calibration"></a><span data-ttu-id="2343e-173">Energie</span><span class="sxs-lookup"><span data-stu-id="2343e-173">Calibration</span></span> 
<span data-ttu-id="2343e-174">Damit die Eye-Nachverfolgung ordnungsgemäß funktioniert, muss jeder Benutzer eine nach [Verfolgungs Benutzer-Kalibrierung](calibration.md) durchlaufen, für die der Benutzer eine Reihe von Holographic-Zielen betrachten muss.</span><span class="sxs-lookup"><span data-stu-id="2343e-174">For eye tracking to work accurately, each user is required to go through an [eye tracking user calibration](calibration.md) for which the user has to look at a set of holographic targets.</span></span> <span data-ttu-id="2343e-175">Dies ermöglicht es dem Gerät, das System für eine komfortablere und qualitativ hochwertige Anzeige für den Benutzer anzupassen und gleichzeitig eine genaue Eye-Nachverfolgung sicherzustellen.</span><span class="sxs-lookup"><span data-stu-id="2343e-175">This allows the device to adjust the system for a more comfortable and higher quality viewing experience for the user and to ensure accurate eye tracking at the same time.</span></span> <span data-ttu-id="2343e-176">Die Augen Verfolgung sollte für die meisten Benutzer funktionieren, aber es gibt Fälle, in denen ein Benutzer möglicherweise nicht in der Lage ist, die Kalibrierung erfolgreich durchzusetzen.</span><span class="sxs-lookup"><span data-stu-id="2343e-176">Eye tracking should work for most users, but there are cases in which a user might be unable to calibrate successfully.</span></span>
<span data-ttu-id="2343e-177">Weitere Informationen zur Kalibrierung finden Sie unter [Kalibrierung](calibration.md).</span><span class="sxs-lookup"><span data-stu-id="2343e-177">To learn more about the calibration, please check [Calibration](calibration.md).</span></span>

## <a name="eye-gaze-input-design-guidelines"></a><span data-ttu-id="2343e-178">Eingabe Entwurfs Richtlinien für den Augenblick</span><span class="sxs-lookup"><span data-stu-id="2343e-178">Eye-gaze input design guidelines</span></span>
<span data-ttu-id="2343e-179">Das Entwickeln einer Interaktion, die die schnelle Ziel Ausrichtung nutzt, kann eine Herausforderung darstellen.</span><span class="sxs-lookup"><span data-stu-id="2343e-179">Building an interaction that takes advantage of fast-moving eye targeting can be challenging.</span></span> <span data-ttu-id="2343e-180">In diesem Abschnitt werden die wichtigsten Vorteile und Herausforderungen zusammengefasst, die beim Entwerfen Ihrer Anwendung zu beachten sind.</span><span class="sxs-lookup"><span data-stu-id="2343e-180">In this section, we summarize the key advantages and challenges to consider when designing your application.</span></span> 

### <a name="benefits-of-eye-gaze-input"></a><span data-ttu-id="2343e-181">Vorteile der Eingabe für den Augenblick</span><span class="sxs-lookup"><span data-stu-id="2343e-181">Benefits of eye-gaze input</span></span>
- <span data-ttu-id="2343e-182">**Zeigen mit hoher Geschwindigkeit.**</span><span class="sxs-lookup"><span data-stu-id="2343e-182">**High speed pointing.**</span></span> <span data-ttu-id="2343e-183">Der Augenschein ist der schnellste reagierende Muskel im menschlichen Körper.</span><span class="sxs-lookup"><span data-stu-id="2343e-183">The eye muscle is the fastest reacting muscle in the human body.</span></span> 

- <span data-ttu-id="2343e-184">**Wenig Aufwand.**</span><span class="sxs-lookup"><span data-stu-id="2343e-184">**Low effort.**</span></span> <span data-ttu-id="2343e-185">Es sind kaum physische Bewegungen erforderlich.</span><span class="sxs-lookup"><span data-stu-id="2343e-185">Barely any physical movements are necessary.</span></span> 

- <span data-ttu-id="2343e-186">**Selbstverständlichkeit.**</span><span class="sxs-lookup"><span data-stu-id="2343e-186">**Implicitness.**</span></span> <span data-ttu-id="2343e-187">Häufig von Benutzern als "Gedanken Lesevorgang" beschrieben, kann das System anhand der Informationen über die Augenbewegungen eines Benutzers erkennen, welche Ziele der Benutzer einbindet.</span><span class="sxs-lookup"><span data-stu-id="2343e-187">Often described by users as "mind reading", information about a user's eye movements lets the system know which target the user plans to engage.</span></span> 

- <span data-ttu-id="2343e-188">**Alternativer Eingabekanal.**</span><span class="sxs-lookup"><span data-stu-id="2343e-188">**Alternative input channel.**</span></span> <span data-ttu-id="2343e-189">Der Augenblick kann eine leistungsstarke, unterstützende Eingabe für Hand-und Spracheingaben bereitstellen, die auf der Grundlage ihrer Hand-Auge-Koordination von Benutzern entwickelt wurden.</span><span class="sxs-lookup"><span data-stu-id="2343e-189">Eye-gaze can provide a powerful supporting input for hand and voice input building on years of experience from users based on their hand-eye coordination.</span></span>

- <span data-ttu-id="2343e-190">**Visuelle Aufmerksamkeit.**</span><span class="sxs-lookup"><span data-stu-id="2343e-190">**Visual attention.**</span></span> <span data-ttu-id="2343e-191">Ein weiterer wichtiger Vorteil ist die Möglichkeit, zu ableiten, worauf ein Benutzer achten soll.</span><span class="sxs-lookup"><span data-stu-id="2343e-191">Another important benefit is the possibility to infer what a user is paying attention to.</span></span> <span data-ttu-id="2343e-192">Dies kann in verschiedenen Anwendungsbereichen hilfreich sein, von der effektiveren Auswertung verschiedener Entwürfe bis hin zu intelligenteren Benutzeroberflächen und erweiterten sozialen Netzwerken für die Remote Kommunikation.</span><span class="sxs-lookup"><span data-stu-id="2343e-192">This can help in various application areas ranging from more effectively evaluating different designs to aiding in smarter user interfaces and enhanced social cues for remote communication.</span></span>

<span data-ttu-id="2343e-193">Kurz gesagt: die Verwendung von Eye-Blick als Eingabe bietet ein schnelles und mühelose Kontext Signal.</span><span class="sxs-lookup"><span data-stu-id="2343e-193">In a nutshell, using eye-gaze as an input offers a fast and effortless contextual signal.</span></span> <span data-ttu-id="2343e-194">Dies ist insbesondere in Kombination mit anderen Eingaben, wie z. b. *Voice* und *manueller* Eingabe, zur Bestätigung der Absicht des Benutzers sehr leistungsstark</span><span class="sxs-lookup"><span data-stu-id="2343e-194">This is particularly powerful when combined with other inputs such as *voice* and *manual* input to confirm the user's intent.</span></span>


### <a name="challenges-of-eye-gaze-as-an-input"></a><span data-ttu-id="2343e-195">Herausforderungen des Augenblicks als Eingabe</span><span class="sxs-lookup"><span data-stu-id="2343e-195">Challenges of eye-gaze as an input</span></span>
<span data-ttu-id="2343e-196">Mit einer großen Menge von Energie.</span><span class="sxs-lookup"><span data-stu-id="2343e-196">With lots of power, comes lots of responsibility.</span></span>
<span data-ttu-id="2343e-197">Wenngleich der Augenblick verwendet werden kann, um zufriedenstellende Benutzeroberflächen zu erstellen, die Ihnen einen Superhelden vermitteln, ist es auch wichtig zu wissen, was für dieses nicht geeignet ist.</span><span class="sxs-lookup"><span data-stu-id="2343e-197">While eye-gaze can be used to create satisfying user experiences that makes you feel like a superhero, it is also important to know what it is not good at to appropriately account for this.</span></span> <span data-ttu-id="2343e-198">Im folgenden werden einige *Probleme* erläutert, die berücksichtigt werden müssen, und es wird erläutert, wie Sie bei der Arbeit mit Augenblick Eingaben behandelt werden:</span><span class="sxs-lookup"><span data-stu-id="2343e-198">The following discusses some *challenges* to consider as well as how to address them when working with eye-gaze input:</span></span> 

- <span data-ttu-id="2343e-199">**Ihr Blick ist "Always on"** . In dem Moment, in dem Sie Ihre Augen Deckeln öffnen, beginnen Ihre Augen damit, die Dinge in der Umgebung zu fixieren.</span><span class="sxs-lookup"><span data-stu-id="2343e-199">**Your eye-gaze is "always on"** The moment you open your eye lids, your eyes start fixating on things in the environment.</span></span> <span data-ttu-id="2343e-200">Wenn Sie auf jede Art und Weise reagieren, die Sie durchführen, und versehentlich Aktionen ausgeben, weil Sie etwas zu lange untersucht haben, würde dies zu einer unkomplizierten</span><span class="sxs-lookup"><span data-stu-id="2343e-200">Reacting to every look you make and accidentally issuing actions because you looked at something for too long would result in an unsatisfying experience.</span></span>
<span data-ttu-id="2343e-201">Daher empfiehlt es sich, den Augenblick mit einem *Sprachbefehl*, einer *Handbewegung*, einem *Schaltflächen Klick* oder einem erweiterten Wohnort zu kombinieren, um die Auswahl eines Ziels zu initiieren.</span><span class="sxs-lookup"><span data-stu-id="2343e-201">Therefore we recommend combining eye-gaze with a *voice command*, *hand gesture*, *button click* or extended dwell to trigger the selection of a target.</span></span>
<span data-ttu-id="2343e-202">Diese Lösung ermöglicht außerdem einen Modus, in dem der Benutzer sich ohne überdies durch eine unwillkürlich Auslösung von etwas bewegen kann.</span><span class="sxs-lookup"><span data-stu-id="2343e-202">This solution also allows for a mode in which the user can freely look around without being overwhelmed by involuntarily triggering something.</span></span> <span data-ttu-id="2343e-203">Dieses Problem sollte auch beim Entwerfen von visuellem und auditiven Feedback berücksichtigt werden, wenn Sie nur ein Ziel betrachten.</span><span class="sxs-lookup"><span data-stu-id="2343e-203">This issue should also be considered when designing visual and auditory feedback when merely looking at a target.</span></span>
<span data-ttu-id="2343e-204">Überfordern Sie den Benutzer nicht mit sofortigen Popup-Effekten oder Sounds beim kurzen Verweilen auf einem Ziel.</span><span class="sxs-lookup"><span data-stu-id="2343e-204">Do not overwhelm the user with immediate pop-out effects or hover sounds.</span></span> <span data-ttu-id="2343e-205">Die Feinheit ist der Schlüssel.</span><span class="sxs-lookup"><span data-stu-id="2343e-205">Subtlety is key.</span></span> <span data-ttu-id="2343e-206">Weiter unten werden im Zusammenhang mit den Entwurfsempfehlungen einige bewährte Methoden hierfür erläutert.</span><span class="sxs-lookup"><span data-stu-id="2343e-206">We will discuss some best practices for this further below when talking about design recommendations.</span></span>

- <span data-ttu-id="2343e-207">**Überwachung und Steuerung** Stellen Sie sich vor, dass Sie ein Foto genau auf Ihre Wand ausrichten möchten.</span><span class="sxs-lookup"><span data-stu-id="2343e-207">**Observation vs. control** Imagine that you want to precisely straighten a photograph on your wall.</span></span> <span data-ttu-id="2343e-208">Sie schauen zuerst auf den Rahmen und dann auf die Umgebung, um festzustellen, ob es richtig ausgerichtet ist.</span><span class="sxs-lookup"><span data-stu-id="2343e-208">You look at its borders and its surroundings to see if it aligns well.</span></span> <span data-ttu-id="2343e-209">Stellen Sie sich nun vor, wie Sie dies tun würden, wenn Sie den Blick als Eingabe zum Verschieben des Bilds verwenden möchten.</span><span class="sxs-lookup"><span data-stu-id="2343e-209">Now imagine how you would do that when you want to use your eye-gaze as an input to move the picture.</span></span> <span data-ttu-id="2343e-210">Schwierig, nicht wahr?</span><span class="sxs-lookup"><span data-stu-id="2343e-210">Difficult, isn't it?</span></span> <span data-ttu-id="2343e-211">Dies beschreibt die doppelte Rolle des Augenblicks, wenn Sie sowohl für die Eingabe als auch für die Steuerung erforderlich ist.</span><span class="sxs-lookup"><span data-stu-id="2343e-211">This describes the double role of eye-gaze when it is required both for input and control.</span></span> 

- <span data-ttu-id="2343e-212">**Abwenden vor dem Klicken:** Für eine schnelle Zielauswahl hat Research gezeigt, dass der Augenblick eines Benutzers fortfahren kann, bevor ein manueller Klick (z. b. eine airtap) abgeschlossen wird.</span><span class="sxs-lookup"><span data-stu-id="2343e-212">**Leave before click:** For quick target selections, research has shown that a user's eye-gaze can move on before concluding a manual click (e.g., an airtap).</span></span> <span data-ttu-id="2343e-213">Daher muss besonders darauf geachtet werden, dass das schnelle Eye-Eye-Signal mit einer langsameren Steuerungs Eingabe (z. b. Voice, Hands, Controller) synchronisiert wird.</span><span class="sxs-lookup"><span data-stu-id="2343e-213">Hence, special attention must be paid to synchronizing the fast eye-gaze signal with slower control input (e.g., voice, hands, controller).</span></span>

- <span data-ttu-id="2343e-214">**Kleine Ziele:** Wissen Sie das Gefühl, wenn Sie versuchen, Text zu lesen, der nur etwas zu klein ist, um bequem lesbar zu sein?</span><span class="sxs-lookup"><span data-stu-id="2343e-214">**Small targets:** Do you know the feeling when you try to read text that is just a bit too small to read comfortably?</span></span> <span data-ttu-id="2343e-215">Diese Überlastung kann dazu führen, dass Sie müde und ausgegraut sind, da Sie versuchen, Ihre Augen besser zu fokussieren.</span><span class="sxs-lookup"><span data-stu-id="2343e-215">This straining feeling on your eyes can cause you to feel tired and worn out because you try to readjust your eyes to focus better.</span></span>
<span data-ttu-id="2343e-216">Dies ist ein Gefühl, das Sie in Ihren Benutzern aufrufen können, wenn Sie erzwingen, dass Sie Ziele auswählen, die in Ihrer Anwendung mit der Ziel Ausrichtung zu klein sind.</span><span class="sxs-lookup"><span data-stu-id="2343e-216">This is a feeling you might invoke in your users when forcing them to select targets that are too small in your application using eye targeting.</span></span>
<span data-ttu-id="2343e-217">Damit Sie für Ihre Benutzer eine angenehme und komfortable Erfahrung schaffen, sollte bei Zielen für Ihren Entwurf der Sehwinkel mindestens 2 Grad (vorzugsweise mehr) betragen.</span><span class="sxs-lookup"><span data-stu-id="2343e-217">For your design, to create a pleasant and comfortable experience for your users, we recommend that targets should be at least 2° in visual angle, preferably larger.</span></span>

- <span data-ttu-id="2343e-218">Unregelmäßige **Augenblicke Bewegungen** Unsere Augen führen zu schnellen Bewegungen von der Fixierung bis zur Fixierung.</span><span class="sxs-lookup"><span data-stu-id="2343e-218">**Ragged eye-gaze movements** Our eyes perform rapid movements from fixation to fixation.</span></span> <span data-ttu-id="2343e-219">Wenn Sie Scanwege aufgezeichneter Blickbewegungen betrachten, können Sie die Flatterhaftigkeit erkennen.</span><span class="sxs-lookup"><span data-stu-id="2343e-219">If you look at scan paths of recorded eye movements, you can see that they look ragged.</span></span> <span data-ttu-id="2343e-220">Die Augen werden schnell und in spontanen Sprüngen im Vergleich zu *Kopf-* und *Handbewegungen*bewegt.</span><span class="sxs-lookup"><span data-stu-id="2343e-220">Your eyes move quickly and in spontaneous jumps in comparison to *head-gaze* or *hand motions*.</span></span>  

- <span data-ttu-id="2343e-221">**Zuverlässigkeit der Verfolgung:** Die Genauigkeit der Blickverfolgung wird ein wenig bei sich ändernden Lichtverhältnissen beeinträchtigt, während sich das Auge an die neuen Bedingungen anpasst.</span><span class="sxs-lookup"><span data-stu-id="2343e-221">**Tracking reliability:** Eye tracking accuracy may degrade a little in changing light as your eye adjust to the new conditions.</span></span>
<span data-ttu-id="2343e-222">Dies sollte sich nicht notwendigerweise auf den Entwurf Ihrer Anwendung auswirken, da die Genauigkeit innerhalb der Begrenzung von 2 ° liegen sollte, ist es möglicherweise erforderlich, dass der Benutzer erneut eine Kalibrierung durchführe.</span><span class="sxs-lookup"><span data-stu-id="2343e-222">While this should not necessarily affect your application design, as the accuracy should be within the 2° limitation, i might be necessary for the user to calibrate again.</span></span> 


## <a name="design-recommendations"></a><span data-ttu-id="2343e-223">Entwurfsempfehlungen</span><span class="sxs-lookup"><span data-stu-id="2343e-223">Design recommendations</span></span>
<span data-ttu-id="2343e-224">Im folgenden finden Sie eine Liste mit spezifischen Entwurfs Empfehlungen, die auf den beschriebenen Vorteilen und Herausforderungen für die Augenblick Eingabe basieren:</span><span class="sxs-lookup"><span data-stu-id="2343e-224">The following is a list of specific design recommendations based on the described advantages and challenges for eye-gaze input:</span></span>

1. <span data-ttu-id="2343e-225">**Der Augenblick ist nicht der gleiche wie der Haupt Blick:**</span><span class="sxs-lookup"><span data-stu-id="2343e-225">**Eye-gaze is not the same as Head-gaze:**</span></span>
    - <span data-ttu-id="2343e-226">**Überlegen Sie, ob schnelle, aber gleichzeitig flatterhafte Blickbewegungen zu der Eingabeaufgabe passen:** Während unsere schnellen und unregelmäßigen Augenbewegungen bei der schnellen Auswahl von Zielen im Sichtbereich sehr nützlich sind, sind Sie für Aufgaben, die Smooth-Eingabe-Bewegungsabläufe erfordern (z. b. das Zeichnen oder einschließen von Anmerkungen), weniger anwendbar.</span><span class="sxs-lookup"><span data-stu-id="2343e-226">**Consider whether fast yet ragged eye movements fit your input task:** While our fast and ragged eye movements are great at quickly selecting targets across our field of view, it is less applicable for tasks that require smooth input trajectories (e.g., drawing or encircling annotations).</span></span> <span data-ttu-id="2343e-227">In diesem Fall ist das Zeigen mit Hand oder Kopf zu bevorzugen.</span><span class="sxs-lookup"><span data-stu-id="2343e-227">In this case, hand or head pointing should be preferred.</span></span>
  
    - <span data-ttu-id="2343e-228">**Vermeiden Sie, etwas direkt an den Augenblick des Benutzers anzufügen (z. b. einen Schieberegler oder Cursor).**</span><span class="sxs-lookup"><span data-stu-id="2343e-228">**Avoid attaching something directly to the user’s eye-gaze (e.g., a slider or cursor).**</span></span>
<span data-ttu-id="2343e-229">Bei einem Cursor führt dies möglicherweise zu einem "flüchtig Cursor"-Effekt aufgrund geringfügiger Offsets im projizierten Augenblick Signal.</span><span class="sxs-lookup"><span data-stu-id="2343e-229">In case of a cursor, this may result in the “fleeing cursor” effect due to slight offsets in the projected eye-gaze signal.</span></span> <span data-ttu-id="2343e-230">Im Fall eines Schiebereglers kann der Schieberegler mit der doppelten Rolle des Schiebereglers in Konflikt stehen, während gleichzeitig überprüft werden soll, ob sich das Objekt am richtigen Speicherort befindet.</span><span class="sxs-lookup"><span data-stu-id="2343e-230">In case of a slider, it can conflict with the double role of controlling the slider with your eyes while also wanting to check whether the object is at the correct location.</span></span> <span data-ttu-id="2343e-231">Kurz gesagt, können Benutzer überlastet und abgelenkt werden, insbesondere wenn das Signal für diesen Benutzer unpräzise ist.</span><span class="sxs-lookup"><span data-stu-id="2343e-231">In a nutshell, users could become overwhelmed and distracted, especially if the signal is imprecise for that user.</span></span> 
  
2. <span data-ttu-id="2343e-232">**Kombinieren Sie den Augenblick mit anderen Eingaben:** Die Integration der Eye-Nachverfolgung mit anderen Eingaben, z. b. Handgesten, Sprachbefehle oder Schaltflächen drückt, bietet mehrere Vorteile:</span><span class="sxs-lookup"><span data-stu-id="2343e-232">**Combine eye-gaze with other inputs:** The integration of eye tracking with other inputs, such as hand gestures, voice commands or button presses, serves several advantages:</span></span>
    - <span data-ttu-id="2343e-233">**Möglichkeit der freien Betrachtung:** Die Hauptrolle unserer Augen besteht darin, unsere Umgebung zu beobachten. es ist wichtig, dass Benutzer die Möglichkeit haben, sich anzusehen, ohne irgendwelche (visuellen, auditiven usw.) Feedback oder Aktionen auszulösen.</span><span class="sxs-lookup"><span data-stu-id="2343e-233">**Allow for free observation:** Given that the main role of our eyes is to observe our environment, it is important users are allowed to look around without triggering any (visual, auditory, etc.) feedback or actions.</span></span> 
    <span data-ttu-id="2343e-234">Das Kombinieren der Eye-Nachverfolgung mit einem anderen Eingabe Steuerelement ermöglicht einen reibungslosen Übergang zwischen der Überwachung der Augen Verfolgung und den Eingabe</span><span class="sxs-lookup"><span data-stu-id="2343e-234">Combining eye tracking with another input control allows smooth transitioning between eye tracking observation and input control modes.</span></span>
  
    - <span data-ttu-id="2343e-235">**Leistungsstarker Kontextanbieter:** Wenn Sie Informationen dazu verwenden, wo und was der Benutzer beim ututing eines sprach Befehls oder beim Ausführen einer Handbewegung sucht, kann die Eingabe nahtlos über das Feld der Ansicht hinweg übertragen werden.</span><span class="sxs-lookup"><span data-stu-id="2343e-235">**Powerful context provider:** Using information about where and what the user is looking at while uttering a voice command or performing a hand gesture allows seamlessly channeling the input across the field-of-view.</span></span> <span data-ttu-id="2343e-236">Zum Beispiel: Mit „Put that there“ (Auswählen, Verschieben, ...hierhin) können Sie schnell und flüssig ein Hologramm auswählen und über die Szene verschieben. Dazu brauchen Sie nur ein Ziel und den Bestimmungsort anzuschauen.</span><span class="sxs-lookup"><span data-stu-id="2343e-236">For example: “Put that there” to quickly and fluently select and position a hologram across the scene by simply looking at a target and destination.</span></span> 

    - <span data-ttu-id="2343e-237">**Multimodale Eingaben müssen synchronisiert werden (Problem des vor dem Klicken abgewendeten Blicks):** Das Kombinieren von Rapid Eye-Bewegungen mit komplexeren zusätzlichen Eingaben, wie z. b. langen Sprachbefehlen oder Handgesten, birgt das Risiko, dass Sie Ihren Blick vor dem Abschluss des zusätzlichen Eingabe Befehls fortsetzen.</span><span class="sxs-lookup"><span data-stu-id="2343e-237">**Need for synchronizing multimodal inputs (“leave before click” issue):** Combining rapid eye movements with more complex additional inputs, such as long voice commands or hand gestures, bears the risk of continuing your eye-gaze before finishing the additional input command.</span></span> <span data-ttu-id="2343e-238">Wenn Sie also Ihre eigenen Eingabe Steuerelemente erstellen (z. b. benutzerdefinierte Handgesten), sollten Sie das Auftreten dieser Eingabe oder der ungefähren Dauer protokollieren, um Sie mit dem zu korrelieren, was ein Benutzer in der Vergangenheit gesehen hat.</span><span class="sxs-lookup"><span data-stu-id="2343e-238">Hence, if you create your own input controls (e.g., custom hand gestures), make sure to log the onset of this input or approximate duration to correlate it with what a user had looked at in the past.</span></span>
    
3. <span data-ttu-id="2343e-239">**Dezentes Feedback für Eingaben über die Blickverfolgung:** Es ist hilfreich, Feedback zu geben, wenn ein Ziel untersucht wird, um anzugeben, dass das System wie beabsichtigt funktioniert, aber dennoch gering gehalten werden sollte.</span><span class="sxs-lookup"><span data-stu-id="2343e-239">**Subtle feedback for eye tracking input:** It's useful to provide feedback when a target is looked at to indicate that the system is working as intended but should be kept subtle.</span></span> <span data-ttu-id="2343e-240">Dies kann eine langsame Mischung, ein-und ausgehende, visuelle Highlights oder andere, feine Ziel Verhaltensweisen, wie z. b. langsame Bewegungen, z. b. eine geringfügige Erhöhung der Zielgröße, beinhalten, um anzugeben, dass das System ordnungsgemäß erkannt hat, dass der Benutzer ein Ziel unnötiges unterbrechen des aktuellen Workflows des Benutzers.</span><span class="sxs-lookup"><span data-stu-id="2343e-240">This can include slowly blending, in and out, visual highlights or perform other subtle target behaviors, such as slow motions, such as slightly increasing the target size, to indicate that the system correctly detected that the user is looking at a target without unnecessarily interrupting the user’s current workflow.</span></span> 

4. <span data-ttu-id="2343e-241">**Vermeiden des Erzwingens unnatürlicher Augenbewegungen für die Eingabe:** Erzwingen Sie nicht, dass Benutzer bestimmte Augenbewegungen (Augenbewegungen) ausführen, um Aktionen in der Anwendung zu initiieren.</span><span class="sxs-lookup"><span data-stu-id="2343e-241">**Avoid enforcing unnatural eye movements as input:** Do not force users to perform specific eye movements (gaze gestures) to trigger actions in your application.</span></span>

5. <span data-ttu-id="2343e-242">**Berücksichtigen von Ungenauigkeiten:** Wir unterscheiden zwei Arten von imsions, die für die Benutzer bemerkbar sind: Offset und Jitter.</span><span class="sxs-lookup"><span data-stu-id="2343e-242">**Account for imprecisions:** We distinguish two types of imprecisions which are noticeable to users: offset and jitter.</span></span> <span data-ttu-id="2343e-243">Die einfachste Möglichkeit, einen Offset zu behandeln, besteht darin, ausreichend große Ziele für die Interaktion bereitzustellen.</span><span class="sxs-lookup"><span data-stu-id="2343e-243">The easiest way to address an offset is to provide sufficiently large targets to interact with.</span></span> <span data-ttu-id="2343e-244">Es wird empfohlen, einen visuellen Winkel größer als 2 ° als Verweis zu verwenden.</span><span class="sxs-lookup"><span data-stu-id="2343e-244">It is suggested that you use a visual angle greater than 2° as a reference.</span></span> <span data-ttu-id="2343e-245">Beispielsweise ist die Miniaturansicht ungefähr 2 ° im visuellen Winkel, wenn Sie den Arm ausdehnen.</span><span class="sxs-lookup"><span data-stu-id="2343e-245">For instance, your thumbnail is about 2° in visual angle when you stretch out your arm.</span></span> <span data-ttu-id="2343e-246">Dies führt zu folgender Richtlinie:</span><span class="sxs-lookup"><span data-stu-id="2343e-246">This leads to the following guidance:</span></span>
    - <span data-ttu-id="2343e-247">Erzwingen Sie nicht, dass Benutzer kleine Ziele auswählen.</span><span class="sxs-lookup"><span data-stu-id="2343e-247">Do not force users to select tiny targets.</span></span> <span data-ttu-id="2343e-248">Die Untersuchung hat ergeben, dass die Interaktionen, wenn die Ziele ausreichend groß sind und das System gut entworfen wurde, mühelos und magisch beschrieben werden.</span><span class="sxs-lookup"><span data-stu-id="2343e-248">Research has shown that if targets are sufficiently large, and that the system is designed well, users describe their interactions as effortless and magical.</span></span> <span data-ttu-id="2343e-249">Wenn Ziele zu klein sind, empfinden Benutzer die Erfahrung als ermüdend und frustrierend.</span><span class="sxs-lookup"><span data-stu-id="2343e-249">If targets become too small, users describe the experience as fatiguing and frustrating.</span></span>
  
## <a name="dev-guidance-what-if-eye-tracking-is-not-available"></a><span data-ttu-id="2343e-250">Leitfaden für Entwickler: Was geschieht, wenn die Augen Verfolgung nicht verfügbar ist?</span><span class="sxs-lookup"><span data-stu-id="2343e-250">Dev guidance: What if eye tracking is not available?</span></span>
<span data-ttu-id="2343e-251">Es kann Situationen geben, in denen Ihre APP aufgrund verschiedener Gründe keine Augen Verfolgungs Daten empfängt, einschließlich, aber nicht beschränkt auf:</span><span class="sxs-lookup"><span data-stu-id="2343e-251">There may be situations in which your app will not receive any eye tracking data due to various reasons including but not limited to:</span></span>
* <span data-ttu-id="2343e-252">Der Benutzer hat die Eye Tracking-Kalibrierung übersprungen.</span><span class="sxs-lookup"><span data-stu-id="2343e-252">The user skipped the eye tracking calibration.</span></span>
* <span data-ttu-id="2343e-253">Der Benutzer hat eine Kalibrierung durchführen, entschied sich aber dafür, der APP keine Berechtigung zur Verwendung Ihrer Überwachungsdaten zu erteilen.</span><span class="sxs-lookup"><span data-stu-id="2343e-253">The user calibrated, but decided to not give permission to your app to use their eye tracking data.</span></span>
* <span data-ttu-id="2343e-254">Der Benutzer hat eine eindeutige Brillen-oder Augen Bedingung, die vom System noch nicht unterstützt wird.</span><span class="sxs-lookup"><span data-stu-id="2343e-254">The user has unique eyeglasses or some eye condition that the system does not yet support.</span></span>
* <span data-ttu-id="2343e-255">Externe Faktoren behindern die zuverlässige Eye-Nachverfolgung, wie z. b. smudges auf den holten-Hypervisor oder-Brillen, intensive direkte Sonneneinstrahlung und-oksionen aufgrund von Haaren vor Augen.</span><span class="sxs-lookup"><span data-stu-id="2343e-255">External factors inhibiting reliable eye tracking such as smudges on the HoloLens visor or eyeglasses, intense direct sunlight and occlusions due to hair in front of the eyes.</span></span>

<span data-ttu-id="2343e-256">Als App-Entwickler bedeutet dies, dass Sie die Unterstützung von Benutzern berücksichtigen müssen, für die möglicherweise keine Überwachungsdaten verfügbar sind.</span><span class="sxs-lookup"><span data-stu-id="2343e-256">For you as an app developer, this means that you need to account for how to support users for whom eye tracking data may not be available.</span></span> <span data-ttu-id="2343e-257">Im folgenden wird erläutert, wie Sie erkennen können, ob die Eye-Nachverfolgung verfügbar ist, und wie Sie sich behandeln, wenn Sie für verschiedene Anwendungen nicht verfügbar ist.</span><span class="sxs-lookup"><span data-stu-id="2343e-257">Below we first explain how to detect whether eye tracking is available and how to address when it is not available for different applications.</span></span>

### <a name="1-how-to-detect-that-eye-tracking-is-available"></a><span data-ttu-id="2343e-258">1. So erkennen Sie, dass die Augen Verfolgung verfügbar ist</span><span class="sxs-lookup"><span data-stu-id="2343e-258">1. How to detect that eye tracking is available</span></span>
<span data-ttu-id="2343e-259">Es gibt einige Überprüfungen, um zu bestimmen, ob die Augen Verfolgungs Daten verfügbar sind.</span><span class="sxs-lookup"><span data-stu-id="2343e-259">There are a few checks to determine whether eye tracking data is available.</span></span> <span data-ttu-id="2343e-260">Überprüfen Sie, ob...</span><span class="sxs-lookup"><span data-stu-id="2343e-260">Check whether...</span></span>
* <span data-ttu-id="2343e-261">... Das System unterstützt die Augen Verfolgung überhaupt.</span><span class="sxs-lookup"><span data-stu-id="2343e-261">... the system supports eye tracking at all.</span></span> <span data-ttu-id="2343e-262">Nennen Sie die folgende *Methode*: [Windows. perception. People. eyespose. IsSupported ()](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.eyespose.issupported#Windows_Perception_People_EyesPose_IsSupported)</span><span class="sxs-lookup"><span data-stu-id="2343e-262">Call the following *method*: [Windows.Perception.People.EyesPose.IsSupported()](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.eyespose.issupported#Windows_Perception_People_EyesPose_IsSupported)</span></span>

* <span data-ttu-id="2343e-263">... der Benutzer ist kalibriert.</span><span class="sxs-lookup"><span data-stu-id="2343e-263">... the user is calibrated.</span></span> <span data-ttu-id="2343e-264">Nennen Sie die folgende *Eigenschaft*: [Windows. perception. People. eyespose. iscalibrationvalid](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.eyespose.iscalibrationvalid#Windows_Perception_People_EyesPose_IsCalibrationValid)</span><span class="sxs-lookup"><span data-stu-id="2343e-264">Call the following *property*: [Windows.Perception.People.EyesPose.IsCalibrationValid](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.eyespose.iscalibrationvalid#Windows_Perception_People_EyesPose_IsCalibrationValid)</span></span>

* <span data-ttu-id="2343e-265">... der Benutzer hat der APP die Berechtigung zur Verwendung der Augen Verfolgungs Daten erteilt: Rufen Sie den aktuellen _"gazinput Access Status"_ ab.</span><span class="sxs-lookup"><span data-stu-id="2343e-265">... the user has given your app permission to use their eye tracking data: Retrieve the current _'GazeInputAccessStatus'_.</span></span> <span data-ttu-id="2343e-266">Ein Beispiel hierfür finden Sie unter [anfordern des Zugriffs auf die Eingabe](https://docs.microsoft.com/en-us/windows/mixed-reality/gaze-in-directX#requesting-access-to-gaze-input).</span><span class="sxs-lookup"><span data-stu-id="2343e-266">An example on how to do this is explained at [Requesting access to gaze input](https://docs.microsoft.com/en-us/windows/mixed-reality/gaze-in-directX#requesting-access-to-gaze-input).</span></span>

<span data-ttu-id="2343e-267">Darüber hinaus können Sie überprüfen, ob Ihre Augen Verfolgungs Daten nicht veraltet sind, indem Sie ein Timeout zwischen empfangenen Datenaktualisierungen für die Augen Verfolgung hinzufügen und andernfalls auf den Haupt Blick zurückgreifen, wie unten erläutert.</span><span class="sxs-lookup"><span data-stu-id="2343e-267">In addition, you may want to check that your eye tracking data is not stale by adding a timeout between received eye tracking data updates and otherwise fallback to head-gaze as discussed below.</span></span> 

<span data-ttu-id="2343e-268">Wie oben beschrieben, gibt es verschiedene Gründe, warum die Augen Verfolgungs Daten möglicherweise nicht verfügbar sind.</span><span class="sxs-lookup"><span data-stu-id="2343e-268">As described above, there are several reasons why eye tracking data may not be available.</span></span> <span data-ttu-id="2343e-269">Einige Benutzer haben sich möglicherweise bewusst entschieden, den Zugriff auf Ihre Augen Verfolgungs Daten aufzuheben, und sind mit dem Nachteil einer geringeren Benutzerfunktion für den Datenschutz, dass Sie keinen Zugriff auf Ihre Überwachungsdaten bereitstellt, in einigen Fällen kann dies unbeabsichtigt sein.</span><span class="sxs-lookup"><span data-stu-id="2343e-269">While some users may have consciously decided to revoke access to their eye tracking data and are ok with the trade-off of an inferior user experience to the privacy of not providing access to their eye tracking data, in some cases this may be unintentional.</span></span> <span data-ttu-id="2343e-270">Wenn Ihre APP die Augen Nachverfolgung verwendet, und dies ein wichtiger Bestandteil der Benutzeroberflächen ist, empfiehlt es sich, diese Funktion an den Benutzer zu übermitteln.</span><span class="sxs-lookup"><span data-stu-id="2343e-270">Hence, if your app uses eye tracking, and this is an important part of the experience, we recommend clearly communicating this to the user.</span></span> <span data-ttu-id="2343e-271">Wenn Sie den Benutzer darüber informieren, warum die Augen Verfolgung für Ihre Anwendung wichtig ist (möglicherweise sogar durch das Auflisten einiger verbesserter Features), um das volle Potenzial Ihrer Anwendung zu erhalten, können Sie dem Benutzer helfen, die Ergebnisse besser zu verstehen.</span><span class="sxs-lookup"><span data-stu-id="2343e-271">Kindly informing the user why eye tracking is critical for your application (maybe even listing some enhanced features) to experience the full potential of your application can help the user to better understand what they are giving up.</span></span> <span data-ttu-id="2343e-272">Helfen Sie dem Benutzer, herauszufinden, warum die Eye-Nachverfolgung möglicherweise nicht funktioniert (basierend auf den obigen Überprüfungen), und bieten Sie einige Vorschläge, um potenzielle Probleme schnell zu beheben.</span><span class="sxs-lookup"><span data-stu-id="2343e-272">Help the user to identify why eye tracking may not be working (based on the above checks) and offer some suggestions to quickly troubleshoot potential issues.</span></span> <span data-ttu-id="2343e-273">Wenn Sie z. b. feststellen können, dass das System die Eye-Nachverfolgung unterstützt, wird der Benutzer kalibriert und selbst seine Berechtigung erteilt, aber es werden keine Augen Verfolgungs Daten empfangen.</span><span class="sxs-lookup"><span data-stu-id="2343e-273">For example, if you can detect that the system supports eye tracking, the user is calibrated and even has given their permission, yet no eye tracking data is received, then this may point to some other issues such as smudges or the eyes being occluded.</span></span> <span data-ttu-id="2343e-274">Beachten Sie jedoch, dass es selten Fälle gibt, in denen die Eye-Nachverfolgung möglicherweise einfach nicht funktioniert.</span><span class="sxs-lookup"><span data-stu-id="2343e-274">Please note though that there are rare cases of users for whom eye tracking may simply not work.</span></span> <span data-ttu-id="2343e-275">Achten Sie daher darauf, dass Sie Erinnerungen zum Aktivieren der Eye-Nachverfolgung in Ihrer APP verwerfen oder sogar deaktivieren können.</span><span class="sxs-lookup"><span data-stu-id="2343e-275">Hence, please be respectful of that by allowing to dismiss or even disable reminders for enabling eye tracking in your app.</span></span>

### <a name="2-fallback-for-apps-using-eye-gaze-as-a-primary-input-pointer"></a><span data-ttu-id="2343e-276">2. Fallback für apps, die den Augenblick als primären Eingabe Zeiger verwenden</span><span class="sxs-lookup"><span data-stu-id="2343e-276">2. Fallback for apps using eye-gaze as a primary input pointer</span></span>
<span data-ttu-id="2343e-277">Wenn Ihre APP den Augenblick als Zeiger Eingabe verwendet, um in der Szene schnell holograms auszuwählen, sind die Augen Verfolgungs Daten nicht verfügbar. es wird empfohlen, auf den Mauszeiger zurückzukehren und den Cursor für den Cursor zu zeigen.</span><span class="sxs-lookup"><span data-stu-id="2343e-277">If your app uses eye-gaze as a pointer input to quickly select holograms across the scene, yet eye tracking data is unavailable, we recommend falling back to head-gaze and start showing the head-gaze cursor.</span></span> <span data-ttu-id="2343e-278">Es wird empfohlen, ein Timeout (z. b. 500 – 1.500 ms) zu verwenden, um zu bestimmen, ob gewechselt werden soll.</span><span class="sxs-lookup"><span data-stu-id="2343e-278">We recommend using a timeout (e.g., 500–1500 ms) to determine whether to switch or not.</span></span> <span data-ttu-id="2343e-279">Dadurch wird verhindert, dass ein Cursor jedes Mal, wenn das System die Nachverfolgung aufgrund von schnellen Augenbewegungen oder winas und Blinks verliert.</span><span class="sxs-lookup"><span data-stu-id="2343e-279">This is to prevent popping up a cursor every time the system may briefly lose tracking due to fast eye motions or winks and blinks.</span></span> <span data-ttu-id="2343e-280">Wenn Sie ein Unity-Entwickler sind, wird der automatische Fall Back auf den Head-Blick bereits im Mixed Reality Toolkit behandelt.</span><span class="sxs-lookup"><span data-stu-id="2343e-280">If you are a Unity developer, the automatic fallback to head-gaze is already handled in the Mixed Reality Toolkit.</span></span> <span data-ttu-id="2343e-281">Wenn Sie ein DirectX-Entwickler sind, müssen Sie diesen Switch selbst verarbeiten.</span><span class="sxs-lookup"><span data-stu-id="2343e-281">If you are a DirectX developer, you need to handle this switch yourself.</span></span>

### <a name="3-fallback-for-other-eye-tracking-specific-applications"></a><span data-ttu-id="2343e-282">3. Fallback für andere Überwachungs spezifische Anwendungen</span><span class="sxs-lookup"><span data-stu-id="2343e-282">3. Fallback for other eye-tracking-specific applications</span></span>
<span data-ttu-id="2343e-283">Ihre APP kann den Augenblick auf eine einzigartige Weise verwenden, die speziell auf die Augen zugeschnitten ist, z. b. zum Animieren der Augen eines Avatars oder zur Augen basierten Aufmerksamkeit Heatmaps, die sich auf genaue Informationen zur visuellen Aufmerksamkeit verlassen.</span><span class="sxs-lookup"><span data-stu-id="2343e-283">Your app may use eye-gaze in a unique way that is tailored specifically to the eyes - for example, for animating an avatar’s eyes or for eye-based attention heatmaps relying on precise information about visual attention.</span></span> <span data-ttu-id="2343e-284">In diesem Fall gibt es keinen klaren Fallback.</span><span class="sxs-lookup"><span data-stu-id="2343e-284">In this case, there is no clear fallback.</span></span> <span data-ttu-id="2343e-285">Wenn die Augen Verfolgung nicht verfügbar ist, müssen diese Funktionen möglicherweise einfach deaktiviert werden.</span><span class="sxs-lookup"><span data-stu-id="2343e-285">If eye tracking is not available, these capabilities may simply need to be disabled.</span></span> 

<br>

<span data-ttu-id="2343e-286">Auf dieser Seite haben Sie hoffentlich einen guten Überblick erhalten, mit dem Sie die Rolle der Eye-Nachverfolgung und die Eingabe des Augenblicks für hololens 2 verstanden haben.</span><span class="sxs-lookup"><span data-stu-id="2343e-286">This page has hopefully provided you with a good overview to get you started understanding the role of eye tracking and eye-gaze input for HoloLens 2.</span></span> <span data-ttu-id="2343e-287">Informationen zu den ersten Schritten bei der Entwicklung finden Sie in den Informationen zu den [Augenblicken in Unity](https://aka.ms/mrtk-eyes) und im Blickwinkel [in DirectX](gaze-in-directx.md).</span><span class="sxs-lookup"><span data-stu-id="2343e-287">To get started developing, check out our information on [eye-gaze in Unity](https://aka.ms/mrtk-eyes) and [eye-gaze in DirectX](gaze-in-directx.md).</span></span>


## <a name="see-also"></a><span data-ttu-id="2343e-288">Siehe auch</span><span class="sxs-lookup"><span data-stu-id="2343e-288">See also</span></span>
* [<span data-ttu-id="2343e-289">Blick in DirectX</span><span class="sxs-lookup"><span data-stu-id="2343e-289">Eye-gaze in DirectX</span></span>](gaze-in-directx.md)
* [<span data-ttu-id="2343e-290">Blick in Unity (Mixed Reality Toolkit)</span><span class="sxs-lookup"><span data-stu-id="2343e-290">Eye-gaze in Unity (Mixed Reality Toolkit)</span></span>](https://aka.ms/mrtk-eyes)
* [<span data-ttu-id="2343e-291">Kalibrierung</span><span class="sxs-lookup"><span data-stu-id="2343e-291">Calibration</span></span>](calibration.md)
* [<span data-ttu-id="2343e-292">Anvisieren mit dem Kopf und Ausführen</span><span class="sxs-lookup"><span data-stu-id="2343e-292">Head-gaze and commit</span></span>](gaze-and-commit.md)
* [<span data-ttu-id="2343e-293">Handgesten</span><span class="sxs-lookup"><span data-stu-id="2343e-293">Hand gestures</span></span>](gestures.md)
* [<span data-ttu-id="2343e-294">Spracheingabe</span><span class="sxs-lookup"><span data-stu-id="2343e-294">Voice input</span></span>](voice-design.md)
* [<span data-ttu-id="2343e-295">Motion-Controller</span><span class="sxs-lookup"><span data-stu-id="2343e-295">Motion controllers</span></span>](motion-controllers.md)
* [<span data-ttu-id="2343e-296">Komfort</span><span class="sxs-lookup"><span data-stu-id="2343e-296">Comfort</span></span>](comfort.md)
