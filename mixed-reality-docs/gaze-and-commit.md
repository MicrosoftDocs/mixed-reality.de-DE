---
title: Anvisieren mit dem Kopf und Ausführen
description: Übersicht über das Eingabemodell „Anvisieren mit dem Kopf und Ausführen“
author: caseymeekhof
ms.author: cmeekhof
ms.date: 03/31/2019
ms.topic: article
ms.localizationpriority: high
keywords: Mixed Reality, Anvisieren, Zielbestimmung, Interaktion, Entwurf
ms.openlocfilehash: d9eae3c0cfceba7c2c31425941dfce865f3aa609
ms.sourcegitcommit: f20beea6a539d04e1d1fc98116f7601137eebebe
ms.translationtype: HT
ms.contentlocale: de-DE
ms.lasthandoff: 06/05/2019
ms.locfileid: "66692302"
---
# <a name="head-gaze-and-commit"></a><span data-ttu-id="48cc4-104">Anvisieren mit dem Kopf und Ausführen</span><span class="sxs-lookup"><span data-stu-id="48cc4-104">Head-gaze and commit</span></span>
<span data-ttu-id="48cc4-105">„Anvisieren mit dem Kopf und Ausführen“ ist ein Eingabemodell, das die Zielbestimmung für ein Objekt umfasst, bei der Ihr Kopf nach vorne gerichtet (Kopfrichtung) ist, und die Interaktion dann mit einer sekundären Eingabemethode (z. B. mit der Handgeste „In die Luft tippen“ oder mit dem Sprachbefehl „Auswählen“) erfolgt.</span><span class="sxs-lookup"><span data-stu-id="48cc4-105">Head-gaze and commit is an input model that involves targeting an object with the direction of your head pointing forward (head-direction), and then acting on it with a secondary input such as the hand gesture Air Tap or the voice command “Select”.</span></span> <span data-ttu-id="48cc4-106">Es gilt als „fernes“ Eingabemodell mit indirekter Bearbeitung, d. h. es wird am besten für die Interaktion mit Inhalten verwendet, die außerhalb der Reichweite der Arme liegen.</span><span class="sxs-lookup"><span data-stu-id="48cc4-106">It is considered a "far" input model with indirect manipulation, meaning it is best used for interacting with content that is beyond arms reach.</span></span>

## <a name="device-support"></a><span data-ttu-id="48cc4-107">Unterstützung von Geräten</span><span class="sxs-lookup"><span data-stu-id="48cc4-107">Device support</span></span>

<table>
    <colgroup>
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    </colgroup>
    <tr>
        <td><span data-ttu-id="48cc4-108"><strong>Eingabemodell</strong></span><span class="sxs-lookup"><span data-stu-id="48cc4-108"><strong>Input model</strong></span></span></td>
        <td><span data-ttu-id="48cc4-109"><a href="hololens-hardware-details.md"><strong>HoloLens (1. Generation)</strong></a></span><span class="sxs-lookup"><span data-stu-id="48cc4-109"><a href="hololens-hardware-details.md"><strong>HoloLens (1st gen)</strong></a></span></span></td>
        <td><span data-ttu-id="48cc4-110"><strong>HoloLens 2</strong></span><span class="sxs-lookup"><span data-stu-id="48cc4-110"><strong>HoloLens 2</strong></span></span></td>
        <td><span data-ttu-id="48cc4-111"><a href="immersive-headset-hardware-details.md"><strong>Immersive Headsets</strong></a></span><span class="sxs-lookup"><span data-stu-id="48cc4-111"><a href="immersive-headset-hardware-details.md"><strong>Immersive headsets</strong></a></span></span></td>
    </tr>
     <tr>
        <td><span data-ttu-id="48cc4-112">Anvisieren mit dem Kopf und Ausführen</span><span class="sxs-lookup"><span data-stu-id="48cc4-112">Head-gaze and commit</span></span></td>
        <td><span data-ttu-id="48cc4-113">✔️ Empfohlen</span><span class="sxs-lookup"><span data-stu-id="48cc4-113">✔️ Recommended</span></span></td>
        <td><span data-ttu-id="48cc4-114">✔️ Empfohlen (dritte Auswahl – <a href="interaction-fundamentals.md">Siehe andere Optionen</a>)</span><span class="sxs-lookup"><span data-stu-id="48cc4-114">✔️ Recommended (third choice - <a href="interaction-fundamentals.md">See the other options</a>)</span></span></td>
        <td><span data-ttu-id="48cc4-115">➕ Alternative Option</span><span class="sxs-lookup"><span data-stu-id="48cc4-115">➕ Alternate option</span></span></td>
    </tr>
</table>

## <a name="head-gaze"></a><span data-ttu-id="48cc4-116">Anvisieren mit dem Kopf</span><span class="sxs-lookup"><span data-stu-id="48cc4-116">Head-gaze</span></span>
<span data-ttu-id="48cc4-117">Mixed Reality-Headsets nutzen Position und Ausrichtung des Kopfes des Benutzers, um dessen Kopfrichtungsvektor zu bestimmen.</span><span class="sxs-lookup"><span data-stu-id="48cc4-117">Mixed reality headsets use the position and orientation of the user's head to determine their head direction vector.</span></span> <span data-ttu-id="48cc4-118">Sie können sich dies als einen Laser vorstellen, der direkt zwischen den Augen des Benutzers geradeaus zeigt.</span><span class="sxs-lookup"><span data-stu-id="48cc4-118">You can think of this as a laser that points straight ahead from directly between the user's eyes.</span></span> <span data-ttu-id="48cc4-119">Dies ist eine ziemlich grobe Annäherung hinsichtlich der Position, die der Benutzer betrachtet.</span><span class="sxs-lookup"><span data-stu-id="48cc4-119">This is a fairly coarse approximation of where the user is looking.</span></span> <span data-ttu-id="48cc4-120">Ihre Anwendung kann diesen Strahl mit virtuellen oder realen Objekten kreuzen und einen Cursor an dieser Stelle darstellen, um dem Benutzer sein aktuelles Ziel mitzuteilen.</span><span class="sxs-lookup"><span data-stu-id="48cc4-120">Your application can intersect this ray with virtual or real-world objects and draw a cursor at that location to let the user know what they are currently targeting.</span></span>

<span data-ttu-id="48cc4-121">Zusätzlich zum Anvisieren mit dem Kopf umfassen einige Mixed Reality-Headsets wie die HoloLens 2 entsprechende Eyetrackingsysteme, die einen Vektor zum Anvisieren mit den Augen erzeugen.</span><span class="sxs-lookup"><span data-stu-id="48cc4-121">In addition to head gaze, some mixed reality headsets like the HoloLens 2 include eye tracking systems that produce an eye-gaze vector.</span></span> <span data-ttu-id="48cc4-122">Dies ermöglicht eine präzisere Messung der Position, die der Benutzer betrachtet.</span><span class="sxs-lookup"><span data-stu-id="48cc4-122">This provides a fine-grained measurement of where the user is looking.</span></span> <span data-ttu-id="48cc4-123">Es ist möglich, Interaktionen für „Anvisieren mit dem Kopf und Ausführen“ mithilfe von „Anvisieren mit den Augen“ zu erstellen, aber dies umfasst einen ganz anderen Satz von Designeinschränkungen, die separat im [Artikel zum Eyetracking](eye-tracking.md) behandelt werden.</span><span class="sxs-lookup"><span data-stu-id="48cc4-123">It is possible to build gaze and commit interactions using eye gaze, but this comes with a very different set of design constraints, which will be covered separately in the [eye tracking article](eye-tracking.md).</span></span>

## <a name="commit"></a><span data-ttu-id="48cc4-124">Ausführen</span><span class="sxs-lookup"><span data-stu-id="48cc4-124">Commit</span></span>
<span data-ttu-id="48cc4-125">Nachdem ein Objekt oder Element der Benutzeroberfläche anvisiert wurde, kann der Benutzer mithilfe einer sekundären Eingabemethode damit interagieren oder darauf „klicken“.</span><span class="sxs-lookup"><span data-stu-id="48cc4-125">After targeting an object or UI element, the user can interact or "click" on it using a secondary input.</span></span> <span data-ttu-id="48cc4-126">Dies wird als „Ausführen“-Schritt des Modells bezeichnet.</span><span class="sxs-lookup"><span data-stu-id="48cc4-126">This is known as the commit step of the model.</span></span> <span data-ttu-id="48cc4-127">Die folgenden Methoden zum Ausführen werden unterstützt:</span><span class="sxs-lookup"><span data-stu-id="48cc4-127">The following commit methods are supported:</span></span>

- <span data-ttu-id="48cc4-128">Tippbewegung in die Luft</span><span class="sxs-lookup"><span data-stu-id="48cc4-128">Air Tap gesture</span></span>
- <span data-ttu-id="48cc4-129">Aussprechen des Sprachbefehls „Auswählen“ oder eines der gewünschten Sprachbefehle</span><span class="sxs-lookup"><span data-stu-id="48cc4-129">Speak the voice command "Select" or one of the targeted voice commands</span></span>
- <span data-ttu-id="48cc4-130">Drücken der einzelnen Taste an einem [HoloLens-Klick-Gerät](hardware-accessories.md#hololens-clicker).</span><span class="sxs-lookup"><span data-stu-id="48cc4-130">Press the single button on a [HoloLens Clicker](hardware-accessories.md#hololens-clicker)</span></span>
- <span data-ttu-id="48cc4-131">Drücken der Taste „A“ an einem Xbox-Gamepad</span><span class="sxs-lookup"><span data-stu-id="48cc4-131">Press the 'A' button on an Xbox Gamepad</span></span>
- <span data-ttu-id="48cc4-132">Drücken der Taste „A“ an einem Xbox Adaptive Controller</span><span class="sxs-lookup"><span data-stu-id="48cc4-132">Press the 'A' button on an Xbox Adaptive Controller</span></span>

### <a name="head-gaze-and-air-tap-gesture"></a><span data-ttu-id="48cc4-133">Anvisieren mit dem Kopf und Tippbewegung in die Luft</span><span class="sxs-lookup"><span data-stu-id="48cc4-133">Head-gaze and air tap gesture</span></span>
<span data-ttu-id="48cc4-134">„In die Luft tippen“ ist eine Tippbewegung mit aufrecht gehaltener Hand</span><span class="sxs-lookup"><span data-stu-id="48cc4-134">Air tap is a tapping gesture with the hand held upright.</span></span> <span data-ttu-id="48cc4-135">Um die Methode „In die Luft tippen“ auszuführen, heben Sie Ihren Zeigefinger in die Bereitschaftsposition, führen Sie ihn dann mit dem Daumen zusammen, und heben Sie den Zeigefinger anschließend zur Freigabe wieder nach oben.</span><span class="sxs-lookup"><span data-stu-id="48cc4-135">To perform an Air tap, raise your index finger to the ready position, then pinch with your thumb and raise your index finger back up to release.</span></span> <span data-ttu-id="48cc4-136">Bei HoloLens 1 ist „In die Luft tippen“ die häufigste sekundäre Eingabemethode.</span><span class="sxs-lookup"><span data-stu-id="48cc4-136">On HoloLens 1, Air tap is the most common secondary input.</span></span>

![Finger in der Bereitschaftsposition und dann eine Tipp- oder Klickbewegung](images/readyandpress.jpg)<br>

<span data-ttu-id="48cc4-138">„In die Luft tippen“ ist auch für HoloLens 2 verfügbar und wurde gegenüber der ursprünglichen Version gelockert.</span><span class="sxs-lookup"><span data-stu-id="48cc4-138">Air tap is also available on HoloLens 2, and it has been relaxed from the original version.</span></span> <span data-ttu-id="48cc4-139">Jetzt werden fast alle Arten der Zusammenführung der Finger unterstützt, solange die Hand aufrecht und still gehalten wird.</span><span class="sxs-lookup"><span data-stu-id="48cc4-139">Nearly all types of pinches are now supported, as long as the hand is upright and holding still.</span></span> <span data-ttu-id="48cc4-140">Dadurch kann der Benutzer die Geste viel einfacher erlernen und ausführen.</span><span class="sxs-lookup"><span data-stu-id="48cc4-140">This makes it much easier for users to learn and perform the gesture.</span></span>  <span data-ttu-id="48cc4-141">Diese neue Methode beim „In die Luft tippen“ ersetzt die alte Methode mithilfe derselben API, sodass vorhandene Anwendungen das neue Verhalten automatisch nach dem erneuten Kompilieren für HoloLens 2 erhalten.</span><span class="sxs-lookup"><span data-stu-id="48cc4-141">This new Air tap replaces the old one through the same API, so existing applications will get the new behavior automatically after recompiling for HoloLens 2.</span></span>

### <a name="head-gaze-and-select-voice-command"></a><span data-ttu-id="48cc4-142">Anvisieren mit dem Kopf und Sprachbefehl „Auswählen“</span><span class="sxs-lookup"><span data-stu-id="48cc4-142">Head-gaze and "Select" voice command</span></span>
<span data-ttu-id="48cc4-143">Die Sprachsteuerung ist eine der wichtigsten Interaktionsmethoden für Mixed Reality.</span><span class="sxs-lookup"><span data-stu-id="48cc4-143">Voice commanding is one of the primary interaction methods on Mixed Reality.</span></span> <span data-ttu-id="48cc4-144">Sie bietet einen sehr leistungsstarken Mechanismus zum „Freisprechen“ zur Steuerung des Systems.</span><span class="sxs-lookup"><span data-stu-id="48cc4-144">It provides a very powerful "Hands Free" mechanism to control the system.</span></span> <span data-ttu-id="48cc4-145">Es gibt verschiedene Arten von Modellen für die Sprachinteraktion:</span><span class="sxs-lookup"><span data-stu-id="48cc4-145">There are diferent types of voice interaction models:</span></span>

- <span data-ttu-id="48cc4-146">Der generische Befehl „Auswählen“, der als sekundäre Eingabe eine „Klick“-Betätigung oder eine Ausführung ermöglicht.</span><span class="sxs-lookup"><span data-stu-id="48cc4-146">The generic command "Select" that allows to perform a "click" actuation or commit as a secondary input.</span></span>
- <span data-ttu-id="48cc4-147">Objektbefehle wie „Schließen“ oder „Vergrößern“, die als sekundäre Eingabe das Ausführen einer Aktion ermöglichen.</span><span class="sxs-lookup"><span data-stu-id="48cc4-147">Object commands like "Close" or "Make it bigger" that allow to perform and commit to an action as a secondary input.</span></span>
- <span data-ttu-id="48cc4-148">Globale Befehle wie „Zum Startmenü“, die kein Ziel erfordern.</span><span class="sxs-lookup"><span data-stu-id="48cc4-148">Global commnads like "Go to start" that don't require a target.</span></span>
- <span data-ttu-id="48cc4-149">Benutzeroberflächen für Unterhaltungen oder Entitäten wie Cortana, die über eine KI-Funktion für natürliche Sprache verfügen.</span><span class="sxs-lookup"><span data-stu-id="48cc4-149">Conversation user interfaces or entities like Cortana that have an AI Natural Language capability.</span></span>
- <span data-ttu-id="48cc4-150">Benutzerdefinierte Befehle</span><span class="sxs-lookup"><span data-stu-id="48cc4-150">Custom commnads</span></span>

<span data-ttu-id="48cc4-151">Weitere Details und eine ausführliche Liste zu den verfügbaren Befehle und deren Verwendung finden Sie in unserer Anleitung zur [Sprachsteuerung](voice-design.md).</span><span class="sxs-lookup"><span data-stu-id="48cc4-151">To find more details and a comprenhesive list of available commands and how to use, check out our [voice commanding](voice-design.md) guidance.</span></span>


### <a name="head-gaze-and-hololens-clicker"></a><span data-ttu-id="48cc4-152">Anvisieren mit dem Kopf und HoloLens-Klick-Gerät</span><span class="sxs-lookup"><span data-stu-id="48cc4-152">Head-gaze and HoloLens Clicker</span></span>
<span data-ttu-id="48cc4-153">Das HoloLens-Klick-Gerät ist das erste speziell für HoloLens entwickelte Peripheriegerät, das in der HoloLens 1 Development Edition enthalten ist.</span><span class="sxs-lookup"><span data-stu-id="48cc4-153">The HoloLens Clicker is the first peripheral device built specifically for HoloLens and is included with the HoloLens 1 Development Edition.</span></span> <span data-ttu-id="48cc4-154">Das HoloLens-Klick-Gerät ermöglicht es einem Benutzer, mit minimaler Handbewegung zu klicken und „Ausführen“ als sekundäre Eingabemethode zu verwenden.</span><span class="sxs-lookup"><span data-stu-id="48cc4-154">The HoloLens Clicker allows a user to click with minimal hand motion and commit as a secondary input.</span></span> <span data-ttu-id="48cc4-155">Das HoloLens-Klick-Gerät stellt eine Verbindung zur HoloLens 1 oder 2 über Bluetooth Low Energy (BTLE) her.</span><span class="sxs-lookup"><span data-stu-id="48cc4-155">The HoloLens clicker connects to the HoloLens 1 or 2 using Bluetooth Low Energy (BTLE).</span></span>

<span data-ttu-id="48cc4-156">![HoloLens-Klick-Gerät](images/hololens-clicker-500px.jpg)</span><span class="sxs-lookup"><span data-stu-id="48cc4-156">![HoloLens Clicker](images/hololens-clicker-500px.jpg)</span></span><br>
<span data-ttu-id="48cc4-157">*HoloLens-Klick-Gerät*</span><span class="sxs-lookup"><span data-stu-id="48cc4-157">*HoloLens Clicker*</span></span>

<span data-ttu-id="48cc4-158">Weitere Informationen und Anweisungen zum Koppeln des Geräts finden Sie [hier](hardware-accessories.md#pairing-bluetooth-accessories).</span><span class="sxs-lookup"><span data-stu-id="48cc4-158">More information and instructions to pair the device can be found [here](hardware-accessories.md#pairing-bluetooth-accessories)</span></span>




### <a name="head-gaze-and-xbox-wireless-controller"></a><span data-ttu-id="48cc4-159">Anvisieren mit dem Kopf und Xbox Wireless Controller</span><span class="sxs-lookup"><span data-stu-id="48cc4-159">Head-gaze and Xbox Wireless Controller</span></span>
<span data-ttu-id="48cc4-160">Der Xbox Wireless Controller ermöglicht es, eine „Klick“-Betätigung als sekundäre Eingabe über die Taste „A“ durchzuführen.</span><span class="sxs-lookup"><span data-stu-id="48cc4-160">The Xbox Wireless Controller allows to perform a "click" actuation as a secondary input by using the A button.</span></span> <span data-ttu-id="48cc4-161">Das Gerät ist einem Standardsatz von Aktionen zugeordnet, die bei der Navigation und Steuerung des Systems helfen.</span><span class="sxs-lookup"><span data-stu-id="48cc4-161">The device is mapped to a default set of actions that help navigate and controll the system.</span></span> <span data-ttu-id="48cc4-162">Wenn Sie den Controller anpassen möchten, verwenden Sie die Xbox Zubehör-App, um Ihren Xbox Wireless Controller zu konfigurieren.</span><span class="sxs-lookup"><span data-stu-id="48cc4-162">If you want to customize the controller, use the Xbox Accesories App to configure your Xbox Wireless Controller.</span></span>

<span data-ttu-id="48cc4-163">![Xbox Wireless Controller](images/xboxcontroller.jpg)</span><span class="sxs-lookup"><span data-stu-id="48cc4-163">![Xbox Wireless Controller](images/xboxcontroller.jpg)</span></span><br>
<span data-ttu-id="48cc4-164">*Xbox Wireless Controller*</span><span class="sxs-lookup"><span data-stu-id="48cc4-164">*Xbox Wireless Controller*</span></span>

[<span data-ttu-id="48cc4-165">Koppeln eines Xbox-Controllers mit Ihrem PC</span><span class="sxs-lookup"><span data-stu-id="48cc4-165">Pairing an Xbox controller with your PC</span></span>](hardware-accessories.md#pairing-bluetooth-accessories)


### <a name="head-gaze-and-xbox-adaptive-controller"></a><span data-ttu-id="48cc4-166">Anvisieren mit dem Kopf und Xbox Adaptive Controller</span><span class="sxs-lookup"><span data-stu-id="48cc4-166">Head-gaze and Xbox Adaptive Controller</span></span>
<span data-ttu-id="48cc4-167">Der Xbox Adaptive Controller wurde in erster Linie für die Bedürfnisse der Spieler mit eingeschränkter Mobilität entwickelt und ist ein einheitlicher Hub für Geräte, der dazu beiträgt, die Barrierefreiheit von Mixed Reality zu erhöhen.</span><span class="sxs-lookup"><span data-stu-id="48cc4-167">Designed primarily to meet the needs of gamers with limited mobility, the Xbox Adaptive Controller is a unified hub for devices that helps make Mixed Reality more accessible.</span></span>

<span data-ttu-id="48cc4-168">Der Xbox Adaptive Controller ermöglicht es, eine „Klick“-Betätigung als sekundäre Eingabe über die Taste „A“ durchzuführen.</span><span class="sxs-lookup"><span data-stu-id="48cc4-168">The Xbox Adaptive Controller allows to perform a "click" actuation as a secondary input by using the A button.</span></span> <span data-ttu-id="48cc4-169">Das Gerät ist einem Standardsatz von Aktionen zugeordnet, die bei der Navigation und Steuerung des Systems helfen.</span><span class="sxs-lookup"><span data-stu-id="48cc4-169">The device is mapped to a default set of actions that help navigate and controll the system.</span></span> <span data-ttu-id="48cc4-170">Wenn Sie den Controller anpassen möchten, verwenden Sie die Xbox Zubehör-App, um Ihren Xbox Adaptive Controller zu konfigurieren.</span><span class="sxs-lookup"><span data-stu-id="48cc4-170">If you want to customize the controller, use the Xbox Accesories App to configure your Xbox Adaptive Controller.</span></span>

<span data-ttu-id="48cc4-171">![Xbox Adaptive Controller](images/xbox-adaptive-controller-devices.jpg)</span><span class="sxs-lookup"><span data-stu-id="48cc4-171">![Xbox Adaptive Controller](images/xbox-adaptive-controller-devices.jpg)</span></span><br>
<span data-ttu-id="48cc4-172">*Xbox Adaptive Controller*</span><span class="sxs-lookup"><span data-stu-id="48cc4-172">*Xbox Adaptive Controller*</span></span>

<span data-ttu-id="48cc4-173">Schließen Sie externe Geräte wie Switches, Tasten, Halterungen und Joysticks an, um eine für Sie einzigartige, benutzerdefinierte Controllerumgebung zu erstellen.</span><span class="sxs-lookup"><span data-stu-id="48cc4-173">Connect external devices such as switches, buttons, mounts, and joysticks to create a custom controllers experience that is uniquely yours.</span></span> <span data-ttu-id="48cc4-174">Eingaben über Tasten, Ministick und Trigger werden mithilfe von Hilfsgeräten gesteuert, die über 3,5-mm-Buchsen und USB-Anschlüsse angeschlossen sind.</span><span class="sxs-lookup"><span data-stu-id="48cc4-174">Button, thumbstick and trigger inputs are controlled with assistive devices connected through 3.5mm jacks and USB ports.</span></span>

<span data-ttu-id="48cc4-175">![Xbox Adaptive Controller-Anschlüsse](images/xbox-adaptive-controller-ports.jpg)</span><span class="sxs-lookup"><span data-stu-id="48cc4-175">![Xbox Adaptive Controller ports](images/xbox-adaptive-controller-ports.jpg)</span></span><br>
<span data-ttu-id="48cc4-176">*Xbox Adaptive Controller-Anschlüsse*</span><span class="sxs-lookup"><span data-stu-id="48cc4-176">*Xbox Adaptive Controller ports*</span></span>

[<span data-ttu-id="48cc4-177">Anweisungen zum Koppeln des Geräts</span><span class="sxs-lookup"><span data-stu-id="48cc4-177">Instructions to pair the device</span></span>](hardware-accessories.md#pairing-bluetooth-accessories)

<span data-ttu-id="48cc4-178"><a href=https://www.xbox.com/en-US/xbox-one/accessories/controllers/xbox-adaptive-controller>Weitere Informationen, die auf der Xbox-Website verfügbar sind</a></span><span class="sxs-lookup"><span data-stu-id="48cc4-178"><a href=https://www.xbox.com/en-US/xbox-one/accessories/controllers/xbox-adaptive-controller>More info available on the Xbox site</a></span></span>


## <a name="design-guidelines"></a><span data-ttu-id="48cc4-179">Entwurfsrichtlinien</span><span class="sxs-lookup"><span data-stu-id="48cc4-179">Design guidelines</span></span>
> [!NOTE]
> <span data-ttu-id="48cc4-180">Weitere Anleitungen zum Entwurf von „Anvisieren“ sind [bald verfügbar](index.md).</span><span class="sxs-lookup"><span data-stu-id="48cc4-180">More guidance specific to gaze design [coming soon](index.md).</span></span>

## <a name="head-gaze-targeting"></a><span data-ttu-id="48cc4-181">Anvisieren mit dem Kopf</span><span class="sxs-lookup"><span data-stu-id="48cc4-181">Head-gaze targeting</span></span>
<span data-ttu-id="48cc4-182">Alle Interaktionen basieren auf der Fähigkeit eines Benutzers, das Element, mit dem er interagieren möchte, unabhängig von der Eingabemethode auszuwählen.</span><span class="sxs-lookup"><span data-stu-id="48cc4-182">All interactions are built upon the ability of a user to target the element they want to interact with, regardless of the input modality.</span></span> <span data-ttu-id="48cc4-183">In Windows Mixed Reality erfolgt dies in der Regel durch das Anvisieren durch den Benutzer.</span><span class="sxs-lookup"><span data-stu-id="48cc4-183">In Windows Mixed Reality, this is generally done using the user's gaze.</span></span>
<span data-ttu-id="48cc4-184">Damit ein Benutzer erfolgreich mit einer Umgebung arbeiten kann, muss die vom System berechnete Absicht des Benutzers mit der tatsächlichen Absicht des Benutzers weitestgehend übereinstimmen.</span><span class="sxs-lookup"><span data-stu-id="48cc4-184">To enable a user to work with an experience successfully, the system's calculated understanding of a user's intent, and the user's actual intent, must align as closely as possible.</span></span> <span data-ttu-id="48cc4-185">In dem Maße, in dem das System die beabsichtigten Aktionen des Benutzers richtig interpretiert, steigen Zufriedenheit und Leistung.</span><span class="sxs-lookup"><span data-stu-id="48cc4-185">To the degree that the system interprets the user's intended actions correctly, satisfaction increases and performance improves.</span></span>


## <a name="target-sizing-and-feedback"></a><span data-ttu-id="48cc4-186">Skalieren von Zielen und Feedback</span><span class="sxs-lookup"><span data-stu-id="48cc4-186">Target sizing and feedback</span></span>
<span data-ttu-id="48cc4-187">Der Anvisierungsvektor hat wiederholt gezeigt, dass er zur Bestimmung präziser Ziele geeignet ist, aber oftmals funktioniert er bei der Bestimmung größerer Ziele am besten.</span><span class="sxs-lookup"><span data-stu-id="48cc4-187">The gaze vector has been shown repeatedly to be usable for fine targeting, but often works best for gross targeting (acquiring somewhat larger targets).</span></span> <span data-ttu-id="48cc4-188">Mindestzielgrößen von 1 bis 1,5 Grad sollten in den meisten Szenarien erfolgreiche Benutzeraktionen ermöglichen, obwohl Ziele von 3 Grad oft eine höhere Geschwindigkeit ermöglichen.</span><span class="sxs-lookup"><span data-stu-id="48cc4-188">Minimum target sizes of 1 to 1.5 degrees should allow successful user actions in most scenarios, though targets of 3 degrees often allow for greater speed.</span></span> <span data-ttu-id="48cc4-189">Beachten Sie, dass die Größe, auf die der Benutzer ausgerichtet ist, auch für 3D-Elemente effektiv ein 2D-Bereich ist. Die ihm jeweils zugewandte Projektion sollte der Zielbereich sein.</span><span class="sxs-lookup"><span data-stu-id="48cc4-189">Note that the size that the user targets is effectively a 2D area even for 3D elements--whichever projection is facing them should be the targetable area.</span></span> <span data-ttu-id="48cc4-190">Es ist äußerst hilfreich, einen markanten Hinweis darauf zu geben, dass ein Element „aktiv“ ist (es wurde vom Benutzer anvisiert). Dies kann die Anwendung von sichtbaren „Hover“-Effekten, akustischen Hervorhebungen oder Klicks oder die eindeutige Ausrichtung eines Cursors mit einem Element umfassen.</span><span class="sxs-lookup"><span data-stu-id="48cc4-190">Providing some salient cue that an element is "active" (that the user is targeting it) is extremely helpful - this can include treatments like visible "hover" effects, audio highlights or clicks, or clear alignment of a cursor with an element.</span></span>

<span data-ttu-id="48cc4-191">![Optimale Zielgröße im Abstand von 2 Metern](images/gazetargeting-size-1000px.jpg)</span><span class="sxs-lookup"><span data-stu-id="48cc4-191">![Optimal target size at 2 meter distance](images/gazetargeting-size-1000px.jpg)</span></span><br>
<span data-ttu-id="48cc4-192">*Optimale Zielgröße im Abstand von 2 Metern*</span><span class="sxs-lookup"><span data-stu-id="48cc4-192">*Optimal target size at 2 meter distance*</span></span>

<span data-ttu-id="48cc4-193">![Beispiel für die Hervorhebung eines anvisierten Objekts](images/gazetargeting-highlighting-640px.jpg)</span><span class="sxs-lookup"><span data-stu-id="48cc4-193">![An example of highlighting a gaze targeted object](images/gazetargeting-highlighting-640px.jpg)</span></span><br>
<span data-ttu-id="48cc4-194">*Beispiel für die Hervorhebung eines anvisierten Objekts*</span><span class="sxs-lookup"><span data-stu-id="48cc4-194">*An example of highlighting a gaze targeted object*</span></span>

## <a name="target-placement"></a><span data-ttu-id="48cc4-195">Zielpositionierung</span><span class="sxs-lookup"><span data-stu-id="48cc4-195">Target placement</span></span>
<span data-ttu-id="48cc4-196">Benutzer können häufig keine Benutzeroberflächenelemente finden, die in ihrem Sichtfeld sehr hoch oder sehr niedrig positioniert sind, sodass sie sich hauptsächlich auf Bereiche um ihren Hauptfokus konzentrieren (in der Regel in etwa auf Augenhöhe).</span><span class="sxs-lookup"><span data-stu-id="48cc4-196">Users will often fail to find UI elements that are positioned very high or very low in their field of view, focusing most of their attention on areas around their main focus (usually roughly eye level).</span></span> <span data-ttu-id="48cc4-197">Die Positionierung der meisten Ziele in einem vernünftigen Bereich auf Augenhöhe kann helfen.</span><span class="sxs-lookup"><span data-stu-id="48cc4-197">Placing most targets in some reasonable band around eye level can help.</span></span> <span data-ttu-id="48cc4-198">Angesichts der Tendenz, dass sich der Benutzer jeweils auf einen relativ kleinen visuellen Bereich konzentrieren kann (der Blickwinkel beträgt etwa 10 Grad), kann die Gruppierung von Benutzeroberflächenelementen in dem Maße, in dem sie konzeptionell verwandt sind, das Verhalten zum Kombinieren der Aufmerksamkeit von Element zu Element nutzen, wenn der Blick eines Benutzers durch einen Bereich schweift.</span><span class="sxs-lookup"><span data-stu-id="48cc4-198">Given the tendency for users to focus on a relatively small visual area at any time (the attentional cone of vision is roughly 10 degrees), grouping UI elements together to the degree that they're related conceptually can leverage attention-chaining behaviors from item to item as a user moves their gaze through an area.</span></span> <span data-ttu-id="48cc4-199">Beachten Sie beim Entwerfen der Benutzeroberfläche die potenziellen großen Unterschiede beim Sichtfeld zwischen HoloLens und immersiven Headsets.</span><span class="sxs-lookup"><span data-stu-id="48cc4-199">When designing UI, keep in mind the potential large variation in field of view between HoloLens and immersive headsets.</span></span>

<span data-ttu-id="48cc4-200">![Beispiel für gruppierte Benutzeroberflächenelemente zur einfacheren Zielbestimmung in Galaxy Explorer](images/gazetargeting-grouping-1000px.jpg).</span><span class="sxs-lookup"><span data-stu-id="48cc4-200">![An example of grouped UI elements for easier gaze targeting in Galaxy Explorer](images/gazetargeting-grouping-1000px.jpg)</span></span><br>
<span data-ttu-id="48cc4-201">*Beispiel für gruppierte Benutzeroberflächenelemente zur einfacheren Zielbestimmung in Galaxy Explorer*.</span><span class="sxs-lookup"><span data-stu-id="48cc4-201">*An example of grouped UI elements for easier gaze targeting in Galaxy Explorer*</span></span>

## <a name="improving-targeting-behaviors"></a><span data-ttu-id="48cc4-202">Verbessern des Verhaltens bei der Zielbestimmung</span><span class="sxs-lookup"><span data-stu-id="48cc4-202">Improving targeting behaviors</span></span>
<span data-ttu-id="48cc4-203">Wenn die Absicht des Benutzers, etwas anzuvisieren, bestimmt (oder näherungsweise ermittelt) werden kann, ist es möglicherweise sehr hilfreich, „near miss“-Versuche (Beinahekollision) bei der Interaktion so zu akzeptieren, als ob die Zielbestimmung ordnungsgemäß erfolgt wäre.</span><span class="sxs-lookup"><span data-stu-id="48cc4-203">If user intent to target something can be determined (or approximated closely), it can be very helpful to accept "near miss" attempts at interaction as though they were targeted correctly.</span></span> <span data-ttu-id="48cc4-204">Es gibt eine Reihe erfolgreicher Methoden, die in Mixed Reality-Umgebungen integriert werden können:</span><span class="sxs-lookup"><span data-stu-id="48cc4-204">There are a handful of successful methods that can be incorporated in mixed reality experiences:</span></span>

### <a name="head-gaze-stabilization-gravity-wells"></a><span data-ttu-id="48cc4-205">Stabilisierung beim Anvisieren mit dem Kopf („Gravitationsbrunnen“)</span><span class="sxs-lookup"><span data-stu-id="48cc4-205">Head-gaze stabilization ("gravity wells")</span></span>
<span data-ttu-id="48cc4-206">Dies sollte meistens/immer aktiviert sein.</span><span class="sxs-lookup"><span data-stu-id="48cc4-206">This should be turned on most/all of the time.</span></span> <span data-ttu-id="48cc4-207">Bei diesem Verfahren werden die natürlichen Kopf-/Nackenschwankungen entfernt, die Benutzer möglicherweise aufweisen.</span><span class="sxs-lookup"><span data-stu-id="48cc4-207">This technique removes the natural head/neck jitters that users may have.</span></span> <span data-ttu-id="48cc4-208">Ebenso Bewegungen aufgrund von Verhaltensweisen beim Sehen/Sprechen.</span><span class="sxs-lookup"><span data-stu-id="48cc4-208">Also movement due to looking/speaking behaviors.</span></span>

### <a name="closest-link-algorithms"></a><span data-ttu-id="48cc4-209">Algorithmen für die engste Verbindung</span><span class="sxs-lookup"><span data-stu-id="48cc4-209">Closest link algorithms</span></span>
<span data-ttu-id="48cc4-210">Diese funktionieren am besten in Bereichen mit wenig interaktiven Inhalten.</span><span class="sxs-lookup"><span data-stu-id="48cc4-210">These work best in areas with sparse interactive content.</span></span> <span data-ttu-id="48cc4-211">Wenn es eine hohe Wahrscheinlichkeit gibt, dass Sie das Interaktionsziel eines Benutzers bestimmen können, haben Sie die Möglichkeit, ihre Fähigkeiten zur Zielbestimmung zu ergänzen, indem Sie einfach einen Absichtsgrad annehmen.</span><span class="sxs-lookup"><span data-stu-id="48cc4-211">If there is a high probability that you can determine what a user was attempting to interact with, you can supplement their targeting abilities by simply assuming some level of intent.</span></span>

### <a name="backdatingpostdating-actions"></a><span data-ttu-id="48cc4-212">Rückdatierung/Nachdatierung von Aktionen</span><span class="sxs-lookup"><span data-stu-id="48cc4-212">Backdating/postdating actions</span></span>
<span data-ttu-id="48cc4-213">Dieser Mechanismus ist hilfreich bei Aufgaben, die Geschwindigkeit erfordern.</span><span class="sxs-lookup"><span data-stu-id="48cc4-213">This mechanism is useful in tasks requiring speed.</span></span> <span data-ttu-id="48cc4-214">Wenn ein Benutzer eine Reihe von Zielbestimmungs-/Aktivierungsmanövern mit hoher Geschwindigkeit durchläuft, kann es nützlich sein, eine gewisse Absicht anzunehmen und verpasste Schritte auf Ziele reagieren zu lassen, die der Benutzer kurz vor oder kurz nach der Tippbewegung im Fokus hatte (50 ms vor oder nach der Tippbewegung war bei frühen Tests wirksam).</span><span class="sxs-lookup"><span data-stu-id="48cc4-214">When a user is moving through a series of targeting/activation maneuvers at speed, it can be useful to assume some intent and allow missed steps to act upon targets which the user had in focus slightly before or slightly after the tap (50ms before/after was effective in early testing).</span></span>

### <a name="smoothing"></a><span data-ttu-id="48cc4-215">Glättung</span><span class="sxs-lookup"><span data-stu-id="48cc4-215">Smoothing</span></span>
<span data-ttu-id="48cc4-216">Dieser Mechanismus ist hilfreich bei Wegstreckenbewegungen und reduziert das leichte Zittern/Schwanken aufgrund der natürlichen Kopfbewegungseigenschaften.</span><span class="sxs-lookup"><span data-stu-id="48cc4-216">This mechanism is useful for pathing movements, reducing the slight jitter/wobble due to natural head movement characteristics.</span></span> <span data-ttu-id="48cc4-217">Bei der Glättung über Wegstreckenbewegungen, glätten Sie eher nach Größe/Abstand der Bewegungen als nach Zeit.</span><span class="sxs-lookup"><span data-stu-id="48cc4-217">When smoothing over pathing motions, smooth by size/distance of movements rather than over time</span></span>

### <a name="magnetism"></a><span data-ttu-id="48cc4-218">Magnetismus</span><span class="sxs-lookup"><span data-stu-id="48cc4-218">Magnetism</span></span>
<span data-ttu-id="48cc4-219">Dieser Mechanismus kann als eine allgemeinere Version der Algorithmen für die engste Verbindung betrachtet werden. Dabei wird ein Cursor in Richtung eines Ziels gezogen oder es werden einfach die Trefferfelder (sichtbar oder nicht) vergrößert, wenn sich Benutzer voraussichtlichen Zielen nähern. Dabei werden Kenntnisse des interaktiven Layouts verwendet, um sich der Absicht des Benutzers besser zu nähern.</span><span class="sxs-lookup"><span data-stu-id="48cc4-219">This mechanism can be thought of as a more general version of "Closest link" algorithms - drawing a cursor toward a target, or simply increasing hitboxes (whether visibly or not) as users approach likely targets, using some knowledge of the interactive layout to better approach user intent.</span></span> <span data-ttu-id="48cc4-220">Dies kann insbesondere bei kleinen Zielen sehr wirkungsvoll sein.</span><span class="sxs-lookup"><span data-stu-id="48cc4-220">This can be particularly powerful for small targets.</span></span>

### <a name="focus-stickiness"></a><span data-ttu-id="48cc4-221">Fokusbindung</span><span class="sxs-lookup"><span data-stu-id="48cc4-221">Focus stickiness</span></span>
<span data-ttu-id="48cc4-222">Wenn Sie bestimmen, welche interaktiven Elemente in der Nähe den Fokus erhalten sollen, stellen Sie eine Tendenz für das Element bereit, das gerade über den Fokus verfügt.</span><span class="sxs-lookup"><span data-stu-id="48cc4-222">When determining which nearby interactive elements to give focus to, provide a bias to the element that is currently focused.</span></span> <span data-ttu-id="48cc4-223">Dies trägt dazu bei, unkontrolliertes Verhalten beim Fokuswechsel zu reduzieren, wenn Sie mittig zwischen zwei Elementen mit natürlicher Verzerrung schwanken.</span><span class="sxs-lookup"><span data-stu-id="48cc4-223">This will help reduce erratic focus switching behaviours when floating at a midpoint between two elements with natural noise.</span></span>


## <a name="composite-gestures"></a><span data-ttu-id="48cc4-224">Zusammengesetzte Gesten</span><span class="sxs-lookup"><span data-stu-id="48cc4-224">Composite gestures</span></span>
<span data-ttu-id="48cc4-225">Apps können mehr als nur einzelne Tippbewegungen erkennen.</span><span class="sxs-lookup"><span data-stu-id="48cc4-225">Apps can recognize more than just individual taps.</span></span> <span data-ttu-id="48cc4-226">Durch die Kombination von Tippen, Halten und Loslassen mit der Bewegung der Hand können komplexere zusammengesetzte Gesten ausgeführt werden.</span><span class="sxs-lookup"><span data-stu-id="48cc4-226">By combining tap, hold and release with the movement of the hand, more complex composite gestures can be performed.</span></span> <span data-ttu-id="48cc4-227">Diese zusammengesetzten Gesten oder Gesten auf hoher Ebene bauen auf den räumlichen Eingabedaten auf niedriger Ebene (von „In die Luft tippen“ und „Öffnen“) auf, auf die Entwickler zugreifen können.</span><span class="sxs-lookup"><span data-stu-id="48cc4-227">These composite or high-level gestures build on the low-level spatial input data (from Air tap and Bloom) that developers have access to.</span></span>

### <a name="air-tap"></a><span data-ttu-id="48cc4-228">In die Luft tippen</span><span class="sxs-lookup"><span data-stu-id="48cc4-228">Air tap</span></span>
<span data-ttu-id="48cc4-229">Die Geste „In die Luft tippen“ (wie auch die anderen nachfolgenden Gesten) reagiert nur auf eine bestimmte Tippbewegung.</span><span class="sxs-lookup"><span data-stu-id="48cc4-229">The Air tap gesture (as well as the other gestures below) reacts only to a specific tap.</span></span> <span data-ttu-id="48cc4-230">Um andere Tippbewegungen wie „Menü“ oder „Greifen“ zu erkennen, muss Ihre App direkt die Interaktionen auf niedrigerer Ebene verwenden, die oben im Abschnitt über zwei Schlüsselkomponentengesten beschrieben sind.</span><span class="sxs-lookup"><span data-stu-id="48cc4-230">To detect other taps, such as Menu or Grasp, your app must directly use the lower-level interactions described in two key component gestures section above.</span></span>

### <a name="tap-and-hold"></a><span data-ttu-id="48cc4-231">Tippen und halten Sie</span><span class="sxs-lookup"><span data-stu-id="48cc4-231">Tap and hold</span></span>
<span data-ttu-id="48cc4-232">„Halten“ bedeutet einfach, die Position mit dem Finger nach unten beim „In die Luft tippen“ beizubehalten.</span><span class="sxs-lookup"><span data-stu-id="48cc4-232">Hold is simply maintaining the downward finger position of the air tap.</span></span> <span data-ttu-id="48cc4-233">Die Kombination von „In die Luft tippen und halten“ ermöglicht eine Vielzahl von komplexeren Interaktionen beim „Klicken und Ziehen“, wenn sie mit Armbewegungen kombiniert werden, z. B. das Aufnehmen eines Objekts anstelle der Aktivierung, oder sekundäre „Mousedown“-Interaktionen (gedrückte Maustaste), wie das Anzeigen eines Kontextmenüs.</span><span class="sxs-lookup"><span data-stu-id="48cc4-233">The combination of air tap and hold allows for a variety of more complex "click and drag" interactions when combined with arm movement such as picking up an object instead of activating it or "mousedown" secondary interactions such as showing a context menu.</span></span>
<span data-ttu-id="48cc4-234">Bei der Gestaltung dieser Geste sollte jedoch mit Bedacht vorgegangen werden, da die Benutzer dazu neigen können, ihre Handhaltungen im Laufe einer längeren Geste zu entspannen.</span><span class="sxs-lookup"><span data-stu-id="48cc4-234">Caution should be used when designing for this gesture however, as users can be prone to relaxing their hand postures during the course of any extended gesture.</span></span>

### <a name="manipulation"></a><span data-ttu-id="48cc4-235">Manipulation</span><span class="sxs-lookup"><span data-stu-id="48cc4-235">Manipulation</span></span>
<span data-ttu-id="48cc4-236">Mithilfe von Manipulationsgesten können Sie ein Hologramm bewegen, skalieren oder drehen, wenn Sie möchten, dass das Hologramm 1:1 auf die Handbewegungen des Benutzers reagiert.</span><span class="sxs-lookup"><span data-stu-id="48cc4-236">Manipulation gestures can be used to move, resize or rotate a hologram when you want the hologram to react 1:1 to the user's hand movements.</span></span> <span data-ttu-id="48cc4-237">Eine Verwendungsmöglichkeit für solche 1:1-Bewegungen ist es, den Benutzer in der Umgebung zeichnen oder malen zu lassen.</span><span class="sxs-lookup"><span data-stu-id="48cc4-237">One use for such 1:1 movements is to let the user draw or paint in the world.</span></span>
<span data-ttu-id="48cc4-238">Die anfängliche Zielbestimmung für eine Manipulationsgeste sollte durch Anvisieren oder Zeigen erfolgen.</span><span class="sxs-lookup"><span data-stu-id="48cc4-238">The initial targeting for a manipulation gesture should be done by gaze or pointing.</span></span> <span data-ttu-id="48cc4-239">Sobald das Tippen und Halten beginnt, erfolgt jede Manipulation des Objekts durch Handbewegungen, sodass sich der Benutzer während der Manipulation umsehen kann.</span><span class="sxs-lookup"><span data-stu-id="48cc4-239">Once the tap and hold starts, any manipulation of the object is then handled by hand movements, freeing the user to look around while they manipulate.</span></span>

### <a name="navigation"></a><span data-ttu-id="48cc4-240">Navigation</span><span class="sxs-lookup"><span data-stu-id="48cc4-240">Navigation</span></span>
<span data-ttu-id="48cc4-241">Navigationsgesten funktionieren wie ein virtueller Joystick und können zur Navigation in Widgets der Benutzeroberfläche, z. B. Radialmenüs, verwendet werden.</span><span class="sxs-lookup"><span data-stu-id="48cc4-241">Navigation gestures operate like a virtual joystick, and can be used to navigate UI widgets, such as radial menus.</span></span> <span data-ttu-id="48cc4-242">Sie tippen und halten, um die Geste zu starten, und bewegen dann Ihre Hand in einem normalisierten 3D-Würfel, der um die erste Betätigung herum angeordnet ist.</span><span class="sxs-lookup"><span data-stu-id="48cc4-242">You tap and hold to start the gesture and then move your hand within a normalized 3D cube, centered around the initial press.</span></span> <span data-ttu-id="48cc4-243">Sie können Ihre Hand entlang der X-, Y- oder Z-Achse zwischen einem Wert von -1 bis 1 bewegen, wobei 0 der Ausgangspunkt ist.</span><span class="sxs-lookup"><span data-stu-id="48cc4-243">You can move your hand along the X, Y or Z axis from a value of -1 to 1, with 0 being the starting point.</span></span>
<span data-ttu-id="48cc4-244">Mithilfe der Navigation können geschwindigkeitsbasierte kontinuierliche Gesten zum Scrollen oder Zoomen erstellt werden, ähnlich dem Scrollen bei einer 2D-Benutzeroberfläche durch Klicken mit der mittleren Maustaste und anschließendes Bewegen der Maus nach oben und unten.</span><span class="sxs-lookup"><span data-stu-id="48cc4-244">Navigation can be used to build velocity-based continuous scrolling or zooming gestures, similar to scrolling a 2D UI by clicking the middle mouse button and then moving the mouse up and down.</span></span>

<span data-ttu-id="48cc4-245">Die „Navigation mit Führungsschienen“ bezieht sich auf die Fähigkeit, Bewegungen entlang einer bestimmten Achse zu erkennen, bis ein bestimmter Schwellenwert auf dieser Achse erreicht ist.</span><span class="sxs-lookup"><span data-stu-id="48cc4-245">Navigation with rails refers to the ability of recognizing movements in certain axis until certain threshold is reached on that axis.</span></span> <span data-ttu-id="48cc4-246">Dies ist nur sinnvoll, wenn die Bewegung innerhalb einer Anwendung durch den Entwickler entlang mehrerer Achsen ermöglicht wird, z. B. wenn eine Anwendung so konfiguriert ist, dass sie Navigationsgesten über die X-, Y-Achse erkennt, aber auch die X-Achse mit Führungsschienen angegeben ist.</span><span class="sxs-lookup"><span data-stu-id="48cc4-246">This is only useful, when movement in more than one axis is enabled in an application by the developer, e.g. if an application is configured to recognize navigation gestures across X, Y axis but also specified X axis with rails.</span></span> <span data-ttu-id="48cc4-247">In diesem Fall erkennt das System Handbewegungen über die X-Achse, solange sie innerhalb einer imaginären Führungsschiene auf der X-Achse verbleiben, wenn die Handbewegung auch auf der Y-Achse erfolgt.</span><span class="sxs-lookup"><span data-stu-id="48cc4-247">In this case system will recognize hand movements across X axis as long as they remain within an imaginary rails (guide) on X axis, if hand movement also occurs Y axis.</span></span>

<span data-ttu-id="48cc4-248">Innerhalb von 2D-Apps können Benutzer mit vertikalen Navigationsgesten innerhalb der App scrollen, zoomen oder ziehen.</span><span class="sxs-lookup"><span data-stu-id="48cc4-248">Within 2D apps, users can use vertical navigation gestures to scroll, zoom, or drag inside the app.</span></span> <span data-ttu-id="48cc4-249">Dadurch werden virtuelle Fingerberührungen in der App eingeführt, um Gesten für die Toucheingabe desselben Typs zu simulieren.</span><span class="sxs-lookup"><span data-stu-id="48cc4-249">This injects virtual finger touches to the app to simulate touch gestures of the same type.</span></span> <span data-ttu-id="48cc4-250">Der Benutzer kann auswählen, welche dieser Aktionen durchgeführt werden sollen, indem er zwischen den Tools auf der Symbolleiste über der App wechselt, indem er entweder die Schaltfläche auswählt oder „<Scroll-/Ziehen-/Zoom->Tool“ sagt.</span><span class="sxs-lookup"><span data-stu-id="48cc4-250">Users can select which of these actions take place by toggling between the tools on the bar above the app, either by selecting the button or saying '<Scroll/Drag/Zoom> Tool'.</span></span>

[<span data-ttu-id="48cc4-251">Weitere Informationen zu zusammengesetzten Gesten</span><span class="sxs-lookup"><span data-stu-id="48cc4-251">More info on composite gestures</span></span>](gestures.md#composite-gestures)

## <a name="gesture-recognizers"></a><span data-ttu-id="48cc4-252">Gestenerkennung</span><span class="sxs-lookup"><span data-stu-id="48cc4-252">Gesture recognizers</span></span>

<span data-ttu-id="48cc4-253">Ein Vorteil der Gestenerkennung besteht darin, dass Sie einen Gestenerkenner nur für die Gesten konfigurieren können, die das aktuell ausgewählte Hologramm akzeptieren kann.</span><span class="sxs-lookup"><span data-stu-id="48cc4-253">One benefit of using gesture recognition is that you can configure a gesture recognizer just for the gestures the currently targeted hologram can accept.</span></span> <span data-ttu-id="48cc4-254">Die Plattform wird nur die zur Unterscheidung dieser besonders unterstützten Gesten erforderliche Mehrdeutigkeitsvermeidung vornehmen.</span><span class="sxs-lookup"><span data-stu-id="48cc4-254">The platform will do only the disambiguation necessary to distinguish those particular supported gestures.</span></span> <span data-ttu-id="48cc4-255">Auf diese Weise kann ein Hologramm, das nur „In die Luft tippen“ unterstützt, jede beliebige Zeitspanne zwischen Drücken und Loslassen akzeptieren, während ein Hologramm, das sowohl Tippen als auch Halten unterstützt, die Tippbewegung nach dem Überschreiten des Schwellenwerts für die Haltezeit in einen Haltevorgang ändern kann.</span><span class="sxs-lookup"><span data-stu-id="48cc4-255">That way, a hologram that just supports air tap can accept any length of time between press and release, while a hologram that supports both tap and hold can promote the tap to a hold after the hold time threshold.</span></span>

## <a name="hand-recognition"></a><span data-ttu-id="48cc4-256">Handerkennung</span><span class="sxs-lookup"><span data-stu-id="48cc4-256">Hand recognition</span></span>
<span data-ttu-id="48cc4-257">HoloLens erkennt Handgesten, indem die Position einer oder beider Hände, die für das Gerät sichtbar sind, verfolgt wird.</span><span class="sxs-lookup"><span data-stu-id="48cc4-257">HoloLens recognizes hand gestures by tracking the position of either or both hands that are visible to the device.</span></span> <span data-ttu-id="48cc4-258">HoloLens erkennt Hände, wenn sie sich entweder im Bereitschaftszustand (Handrücken mit nach oben gerichtetem Zeigefinger zu Ihnen gewandt) oder im gedrückten Zustand (Handrücken mit nach unten gerichtetem Zeigefinger zu Ihnen gewandt) befinden.</span><span class="sxs-lookup"><span data-stu-id="48cc4-258">HoloLens sees hands when they are in either the ready state (back of the hand facing you with index finger up) or the pressed state (back of the hand facing you with the index finger down).</span></span> <span data-ttu-id="48cc4-259">Wenn die Hände eine andere Pose einnehmen, werden sie von HoloLens ignoriert.</span><span class="sxs-lookup"><span data-stu-id="48cc4-259">When hands are in other poses, the HoloLens will ignore them.</span></span>
<span data-ttu-id="48cc4-260">Sie können für jede Hand, die von HoloLens erkannt wird, auf ihre Position (ohne Ausrichtung) und ihren gedrückten Zustand zugreifen.</span><span class="sxs-lookup"><span data-stu-id="48cc4-260">For each hand that HoloLens detects, you can access its position (without orientation) and its pressed state.</span></span> <span data-ttu-id="48cc4-261">Wenn sich die Hand dem Rand des Gestenrahmens nähert, erhalten Sie auch einen Richtungsvektor, den Sie dem Benutzer zeigen können, damit er weiß, wie er seine Hand bewegen muss, um sie dorthin zurückzubringen, wo sie von HoloLens erkannt werden kann.</span><span class="sxs-lookup"><span data-stu-id="48cc4-261">As the hand nears the edge of the gesture frame, you're also provided with a direction vector, which you can show to the user so they know how to move their hand to get it back where HoloLens can see it.</span></span>

## <a name="gesture-frame"></a><span data-ttu-id="48cc4-262">Gestenrahmen</span><span class="sxs-lookup"><span data-stu-id="48cc4-262">Gesture frame</span></span>
<span data-ttu-id="48cc4-263">Bei Gesten für HoloLens muss sich die Hand innerhalb eines „Gestenrahmens“ befinden, in einem Bereich, den die Gestenerkennungskameras entsprechend sehen können (ganz grob genommen von der Nase bis zur Taille und zwischen den Schultern).</span><span class="sxs-lookup"><span data-stu-id="48cc4-263">For gestures on HoloLens, the hand must be within a “gesture frame”, in a range that the gesture-sensing cameras can see appropriately (very roughly from nose to waist, and between the shoulders).</span></span> <span data-ttu-id="48cc4-264">Die Benutzer müssen in diesem Erkennungsbereich sowohl für den Aktionserfolg als auch für die eigene Bequemlichkeit geschult werden (viele Benutzer werden zunächst davon ausgehen, dass sich der Gestenrahmen innerhalb Ihres Sichtfelds der HoloLens befinden muss und daher ihre Arme zum Interagieren auf unbequeme Weise hochhalten).</span><span class="sxs-lookup"><span data-stu-id="48cc4-264">Users need to be trained on this area of recognition both for success of action and for their own comfort (many users will initially assume that the gesture frame must be within their view through HoloLens, and hold their arms up uncomfortably in order to interact).</span></span> <span data-ttu-id="48cc4-265">Bei der Verwendung des HoloLens-Klick-Geräts müssen sich Ihre Hände nicht innerhalb des Gestenrahmens befinden.</span><span class="sxs-lookup"><span data-stu-id="48cc4-265">When using the HoloLens Clicker, your hands do not need to be within the gesture frame.</span></span>

<span data-ttu-id="48cc4-266">Insbesondere bei fortlaufenden Gesten besteht die Gefahr, dass Benutzer ihre Hände im Verlauf der Geste außerhalb des Gestenrahmens bewegen (z. B. beim Bewegen eines holografischen Objekts) und nicht das gewünschte Ergebnis erzielen.</span><span class="sxs-lookup"><span data-stu-id="48cc4-266">In the case of continuous gestures in particular, there is some risk of users moving their hands outside of the gesture frame while in mid-gesture (while moving some holographic object, for example), and losing their intended outcome.</span></span>

<span data-ttu-id="48cc4-267">Sie sollten die folgenden drei Aspekte berücksichtigen:</span><span class="sxs-lookup"><span data-stu-id="48cc4-267">There are three things that you should consider:</span></span>

- <span data-ttu-id="48cc4-268">Schulung der Benutzer zur Existenz des Gestenrahmens und zu ungefähren Begrenzungen (dies wird beim HoloLens-Setup vermittelt).</span><span class="sxs-lookup"><span data-stu-id="48cc4-268">User education on the gesture frame's existence and approximate boundaries (this is taught during HoloLens setup).</span></span>

- <span data-ttu-id="48cc4-269">Benachrichtigung der Benutzer, wenn sich ihre Gesten den Gestenrahmenbegrenzungen innerhalb einer Anwendung nähern bzw. diese überschreiten, da eine verlorene Geste zu unerwünschten Ergebnissen führt.</span><span class="sxs-lookup"><span data-stu-id="48cc4-269">Notifying users when their gestures are nearing/breaking the gesture frame boundaries within an application, to the degree that a lost gesture will lead to undesired outcomes.</span></span> <span data-ttu-id="48cc4-270">Studien haben die wichtigsten Eigenschaften eines solchen Benachrichtigungssystems gezeigt, und die HoloLens-Shell ist ein gutes Beispiel für diese Art der Benachrichtigung (visuelle Benachrichtigung auf dem zentralen Cursor, der die Richtung angibt, in der die Überschreitung der Begrenzung erfolgt ist).</span><span class="sxs-lookup"><span data-stu-id="48cc4-270">Research has shown the key qualities of such a notification system, and the HoloLens shell provides a good example of this type of notification (visual, on the central cursor, indicating the direction in which boundary crossing is taking place).</span></span>

- <span data-ttu-id="48cc4-271">Die Folgen des Überschreitens der Begrenzungen des Gestenrahmens sollten minimiert werden.</span><span class="sxs-lookup"><span data-stu-id="48cc4-271">Consequences of breaking the gesture frame boundaries should be minimized.</span></span> <span data-ttu-id="48cc4-272">Im Allgemeinen bedeutet dies, dass das Ergebnis einer Geste an der Begrenzung gestoppt, aber nicht rückgängig gemacht werden sollte.</span><span class="sxs-lookup"><span data-stu-id="48cc4-272">In general, this means that the outcome of a gesture should be stopped at the boundary, but not reversed.</span></span> <span data-ttu-id="48cc4-273">Wenn ein Benutzer z. B. ein holografisches Objekt durch einen Raum bewegt, sollte die Bewegung gestoppt werden, wenn der Gestenrahmen überschritten wird, aber das Objekt nicht zum Ausgangspunkt zurückkehren.</span><span class="sxs-lookup"><span data-stu-id="48cc4-273">For example, if a user is moving some holographic object across a room, movement should stop when the gesture frame is breached, but not be returned to the starting point.</span></span> <span data-ttu-id="48cc4-274">Der Benutzer empfindet dann möglicherweise eine gewisse Frustration, kann aber die Begrenzungen schneller verstehen und muss nicht jedes Mal seine beabsichtigten Aktionen vollständig neu starten.</span><span class="sxs-lookup"><span data-stu-id="48cc4-274">The user may experience some frustration then, but may more quickly understand the boundaries, and not have to restart their full intended actions each time.</span></span>


## <a name="see-also"></a><span data-ttu-id="48cc4-275">Weitere Informationen</span><span class="sxs-lookup"><span data-stu-id="48cc4-275">See also</span></span>
* [<span data-ttu-id="48cc4-276">Direkte Manipulation mit den Händen</span><span class="sxs-lookup"><span data-stu-id="48cc4-276">Direct manipulation with hands</span></span>](direct-manipulation.md)
* [<span data-ttu-id="48cc4-277">Zeigen und Ausführen mit den Händen</span><span class="sxs-lookup"><span data-stu-id="48cc4-277">Point and commit with hands</span></span>](point-and-commit.md)
* [<span data-ttu-id="48cc4-278">Instinktive Interaktionen</span><span class="sxs-lookup"><span data-stu-id="48cc4-278">Instinctual interactions</span></span>](interaction-fundamentals.md)
* [<span data-ttu-id="48cc4-279">Anvisieren mit dem Kopf und Verweilen</span><span class="sxs-lookup"><span data-stu-id="48cc4-279">Head-gaze and dwell</span></span>](gaze-and-dwell.md)
* [<span data-ttu-id="48cc4-280">Sprachbefehle</span><span class="sxs-lookup"><span data-stu-id="48cc4-280">Voice commanding</span></span>](voice-design.md)





