---
title: Head-Blicke und commit
description: Übersicht über das Eingabemodell Head-Blicke und commit
author: caseymeekhof
ms.author: cmeekhof
ms.date: 03/31/2019
ms.topic: article
ms.localizationpriority: high
keywords: Gemischte Realität Blicke, Blicke Ziel ist, handelt es sich bei der Interaktion, Entwerfen
ms.openlocfilehash: 95f2cef8c10ce3d0d2a218953613fef6f0a00362
ms.sourcegitcommit: 1c0fbee8fa887525af6ed92174edc42c05b25f90
ms.translationtype: MT
ms.contentlocale: de-DE
ms.lasthandoff: 05/16/2019
ms.locfileid: "65730820"
---
# <a name="head-gaze-and-commit"></a><span data-ttu-id="7cb5d-104">Head-Blicke und commit</span><span class="sxs-lookup"><span data-stu-id="7cb5d-104">Head-gaze and commit</span></span>
<span data-ttu-id="7cb5d-105">Head-Blicke und Commit ist ein Eingabemodell aus, die umfasst das Anpassen eines Objekts mit der Richtung der Kopf vorwärts verweist (Head-Richtung), und klicken Sie dann mit einer sekundären Datenbank darauf reagieren, geben Sie z. B. als die Luft, tippen Sie auf Hand-Geste oder den Befehl "Select".</span><span class="sxs-lookup"><span data-stu-id="7cb5d-105">Head-gaze and commit is an input model that involves targeting an object with the direction of your head pointing forward (head-direction), and then acting on it with a secondary input such as the hand gesture Air Tap or the voice command “Select”.</span></span> <span data-ttu-id="7cb5d-106">Es gilt eine "weit" Eingabemodell mit indirekte Manipulation, was bedeutet, dass es am besten verwendet wird, für die Interaktion mit Inhalt, der über Gelenkarme zu erreichen ist.</span><span class="sxs-lookup"><span data-stu-id="7cb5d-106">It is considered a "far" input model with indirect manipulation, meaning it is best used for interacting with content that is beyond arms reach.</span></span>

## <a name="device-support"></a><span data-ttu-id="7cb5d-107">Unterstützung von Geräten</span><span class="sxs-lookup"><span data-stu-id="7cb5d-107">Device support</span></span>

<table>
    <colgroup>
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    </colgroup>
    <tr>
        <td><span data-ttu-id="7cb5d-108"><strong>Eingabemodell</strong></span><span class="sxs-lookup"><span data-stu-id="7cb5d-108"><strong>Input model</strong></span></span></td>
        <td><span data-ttu-id="7cb5d-109"><a href="hololens-hardware-details.md"><strong>HoloLens (1. Generation)</strong></a></span><span class="sxs-lookup"><span data-stu-id="7cb5d-109"><a href="hololens-hardware-details.md"><strong>HoloLens (1st gen)</strong></a></span></span></td>
        <td><span data-ttu-id="7cb5d-110"><strong>HoloLens 2</strong></span><span class="sxs-lookup"><span data-stu-id="7cb5d-110"><strong>HoloLens 2</strong></span></span></td>
        <td><span data-ttu-id="7cb5d-111"><a href="immersive-headset-hardware-details.md"><strong>Immersive headsets</strong></a></span><span class="sxs-lookup"><span data-stu-id="7cb5d-111"><a href="immersive-headset-hardware-details.md"><strong>Immersive headsets</strong></a></span></span></td>
    </tr>
     <tr>
        <td><span data-ttu-id="7cb5d-112">Head-Blicke und commit</span><span class="sxs-lookup"><span data-stu-id="7cb5d-112">Head-gaze and commit</span></span></td>
        <td><span data-ttu-id="7cb5d-113">✔️ Empfohlen</span><span class="sxs-lookup"><span data-stu-id="7cb5d-113">✔️ Recommended</span></span></td>
        <td><span data-ttu-id="7cb5d-114">✔️ Empfohlen (dritte Option - <a href="interaction-fundamentals.md">finden Sie unter den anderen Optionen</a>)</span><span class="sxs-lookup"><span data-stu-id="7cb5d-114">✔️ Recommended (third choice - <a href="interaction-fundamentals.md">See the other options</a>)</span></span></td>
        <td><span data-ttu-id="7cb5d-115">Alternative Option ➕</span><span class="sxs-lookup"><span data-stu-id="7cb5d-115">➕ Alternate option</span></span></td>
    </tr>
</table>

## <a name="head-gaze"></a><span data-ttu-id="7cb5d-116">Head-Blicke</span><span class="sxs-lookup"><span data-stu-id="7cb5d-116">Head-gaze</span></span>
<span data-ttu-id="7cb5d-117">Mixed Reality-Headsets werden die Position und Ausrichtung des Benutzers Head verwenden, um ihre Head Richtungsvektor zu bestimmen.</span><span class="sxs-lookup"><span data-stu-id="7cb5d-117">Mixed reality headsets use the position and orientation of the user's head to determine their head direction vector.</span></span> <span data-ttu-id="7cb5d-118">Sie können dies als eine Laser vorstellen, die direkt direkt von direkt zwischen dem Benutzer die Augen verweist.</span><span class="sxs-lookup"><span data-stu-id="7cb5d-118">You can think of this as a laser that points straight ahead from directly between the user's eyes.</span></span> <span data-ttu-id="7cb5d-119">Dies ist eine ziemlich grobe Schätzung der, in denen der Benutzer sieht.</span><span class="sxs-lookup"><span data-stu-id="7cb5d-119">This is a fairly coarse approximation of where the user is looking.</span></span> <span data-ttu-id="7cb5d-120">Ihre Anwendung kann Schnittmenge dieser Chow mit virtuell oder Real-World-Objekten, und zeichnen einen Cursor an diesem Speicherort, damit der Benutzer wissen, was sie aktuell Anzielen.</span><span class="sxs-lookup"><span data-stu-id="7cb5d-120">Your application can intersect this ray with virtual or real-world objects and draw a cursor at that location to let the user know what they are currently targeting.</span></span>

<span data-ttu-id="7cb5d-121">Zusätzlich zum Head Blicke enthalten einige mixed Reality-Headsets wie beispielsweise HoloLens 2 Eye-tracking-Systeme, die einen Vektor Eye-Blicke zu erzeugen.</span><span class="sxs-lookup"><span data-stu-id="7cb5d-121">In addition to head gaze, some mixed reality headsets like the HoloLens 2 include eye tracking systems that produce an eye-gaze vector.</span></span> <span data-ttu-id="7cb5d-122">Dies bietet eine differenzierte Maß, in denen der Benutzer sieht.</span><span class="sxs-lookup"><span data-stu-id="7cb5d-122">This provides a fine-grained measurement of where the user is looking.</span></span> <span data-ttu-id="7cb5d-123">Es ist möglich, die Blicke erstellen, und committen Interaktionen mit Eye Blicke, aber dies ist mit einem ganz anderen Satz von Einschränkungen beim Entwurf, der separat in behandelt werden die [Eye-tracking Artikel](eye-tracking.md).</span><span class="sxs-lookup"><span data-stu-id="7cb5d-123">It is possible to build gaze and commit interactions using eye gaze, but this comes with a very different set of design constraints, which will be covered separately in the [eye tracking article](eye-tracking.md).</span></span>

## <a name="commit"></a><span data-ttu-id="7cb5d-124">Commit</span><span class="sxs-lookup"><span data-stu-id="7cb5d-124">Commit</span></span>
<span data-ttu-id="7cb5d-125">Nach der ein Objekt oder Element der Benutzeroberfläche, abzielen, kann der Benutzer interagieren oder "click", mit einer sekundären Eingabe.</span><span class="sxs-lookup"><span data-stu-id="7cb5d-125">After targeting an object or UI element, the user can interact or "click" on it using a secondary input.</span></span> <span data-ttu-id="7cb5d-126">Dies wird als Schritt Commit des Modells bezeichnet.</span><span class="sxs-lookup"><span data-stu-id="7cb5d-126">This is known as the commit step of the model.</span></span> <span data-ttu-id="7cb5d-127">Die folgenden Commit-Methoden werden unterstützt:</span><span class="sxs-lookup"><span data-stu-id="7cb5d-127">The following commit methods are supported:</span></span>

- <span data-ttu-id="7cb5d-128">Tippbewegung</span><span class="sxs-lookup"><span data-stu-id="7cb5d-128">Air Tap gesture</span></span>
- <span data-ttu-id="7cb5d-129">Sprechen Sie mindestens eine der Voice-Befehl "Select" die gezielte Sprachbefehle</span><span class="sxs-lookup"><span data-stu-id="7cb5d-129">Speak the voice command "Select" or one of the targeted voice commands</span></span>
- <span data-ttu-id="7cb5d-130">Drücken Sie die einzelne Schaltfläche auf einem [HoloLens Clicker](hardware-accessories.md#hololens-clicker)</span><span class="sxs-lookup"><span data-stu-id="7cb5d-130">Press the single button on a [HoloLens Clicker](hardware-accessories.md#hololens-clicker)</span></span>
- <span data-ttu-id="7cb5d-131">Drücken Sie die Schaltfläche "A" auf eine Xbox Gamepad</span><span class="sxs-lookup"><span data-stu-id="7cb5d-131">Press the 'A' button on an Xbox Gamepad</span></span>
- <span data-ttu-id="7cb5d-132">Drücken Sie die Schaltfläche "A" auf eine Adaptive Xbox-Controller</span><span class="sxs-lookup"><span data-stu-id="7cb5d-132">Press the 'A' button on an Xbox Adaptive Controller</span></span>

### <a name="head-gaze-and-air-tap-gesture"></a><span data-ttu-id="7cb5d-133">Head-Blicke und Air tippen</span><span class="sxs-lookup"><span data-stu-id="7cb5d-133">Head-gaze and air tap gesture</span></span>
<span data-ttu-id="7cb5d-134">Tippbewegung ist eine Geste für ein Tippen mit der Hand aufrechte gespeichert.</span><span class="sxs-lookup"><span data-stu-id="7cb5d-134">Air tap is a tapping gesture with the hand held upright.</span></span> <span data-ttu-id="7cb5d-135">Um tippbewegung ausführen zu können, Ihren Finger Index, an der Position bereit, und klicken Sie dann mit dem Daumen zusammendrücken ausgelöst und der Zeigefinger sichern freigeben.</span><span class="sxs-lookup"><span data-stu-id="7cb5d-135">To perform an Air tap, raise your index finger to the ready position, then pinch with your thumb and raise your index finger back up to release.</span></span> <span data-ttu-id="7cb5d-136">HoloLens-1 ist die Tippen Sie auf die am häufigsten verwendeten sekundären Eingabe.</span><span class="sxs-lookup"><span data-stu-id="7cb5d-136">On HoloLens 1, Air tap is the most common secondary input.</span></span>

![Schätzungen der Position des bereit, und klicken Sie dann eine Bewegung tippen oder klicken Sie auf](images/readyandpress.jpg)<br>

<span data-ttu-id="7cb5d-138">Tippbewegung steht auch auf HoloLens 2, und es wurde aus der ursprünglichen Version erhöht wurde.</span><span class="sxs-lookup"><span data-stu-id="7cb5d-138">Air tap is also available on HoloLens 2, and it has been relaxed from the original version.</span></span> <span data-ttu-id="7cb5d-139">Nahezu alle Arten von Pinches werden jetzt unterstützt, solange das Handsymbol weiterhin aufrecht und gehalten wird.</span><span class="sxs-lookup"><span data-stu-id="7cb5d-139">Nearly all types of pinches are now supported, as long as the hand is upright and holding still.</span></span> <span data-ttu-id="7cb5d-140">Dies erleichtert es für Benutzer, um zu erfahren, und führen Sie die Bewegung.</span><span class="sxs-lookup"><span data-stu-id="7cb5d-140">This makes it much easier for users to learn and perform the gesture.</span></span>  <span data-ttu-id="7cb5d-141">Diese neue tippbewegung ersetzt das alte Konto über die gleiche API, und vorhandene Anwendungen das neue Verhalten automatisch nach dem erneuten Kompilieren für HoloLens 2.</span><span class="sxs-lookup"><span data-stu-id="7cb5d-141">This new Air tap replaces the old one through the same API, so existing applications will get the new behavior automatically after recompiling for HoloLens 2.</span></span>

### <a name="head-gaze-and-select-voice-command"></a><span data-ttu-id="7cb5d-142">Head-Blicke und "Select" voice-Befehl</span><span class="sxs-lookup"><span data-stu-id="7cb5d-142">Head-gaze and "Select" voice command</span></span>
<span data-ttu-id="7cb5d-143">Voice-Befehle ist eine der Methoden primären Interaktion in Mixed Reality.</span><span class="sxs-lookup"><span data-stu-id="7cb5d-143">Voice commanding is one of the primary interaction methods on Mixed Reality.</span></span> <span data-ttu-id="7cb5d-144">Es bietet eine sehr leistungsfähige "Hands Free" Methode bereit, um zu steuern, das System.</span><span class="sxs-lookup"><span data-stu-id="7cb5d-144">It provides a very powerful "Hands Free" mechanism to control the system.</span></span> <span data-ttu-id="7cb5d-145">Es gibt andere Arten von Voice-interaktionsmodellen:</span><span class="sxs-lookup"><span data-stu-id="7cb5d-145">There are diferent types of voice interaction models:</span></span>

- <span data-ttu-id="7cb5d-146">Der generische Befehl "Select" ermöglicht eine Betätigung der "Klick" oder einer sekundären Eingabe Commit ausführen.</span><span class="sxs-lookup"><span data-stu-id="7cb5d-146">The generic command "Select" that allows to perform a "click" actuation or commit as a secondary input.</span></span>
- <span data-ttu-id="7cb5d-147">Objektbefehle wie z. B. "Schließen" oder "es größer Mach" zuzulassen, und übergeben an eine Aktion als einer sekundären Eingabe.</span><span class="sxs-lookup"><span data-stu-id="7cb5d-147">Object commands like "Close" or "Make it bigger" that allow to perform and commit to an action as a secondary input.</span></span>
- <span data-ttu-id="7cb5d-148">Globale Befehle wie "Gehe zu", die ein Ziel nicht benötigen.</span><span class="sxs-lookup"><span data-stu-id="7cb5d-148">Global commnads like "Go to start" that don't require a target.</span></span>
- <span data-ttu-id="7cb5d-149">Benutzeroberflächen für die Konversation oder Entitäten wie Cortana, die eine Funktion AI natürlicher Sprache enthalten.</span><span class="sxs-lookup"><span data-stu-id="7cb5d-149">Conversation user interfaces or entities like Cortana that have an AI Natural Language capability.</span></span>
- <span data-ttu-id="7cb5d-150">Benutzerdefinierte Befehle</span><span class="sxs-lookup"><span data-stu-id="7cb5d-150">Custom commnads</span></span>

<span data-ttu-id="7cb5d-151">Um weitere Details und eine Comprenhesive-Liste der verfügbaren Befehle und Verwendung finden, sehen Sie sich unsere [voice-Entwurf](voice-design.md) Anleitungen.</span><span class="sxs-lookup"><span data-stu-id="7cb5d-151">To find more details and a comprenhesive list of available commands and how to use, check out our [voice design](voice-design.md) guidance.</span></span>


### <a name="head-gaze-and-hololens-clicker"></a><span data-ttu-id="7cb5d-152">Head-Blicke und HoloLens Clicker</span><span class="sxs-lookup"><span data-stu-id="7cb5d-152">Head-gaze and HoloLens Clicker</span></span>
<span data-ttu-id="7cb5d-153">Die HoloLens Clicker ist der erste Peripheriegerät wurde speziell für HoloLens und mit der HoloLens 1 Development Edition enthalten ist.</span><span class="sxs-lookup"><span data-stu-id="7cb5d-153">The HoloLens Clicker is the first peripheral device built specifically for HoloLens and is included with the HoloLens 1 Development Edition.</span></span> <span data-ttu-id="7cb5d-154">Die HoloLens Clicker ermöglicht einen Benutzer mit minimalen Hand Bewegung klicken, und committen als sekundären Eingabe.</span><span class="sxs-lookup"><span data-stu-id="7cb5d-154">The HoloLens Clicker allows a user to click with minimal hand motion and commit as a secondary input.</span></span> <span data-ttu-id="7cb5d-155">Die HoloLens Clicker stellt eine Verbindung her, die HoloLens-1 oder 2 mit Bluetooth Low Energy (BTLE).</span><span class="sxs-lookup"><span data-stu-id="7cb5d-155">The HoloLens clicker connects to the HoloLens 1 or 2 using Bluetooth Low Energy (BTLE).</span></span>

![](images/hololens-clicker-500px.jpg)<br>
<span data-ttu-id="7cb5d-156">HoloLens Clicker</span><span class="sxs-lookup"><span data-stu-id="7cb5d-156">HoloLens Clicker</span></span>

<span data-ttu-id="7cb5d-157">Weitere Informationen und Anweisungen, um das Gerät koppeln finden [hier](hardware-accessories.md#pairing-bluetooth-accessories)</span><span class="sxs-lookup"><span data-stu-id="7cb5d-157">More information and instructions to pair the device can be found [here](hardware-accessories.md#pairing-bluetooth-accessories)</span></span>




### <a name="head-gaze-and-xbox-wireless-controller"></a><span data-ttu-id="7cb5d-158">Head-Blicke und Xbox-Wireless-Controller</span><span class="sxs-lookup"><span data-stu-id="7cb5d-158">Head-gaze and Xbox Wireless Controller</span></span>
<span data-ttu-id="7cb5d-159">Die drahtlose Xbox-Controller ermöglicht eine Betätigung der "klicken Sie auf" als Eingabe mithilfe der Schaltfläche ein sekundäres Replikat ausführen.</span><span class="sxs-lookup"><span data-stu-id="7cb5d-159">The Xbox Wireless Controller allows to perform a "click" actuation as a secondary input by using the A button.</span></span> <span data-ttu-id="7cb5d-160">Das Gerät ist eine Reihe von Aktionen, mit deren Hilfe navigieren und gegebenenfalls das System zugeordnet.</span><span class="sxs-lookup"><span data-stu-id="7cb5d-160">The device is mapped to a default set of actions that help navigate and controll the system.</span></span> <span data-ttu-id="7cb5d-161">Wenn Sie den Controller anpassen möchten, verwenden Sie die Xbox Accesories-App, um dem Xbox-Wireless-Controller zu konfigurieren.</span><span class="sxs-lookup"><span data-stu-id="7cb5d-161">If you want to customize the controller, use the Xbox Accesories App to configure your Xbox Wireless Controller.</span></span>

![](images/xboxcontroller.jpg)<br>
<span data-ttu-id="7cb5d-162">Xbox-Wireless-Controller</span><span class="sxs-lookup"><span data-stu-id="7cb5d-162">Xbox Wireless Controller</span></span>

[<span data-ttu-id="7cb5d-163">Kopplung mit Ihrem PC einen Xbox-controller</span><span class="sxs-lookup"><span data-stu-id="7cb5d-163">Pairing an Xbox controller with your PC</span></span>](hardware-accessories.md#pairing-bluetooth-accessories)


### <a name="head-gaze-and-xbox-adaptive-controller"></a><span data-ttu-id="7cb5d-164">Adaptive Head-Blicke und Xbox-Controller</span><span class="sxs-lookup"><span data-stu-id="7cb5d-164">Head-gaze and Xbox Adaptive Controller</span></span>
<span data-ttu-id="7cb5d-165">Soll in erster Linie den Bedürfnissen der Spieler mit eingeschränkter Beweglichkeit, ist die Adaptive Xbox-Controller ein zentraler Hub für Geräte, der dabei hilft, Mixed Reality zugänglicher zu machen.</span><span class="sxs-lookup"><span data-stu-id="7cb5d-165">Designed primarily to meet the needs of gamers with limited mobility, the Xbox Adaptive Controller is a unified hub for devices that helps make Mixed Reality more accessible.</span></span>

<span data-ttu-id="7cb5d-166">Der Adaptive Xbox-Controller ermöglicht eine Betätigung der "klicken Sie auf" als Eingabe mithilfe der Schaltfläche ein sekundäres Replikat ausführen.</span><span class="sxs-lookup"><span data-stu-id="7cb5d-166">The Xbox Adaptive Controller allows to perform a "click" actuation as a secondary input by using the A button.</span></span> <span data-ttu-id="7cb5d-167">Das Gerät ist eine Reihe von Aktionen, mit deren Hilfe navigieren und gegebenenfalls das System zugeordnet.</span><span class="sxs-lookup"><span data-stu-id="7cb5d-167">The device is mapped to a default set of actions that help navigate and controll the system.</span></span> <span data-ttu-id="7cb5d-168">Wenn Sie den Controller anpassen möchten, verwenden Sie die Xbox Accesories-App, um Ihre adaptiven Xbox-Controller zu konfigurieren.</span><span class="sxs-lookup"><span data-stu-id="7cb5d-168">If you want to customize the controller, use the Xbox Accesories App to configure your Xbox Adaptive Controller.</span></span>

![](images/xbox-adaptive-controller-devices.jpg)<br>
<span data-ttu-id="7cb5d-169">Adaptive Xbox-Controller</span><span class="sxs-lookup"><span data-stu-id="7cb5d-169">Xbox Adaptive Controller</span></span>

<span data-ttu-id="7cb5d-170">Verbinden Sie externe Geräte wie z. B. Switches, Schaltflächen, Bereitstellungen und Joysticks, um eine benutzerdefinierte Controller-Benutzeroberfläche zu erstellen, die eindeutig verwalten können.</span><span class="sxs-lookup"><span data-stu-id="7cb5d-170">Connect external devices such as switches, buttons, mounts, and joysticks to create a custom controllers experience that is uniquely yours.</span></span> <span data-ttu-id="7cb5d-171">Schaltfläche "," Ministick "und" Trigger-Eingaben werden mit Hilfstechnologiegeräte über 3,5 mm Jacks und USB-Ports verbunden gesteuert.</span><span class="sxs-lookup"><span data-stu-id="7cb5d-171">Button, thumbstick and trigger inputs are controlled with assistive devices connected through 3.5mm jacks and USB ports.</span></span>

![](images/xbox-adaptive-controller-ports.jpg)<br>
<span data-ttu-id="7cb5d-172">Adaptive Xbox-Controller-ports</span><span class="sxs-lookup"><span data-stu-id="7cb5d-172">Xbox Adaptive Controller ports</span></span>

[<span data-ttu-id="7cb5d-173">Anweisungen, um das Gerät koppeln</span><span class="sxs-lookup"><span data-stu-id="7cb5d-173">Instructions to pair the device</span></span>](hardware-accessories.md#pairing-bluetooth-accessories)

<span data-ttu-id="7cb5d-174"><a href=https://www.xbox.com/en-US/xbox-one/accessories/controllers/xbox-adaptive-controller>Weitere Informationen, die auf der Xbox-Website verfügbar</a></span><span class="sxs-lookup"><span data-stu-id="7cb5d-174"><a href=https://www.xbox.com/en-US/xbox-one/accessories/controllers/xbox-adaptive-controller>More info available on the Xbox site</a></span></span>


# <a name="head-gaze-design-guidelines"></a><span data-ttu-id="7cb5d-175">Richtlinien für den Head-Blicke-Entwurf</span><span class="sxs-lookup"><span data-stu-id="7cb5d-175">Head-gaze design guidelines</span></span>
> [!NOTE]
> <span data-ttu-id="7cb5d-176">Weitere Anleitungen, die speziell für den Entwurf bestaunen [bald](index.md).</span><span class="sxs-lookup"><span data-stu-id="7cb5d-176">More guidance specific to gaze design [coming soon](index.md).</span></span>

## <a name="head-gaze-targeting"></a><span data-ttu-id="7cb5d-177">Head-Blicke-Ziel</span><span class="sxs-lookup"><span data-stu-id="7cb5d-177">Head-gaze targeting</span></span>
<span data-ttu-id="7cb5d-178">Alle Interaktionen werden erstellt, auf die Fähigkeit eines Benutzers, das Element als Ziel, die, das Sie mit, unabhängig von der Eingabe Modalität interagieren möchten.</span><span class="sxs-lookup"><span data-stu-id="7cb5d-178">All interactions are built upon the ability of a user to target the element they want to interact with, regardless of the input modality.</span></span> <span data-ttu-id="7cb5d-179">In Windows Mixed Reality, erfolgt dies in der Regel mithilfe des Benutzers Blicke.</span><span class="sxs-lookup"><span data-stu-id="7cb5d-179">In Windows Mixed Reality, this is generally done using the user's gaze.</span></span>
<span data-ttu-id="7cb5d-180">Damit Benutzer erfolgreich eine Möglichkeit zum arbeiten können, muss des Systems berechnete Verständnis der Absicht des Benutzers und die Absicht des Benutzers tatsächliche, so weit wie möglich ausgerichtet sind.</span><span class="sxs-lookup"><span data-stu-id="7cb5d-180">To enable a user to work with an experience successfully, the system's calculated understanding of a user's intent, and the user's actual intent, must align as closely as possible.</span></span> <span data-ttu-id="7cb5d-181">Um den Grad an, dass das System den beabsichtigten Benutzeraktionen interpretiert verbessert ordnungsgemäß Kundenzufriedenheit erhöht und die Leistung.</span><span class="sxs-lookup"><span data-stu-id="7cb5d-181">To the degree that the system interprets the user's intended actions correctly, satisfaction increases and performance improves.</span></span>


## <a name="target-sizing-and-feedback"></a><span data-ttu-id="7cb5d-182">Ziel-größenanpassung und feedback</span><span class="sxs-lookup"><span data-stu-id="7cb5d-182">Target sizing and feedback</span></span>
<span data-ttu-id="7cb5d-183">Der Blicke Vektor hat wiederholt angezeigt wurden, für die Ziel-problemlos verwendet werden kann, aber häufig am besten für gross für die Zielgruppenadressierung (erwerben von etwas größer Ziele).</span><span class="sxs-lookup"><span data-stu-id="7cb5d-183">The gaze vector has been shown repeatedly to be usable for fine targeting, but often works best for gross targeting (acquiring somewhat larger targets).</span></span> <span data-ttu-id="7cb5d-184">Mindestversion der Zielplattform Größen von 1 bis 1.5 Grad sollte erfolgreich Benutzeraktionen in den meisten Szenarien ermöglichen, wenn Ziele von 3 Grad häufig schneller zu ermöglichen.</span><span class="sxs-lookup"><span data-stu-id="7cb5d-184">Minimum target sizes of 1 to 1.5 degrees should allow successful user actions in most scenarios, though targets of 3 degrees often allow for greater speed.</span></span> <span data-ttu-id="7cb5d-185">Beachten Sie, dass die Größe, der Benutzerziele ist eine 2D-Bereich auch für 3D-Elemente – welche Projektion sie-Sie sollte Bereich als Ziel gesetzt sein.</span><span class="sxs-lookup"><span data-stu-id="7cb5d-185">Note that the size that the user targets is effectively a 2D area even for 3D elements--whichever projection is facing them should be the targetable area.</span></span> <span data-ttu-id="7cb5d-186">Bietet einige wichtige Hinweis, dass ein Element "aktiv" ist, (, dass der Benutzer es abzielt) äußerst hilfreich ist – dazu zählen Behandlungen, damit wie sichtbar "darauf zeigen" Effekte "," audio-Highlights "oder" klickt, oder deaktivieren Sie die Ausrichtung eines Cursors mit einem Element.</span><span class="sxs-lookup"><span data-stu-id="7cb5d-186">Providing some salient cue that an element is "active" (that the user is targeting it) is extremely helpful - this can include treatments like visible "hover" effects, audio highlights or clicks, or clear alignment of a cursor with an element.</span></span>

<span data-ttu-id="7cb5d-187">![Optimale Zielgröße im Abstand von 2 Verbrauchseinheit](images/gazetargeting-size-1000px.jpg)</span><span class="sxs-lookup"><span data-stu-id="7cb5d-187">![Optimal target size at 2 meter distance](images/gazetargeting-size-1000px.jpg)</span></span><br>
<span data-ttu-id="7cb5d-188">*Optimale Zielgröße im Abstand von 2 Verbrauchseinheit*</span><span class="sxs-lookup"><span data-stu-id="7cb5d-188">*Optimal target size at 2 meter distance*</span></span>

<span data-ttu-id="7cb5d-189">![Ein Beispiel für ein Zielobjekt Blicke hervorheben](images/gazetargeting-highlighting-640px.jpg)</span><span class="sxs-lookup"><span data-stu-id="7cb5d-189">![An example of highlighting a gaze targeted object](images/gazetargeting-highlighting-640px.jpg)</span></span><br>
<span data-ttu-id="7cb5d-190">*Ein Beispiel für ein Zielobjekt Blicke hervorheben*</span><span class="sxs-lookup"><span data-stu-id="7cb5d-190">*An example of highlighting a gaze targeted object*</span></span>

## <a name="target-placement"></a><span data-ttu-id="7cb5d-191">Ziel-Platzierung</span><span class="sxs-lookup"><span data-stu-id="7cb5d-191">Target placement</span></span>
<span data-ttu-id="7cb5d-192">Benutzer können häufig nicht finden im jeweiligen Lesebereich, Benutzeroberflächenelemente, die sehr hoch oder sehr niedrige positioniert sind die meisten ihre Aufmerksamkeit auf Bereiche, um ihren Mittelpunkt (in der Regel ungefähr Eye-Ebene) konzentrieren.</span><span class="sxs-lookup"><span data-stu-id="7cb5d-192">Users will often fail to find UI elements that are positioned very high or very low in their field of view, focusing most of their attention on areas around their main focus (usually roughly eye level).</span></span> <span data-ttu-id="7cb5d-193">Die meisten Ziele in eine angemessene-Band-Bereich von Eye-Ebene platzieren können.</span><span class="sxs-lookup"><span data-stu-id="7cb5d-193">Placing most targets in some reasonable band around eye level can help.</span></span> <span data-ttu-id="7cb5d-194">Erhält die Tendenz eines für Benutzer kann für den Blick auf einer relativ kleinen visuellen Elements jederzeit (der attentional Lichtkegel des Vision ist ungefähr 10 Grad), der gruppieren Elemente der Benutzeroberfläche, die den Grad an, dass sie konzeptionell verwandt sind Aufmerksamkeit mit vorwärtsverkettung Verhaltensweisen nutzen Element zu Element als ein Benutzer durchläuft einen Bereich ihre Blicke.</span><span class="sxs-lookup"><span data-stu-id="7cb5d-194">Given the tendency for users to focus on a relatively small visual area at any time (the attentional cone of vision is roughly 10 degrees), grouping UI elements together to the degree that they're related conceptually can leverage attention-chaining behaviors from item to item as a user moves their gaze through an area.</span></span> <span data-ttu-id="7cb5d-195">Beim Entwerfen der Benutzeroberfläche sollten Sie Bedenken der großen möglichen Variante im Lesebereich zwischen HoloLens und immersive Headsets.</span><span class="sxs-lookup"><span data-stu-id="7cb5d-195">When designing UI, keep in mind the potential large variation in field of view between HoloLens and immersive headsets.</span></span>

<span data-ttu-id="7cb5d-196">![Ein Beispiel für gruppierte Elemente der Benutzeroberfläche für einfacher Blicke Zielgruppenadressierung in Galaxy-Explorer](images/gazetargeting-grouping-1000px.jpg)</span><span class="sxs-lookup"><span data-stu-id="7cb5d-196">![An example of grouped UI elements for easier gaze targeting in Galaxy Explorer](images/gazetargeting-grouping-1000px.jpg)</span></span><br>
<span data-ttu-id="7cb5d-197">*Ein Beispiel für gruppierte Elemente der Benutzeroberfläche für einfacher Blicke Zielgruppenadressierung in Galaxy-Explorer*</span><span class="sxs-lookup"><span data-stu-id="7cb5d-197">*An example of grouped UI elements for easier gaze targeting in Galaxy Explorer*</span></span>

## <a name="improving-targeting-behaviors"></a><span data-ttu-id="7cb5d-198">Verbessern die Zielgruppenadressierung anhand bestimmter Verhaltensweisen</span><span class="sxs-lookup"><span data-stu-id="7cb5d-198">Improving targeting behaviors</span></span>
<span data-ttu-id="7cb5d-199">Wenn Benutzerabsicht etwas Ziel kann werden festgelegt (oder eng angeglichen), kann es sehr hilfreich sein, zu akzeptieren, dass "Near Miss" bei der Interaktion versucht, als ob sie ordnungsgemäß zugewiesen wurden.</span><span class="sxs-lookup"><span data-stu-id="7cb5d-199">If user intent to target something can be determined (or approximated closely), it can be very helpful to accept "near miss" attempts at interaction as though they were targeted correctly.</span></span> <span data-ttu-id="7cb5d-200">Es gibt eine Reihe von erfolgreichen Methoden, die in mixed Reality-Benutzeroberfläche integriert werden können:</span><span class="sxs-lookup"><span data-stu-id="7cb5d-200">There are a handful of successful methods that can be incorporated in mixed reality experiences:</span></span>

### <a name="head-gaze-stabilization-gravity-wells"></a><span data-ttu-id="7cb5d-201">Head-Blicke Stabilisierung ("Schwerkraft Wells")</span><span class="sxs-lookup"><span data-stu-id="7cb5d-201">Head-gaze stabilization ("gravity wells")</span></span>
<span data-ttu-id="7cb5d-202">Dies sollte die meisten oder alle der Zeit aktiviert werden.</span><span class="sxs-lookup"><span data-stu-id="7cb5d-202">This should be turned on most/all of the time.</span></span> <span data-ttu-id="7cb5d-203">Dieses Verfahren wird die natürliche Haupt-/trichterhalses JIT-Compiler, die Benutzer möglicherweise entfernt.</span><span class="sxs-lookup"><span data-stu-id="7cb5d-203">This technique removes the natural head/neck jitters that users may have.</span></span> <span data-ttu-id="7cb5d-204">Auch Verschiebung aufgrund von Verhaltensweisen suchen/sprechen.</span><span class="sxs-lookup"><span data-stu-id="7cb5d-204">Also movement due to looking/speaking behaviors.</span></span>

### <a name="closest-link-algorithms"></a><span data-ttu-id="7cb5d-205">Am nächsten Link-Algorithmen</span><span class="sxs-lookup"><span data-stu-id="7cb5d-205">Closest link algorithms</span></span>
<span data-ttu-id="7cb5d-206">Diese funktionieren am besten in Bereichen mit geringer Dichte interaktive Inhalte.</span><span class="sxs-lookup"><span data-stu-id="7cb5d-206">These work best in areas with sparse interactive content.</span></span> <span data-ttu-id="7cb5d-207">Liegt eine hohe Wahrscheinlichkeit, dass auf Sie bestimmen können, was ein Benutzer versucht hat, für die Interaktion mit, können Sie die Zielgruppenadressierung anhand bestimmter Möglichkeiten ergänzen, indem Sie einfach vorausgesetzt gewisse Absicht.</span><span class="sxs-lookup"><span data-stu-id="7cb5d-207">If there is a high probability that you can determine what a user was attempting to interact with, you can supplement their targeting abilities by simply assuming some level of intent.</span></span>

### <a name="backdatingpostdating-actions"></a><span data-ttu-id="7cb5d-208">Backdating/postdating Aktionen</span><span class="sxs-lookup"><span data-stu-id="7cb5d-208">Backdating/postdating actions</span></span>
<span data-ttu-id="7cb5d-209">Dieser Mechanismus eignet sich Aufgaben aus, die Geschwindigkeit zur Verfügung.</span><span class="sxs-lookup"><span data-stu-id="7cb5d-209">This mechanism is useful in tasks requiring speed.</span></span> <span data-ttu-id="7cb5d-210">Wenn ein Benutzer über eine Reihe von Ziel/Aktivierung Schachzüge Geschwindigkeit verschoben wird, kann es hilfreich sein, einige Absicht angenommen und fehlenden Schritte aus, um auf Zielgruppen fungieren, mit denen der Benutzer den Fokus etwas hat vor oder nach der das Tap (50 ms war vor/hinter effektiv etwas zulassen Testen früh) ein.</span><span class="sxs-lookup"><span data-stu-id="7cb5d-210">When a user is moving through a series of targeting/activation maneuvers at speed, it can be useful to assume some intent and allow missed steps to act upon targets which the user had in focus slightly before or slightly after the tap (50ms before/after was effective in early testing).</span></span>

### <a name="smoothing"></a><span data-ttu-id="7cb5d-211">Glättung</span><span class="sxs-lookup"><span data-stu-id="7cb5d-211">Smoothing</span></span>
<span data-ttu-id="7cb5d-212">Dieser Mechanismus eignet sich für Pfade Bewegungen, reduzieren die leichte Jitter/bringen aufgrund von natürlichen Bewegungen Merkmale.</span><span class="sxs-lookup"><span data-stu-id="7cb5d-212">This mechanism is useful for pathing movements, reducing the slight jitter/wobble due to natural head movement characteristics.</span></span> <span data-ttu-id="7cb5d-213">Wenn Sie über die Pfade Bewegungen, die von der Größe/Entfernung von Bewegungen statt im Laufe der Zeit smooth-Glättung</span><span class="sxs-lookup"><span data-stu-id="7cb5d-213">When smoothing over pathing motions, smooth by size/distance of movements rather than over time</span></span>

### <a name="magnetism"></a><span data-ttu-id="7cb5d-214">Magnetismus</span><span class="sxs-lookup"><span data-stu-id="7cb5d-214">Magnetism</span></span>
<span data-ttu-id="7cb5d-215">Dieser Mechanismus kann als eine allgemeine Version des "Nächsten link" Algorithmen, zeichnen einen Cursor auf ein Ziel oder Vergrößerung Hitboxes (ob sichtbar oder nicht) betrachtet werden, wie Benutzer wahrscheinlich Ziele Ansatz, verwenden einige Kenntnisse über das interaktive Layout Benutzerabsicht für eine bessere Ansatz.</span><span class="sxs-lookup"><span data-stu-id="7cb5d-215">This mechanism can be thought of as a more general version of "Closest link" algorithms - drawing a cursor toward a target, or simply increasing hitboxes (whether visibly or not) as users approach likely targets, using some knowledge of the interactive layout to better approach user intent.</span></span> <span data-ttu-id="7cb5d-216">Dies kann besonders für kleine Ziele effektiv sein.</span><span class="sxs-lookup"><span data-stu-id="7cb5d-216">This can be particularly powerful for small targets.</span></span>

### <a name="focus-stickiness"></a><span data-ttu-id="7cb5d-217">Fokus-Bindung</span><span class="sxs-lookup"><span data-stu-id="7cb5d-217">Focus stickiness</span></span>
<span data-ttu-id="7cb5d-218">Wenn Sie die in der Nähe interaktive Elemente Fokus erhalten bestimmen, geben Sie eine Verschiebung auf das Element, das gerade fokussiert ist.</span><span class="sxs-lookup"><span data-stu-id="7cb5d-218">When determining which nearby interactive elements to give focus to, provide a bias to the element that is currently focused.</span></span> <span data-ttu-id="7cb5d-219">Dadurch können die fehlerhaften Verhalten wechseln, in eine Mitte zwischen zwei Elemente mit dem natürlichen Geräusch unverankerten Fokus zu reduzieren.</span><span class="sxs-lookup"><span data-stu-id="7cb5d-219">This will help reduce erratic focus switching behaviours when floating at a midpoint between two elements with natural noise.</span></span>


## <a name="composite-gestures"></a><span data-ttu-id="7cb5d-220">Zusammengesetzte Gesten</span><span class="sxs-lookup"><span data-stu-id="7cb5d-220">Composite gestures</span></span>
<span data-ttu-id="7cb5d-221">Apps können mehr als nur einzelne Taps erkennen.</span><span class="sxs-lookup"><span data-stu-id="7cb5d-221">Apps can recognize more than just individual taps.</span></span> <span data-ttu-id="7cb5d-222">Durch Kombinieren von Tap zu speichern und Freigeben mit dem Wechsel der Hand, komplexere zusammengesetzte Gesten ausgeführt werden können.</span><span class="sxs-lookup"><span data-stu-id="7cb5d-222">By combining tap, hold and release with the movement of the hand, more complex composite gestures can be performed.</span></span> <span data-ttu-id="7cb5d-223">Erstellen Sie für diese Gesten zusammengesetzten oder auf hoher Ebene für die Low-Level räumlichen Eingabedaten (von tippbewegung und Bloom), die Entwicklern den Zugriff auf.</span><span class="sxs-lookup"><span data-stu-id="7cb5d-223">These composite or high-level gestures build on the low-level spatial input data (from Air tap and Bloom) that developers have access to.</span></span>

### <a name="air-tap"></a><span data-ttu-id="7cb5d-224">Tippen Sie auf</span><span class="sxs-lookup"><span data-stu-id="7cb5d-224">Air tap</span></span>
<span data-ttu-id="7cb5d-225">Die tippbewegung (ebenso wie die anderen Bewegungen, die unten) reagiert nur auf ein bestimmtes tippen.</span><span class="sxs-lookup"><span data-stu-id="7cb5d-225">The Air tap gesture (as well as the other gestures below) reacts only to a specific tap.</span></span> <span data-ttu-id="7cb5d-226">Zum Erkennen von anderen Taps, z. B. Menüs oder verstehen, muss Ihre app direkt die Low-Level-Interaktionen, die in zwei wichtige Komponente Gesten-Abschnitt oben beschrieben verwenden.</span><span class="sxs-lookup"><span data-stu-id="7cb5d-226">To detect other taps, such as Menu or Grasp, your app must directly use the lower-level interactions described in two key component gestures section above.</span></span>

### <a name="tap-and-hold"></a><span data-ttu-id="7cb5d-227">Tippen und halten Sie</span><span class="sxs-lookup"><span data-stu-id="7cb5d-227">Tap and hold</span></span>
<span data-ttu-id="7cb5d-228">Die Position nach unten weisenden Finger die tippbewegung verwaltet halten einfach.</span><span class="sxs-lookup"><span data-stu-id="7cb5d-228">Hold is simply maintaining the downward finger position of the air tap.</span></span> <span data-ttu-id="7cb5d-229">Die Kombination von Air Tap- und Hold ermöglicht eine Vielzahl von komplexeren "klicken und ziehen Sie" Interaktionen in Kombination mit Arm-Bewegung, z. B. ein Objekt und nicht deren Aktivierung übernommen oder "Mousedown" sekundäre Interaktionen wie z. B. ein Kontextmenü angezeigt.</span><span class="sxs-lookup"><span data-stu-id="7cb5d-229">The combination of air tap and hold allows for a variety of more complex "click and drag" interactions when combined with arm movement such as picking up an object instead of activating it or "mousedown" secondary interactions such as showing a context menu.</span></span>
<span data-ttu-id="7cb5d-230">Vorsicht sollte verwendet werden, wenn für diese stiftbewegung jedoch als Benutzer entwerfen anfällig für lockern ihre Hand Postures im Verlauf erweiterten Bewegung werden kann.</span><span class="sxs-lookup"><span data-stu-id="7cb5d-230">Caution should be used when designing for this gesture however, as users can be prone to relaxing their hand postures during the course of any extended gesture.</span></span>

### <a name="manipulation"></a><span data-ttu-id="7cb5d-231">Datenbearbeitung</span><span class="sxs-lookup"><span data-stu-id="7cb5d-231">Manipulation</span></span>
<span data-ttu-id="7cb5d-232">Manipulation Gesten können verwendet werden, zu verschieben, ändern Sie die Größe oder ggf. ein Hologramm zu rotieren, wenn die Hologramm, 1:1 für Bewegungen, die der Benutzer manuell zu reagieren soll.</span><span class="sxs-lookup"><span data-stu-id="7cb5d-232">Manipulation gestures can be used to move, resize or rotate a hologram when you want the hologram to react 1:1 to the user's hand movements.</span></span> <span data-ttu-id="7cb5d-233">Diese 1:1-Bewegungen können verwendet werden, damit der Benutzer, die gezeichnet werden soll, oder in der ganzen Welt zu zeichnen.</span><span class="sxs-lookup"><span data-stu-id="7cb5d-233">One use for such 1:1 movements is to let the user draw or paint in the world.</span></span>
<span data-ttu-id="7cb5d-234">Die erste Zielgruppenadressierung für eine Bewegung der Manipulation sollten durch Blicke oder zeigt durchgeführt werden.</span><span class="sxs-lookup"><span data-stu-id="7cb5d-234">The initial targeting for a manipulation gesture should be done by gaze or pointing.</span></span> <span data-ttu-id="7cb5d-235">Sobald die Tap- und Hold gestartet wird, Änderungen an das Objekt dann erfolgt manuell Bewegungen, Freigeben von dem Benutzer zu suchen, während sie ändern.</span><span class="sxs-lookup"><span data-stu-id="7cb5d-235">Once the tap and hold starts, any manipulation of the object is then handled by hand movements, freeing the user to look around while they manipulate.</span></span>

### <a name="navigation"></a><span data-ttu-id="7cb5d-236">Navigation</span><span class="sxs-lookup"><span data-stu-id="7cb5d-236">Navigation</span></span>
<span data-ttu-id="7cb5d-237">Navigation Gesten funktioniert wie ein virtueller Joystick und können verwendet werden, um die UI-Widgets, wie z.B. radiale Menüs navigieren.</span><span class="sxs-lookup"><span data-stu-id="7cb5d-237">Navigation gestures operate like a virtual joystick, and can be used to navigate UI widgets, such as radial menus.</span></span> <span data-ttu-id="7cb5d-238">Sie tippen und halten Sie, um die Bewegung gestartet, und verschieben Sie Ihre Hand innerhalb einer normalisierten 3D-Würfel zentraler Punkt drücken, auf der ersten.</span><span class="sxs-lookup"><span data-stu-id="7cb5d-238">You tap and hold to start the gesture and then move your hand within a normalized 3D cube, centered around the initial press.</span></span> <span data-ttu-id="7cb5d-239">Sie können Ihre Hand entlang der X-, Y oder Z-Achse aus einem Wert von-1 in 1, wobei 0 für den Anfangspunkt, an die verschieben.</span><span class="sxs-lookup"><span data-stu-id="7cb5d-239">You can move your hand along the X, Y or Z axis from a value of -1 to 1, with 0 being the starting point.</span></span>
<span data-ttu-id="7cb5d-240">Navigation kann verwendet werden, um fortlaufenden Bildlauf Geschwindigkeit-basierte oder Zoomen Gesten, ähnlich wie eine 2D Benutzeroberfläche scrollen, indem Sie auf der mittleren Maustaste, und klicken Sie dann nach oben und unten bewegen der Maus zu erstellen.</span><span class="sxs-lookup"><span data-stu-id="7cb5d-240">Navigation can be used to build velocity-based continuous scrolling or zooming gestures, similar to scrolling a 2D UI by clicking the middle mouse button and then moving the mouse up and down.</span></span>

<span data-ttu-id="7cb5d-241">Navigation mit Rails bezieht sich auf die Fähigkeit zum Erkennen von Bewegungen im bestimmte Achse bis auf dieser Achse bestimmten Schwellenwert erreicht ist.</span><span class="sxs-lookup"><span data-stu-id="7cb5d-241">Navigation with rails refers to the ability of recognizing movements in certain axis until certain threshold is reached on that axis.</span></span> <span data-ttu-id="7cb5d-242">Dies ist nur nützlich, wenn das Verschieben von Daten in mehr als eine Achse in einer Anwendung vom Entwickler z. B. aktiviert ist, wenn eine Anwendung so konfiguriert, dass die um Navigation Gesten in X, Y-Achse zu erkennen ist, sondern auch angegeben X-Achse mit Schienen.</span><span class="sxs-lookup"><span data-stu-id="7cb5d-242">This is only useful, when movement in more than one axis is enabled in an application by the developer, e.g. if an application is configured to recognize navigation gestures across X, Y axis but also specified X axis with rails.</span></span> <span data-ttu-id="7cb5d-243">In diesem Fall erkennt System manuell Bewegungen, für die X-Achse, solange diese innerhalb einer imaginären Rails (Handbuch) für X-Achse, bleiben, wenn Hand datenverschiebung tritt auch auf die y-Achse.</span><span class="sxs-lookup"><span data-stu-id="7cb5d-243">In this case system will recognize hand movements across X axis as long as they remain within an imaginary rails (guide) on X axis, if hand movement also occurs Y axis.</span></span>

<span data-ttu-id="7cb5d-244">In Direct2D-apps können Benutzer vertikale Navigation Gesten scrollen, Zoomen, oder ziehen in der app verwenden.</span><span class="sxs-lookup"><span data-stu-id="7cb5d-244">Within 2D apps, users can use vertical navigation gestures to scroll, zoom, or drag inside the app.</span></span> <span data-ttu-id="7cb5d-245">Dies fügt virtuellen Finger Workflows an die app zum Simulieren von Touchgesten des gleichen Typs.</span><span class="sxs-lookup"><span data-stu-id="7cb5d-245">This injects virtual finger touches to the app to simulate touch gestures of the same type.</span></span> <span data-ttu-id="7cb5d-246">Benutzer können auswählen, welche der folgenden Aktionen durchgeführt werden, durch das Umschalten zwischen den Tools auf der Leiste über die app, entweder durch Auswählen der Schaltfläche oder sagen "< Scroll/Drag/vergrößern > Tool".</span><span class="sxs-lookup"><span data-stu-id="7cb5d-246">Users can select which of these actions take place by toggling between the tools on the bar above the app, either by selecting the button or saying '<Scroll/Drag/Zoom> Tool'.</span></span>

[<span data-ttu-id="7cb5d-247">Weitere Informationen zur zusammengesetzten Gesten</span><span class="sxs-lookup"><span data-stu-id="7cb5d-247">More info on composite gestures</span></span>](gestures.md#composite-gestures)

## <a name="gesture-recognizers"></a><span data-ttu-id="7cb5d-248">Geste Erkennungen</span><span class="sxs-lookup"><span data-stu-id="7cb5d-248">Gesture recognizers</span></span>

<span data-ttu-id="7cb5d-249">Ein Vorteil der Verwendung von gestenerkennung ist, dass Sie eine stiftbewegungs-Erkennung nur für die Gesten konfigurieren können, die derzeit gezielte – Hologramm annehmen kann.</span><span class="sxs-lookup"><span data-stu-id="7cb5d-249">One benefit of using gesture recognition is that you can configure a gesture recognizer just for the gestures the currently targeted hologram can accept.</span></span> <span data-ttu-id="7cb5d-250">Die Plattform erfolgt nur die zur mehrdeutigkeitsvermeidung erforderlich, um diese bestimmten unterstützten Gesten zu unterscheiden.</span><span class="sxs-lookup"><span data-stu-id="7cb5d-250">The platform will do only the disambiguation necessary to distinguish those particular supported gestures.</span></span> <span data-ttu-id="7cb5d-251">Auf diese Weise kann ggf. ein Hologramm, die nur die tippbewegung unterstützt unbestimmte Zeit zwischen drücken Sie akzeptieren, und ggf. ein Hologramm, unterstützt sowohl tippen und halten Sie können höher stufen, das Tap, stehen nach der Hold-Suchdauer-Schwellenwert.</span><span class="sxs-lookup"><span data-stu-id="7cb5d-251">That way, a hologram that just supports air tap can accept any length of time between press and release, while a hologram that supports both tap and hold can promote the tap to a hold after the hold time threshold.</span></span>

## <a name="hand-recognition"></a><span data-ttu-id="7cb5d-252">Hand-Erkennung</span><span class="sxs-lookup"><span data-stu-id="7cb5d-252">Hand recognition</span></span>
<span data-ttu-id="7cb5d-253">HoloLens erkennt die gestensteuerung durch Überwachung der Position einer oder beide Hände, die auf dem Gerät angezeigt werden.</span><span class="sxs-lookup"><span data-stu-id="7cb5d-253">HoloLens recognizes hand gestures by tracking the position of either or both hands that are visible to the device.</span></span> <span data-ttu-id="7cb5d-254">HoloLens werden praktische angezeigt, wenn sie sich im Zustand "bereit" (Rückseite der Hand, die Sie mit Zeigefinger nach, oben) oder (Rückseite der Hand, die Sie mit dem Finger Index nach unten gerichteten) gedrückt werden.</span><span class="sxs-lookup"><span data-stu-id="7cb5d-254">HoloLens sees hands when they are in either the ready state (back of the hand facing you with index finger up) or the pressed state (back of the hand facing you with the index finger down).</span></span> <span data-ttu-id="7cb5d-255">Wenn andere stellt praktische nutzen, wird die HoloLens werden ignoriert.</span><span class="sxs-lookup"><span data-stu-id="7cb5d-255">When hands are in other poses, the HoloLens will ignore them.</span></span>
<span data-ttu-id="7cb5d-256">Jeder Runde erkennt, HoloLens, Sie seine Position (ohne Ausrichtung) und ihren aktuellen Status zugreifen können.</span><span class="sxs-lookup"><span data-stu-id="7cb5d-256">For each hand that HoloLens detects, you can access its position (without orientation) and its pressed state.</span></span> <span data-ttu-id="7cb5d-257">Das Handsymbol den Rand des Rahmens Geste nähert, sind Sie auch bei einem Richtungsvektor bereitgestellt das Sie für den Benutzer anzeigen können, damit sie wissen, verschieben Sie ihre Hand, um es wieder zu erhalten, sodass HoloLens sie sehen können.</span><span class="sxs-lookup"><span data-stu-id="7cb5d-257">As the hand nears the edge of the gesture frame, you're also provided with a direction vector, which you can show to the user so they know how to move their hand to get it back where HoloLens can see it.</span></span>

## <a name="gesture-frame"></a><span data-ttu-id="7cb5d-258">Geste frame</span><span class="sxs-lookup"><span data-stu-id="7cb5d-258">Gesture frame</span></span>
<span data-ttu-id="7cb5d-259">Bei Gesten für HoloLens muss das Handsymbol innerhalb eines"Aktion", in einem Bereich, der die Bewegung Erkennung Kameras entsprechend (sehr grob von Nase Taille und zwischen den Schultern) angezeigt.</span><span class="sxs-lookup"><span data-stu-id="7cb5d-259">For gestures on HoloLens, the hand must be within a “gesture frame”, in a range that the gesture-sensing cameras can see appropriately (very roughly from nose to waist, and between the shoulders).</span></span> <span data-ttu-id="7cb5d-260">Benutzer müssen auf diesen Bereich der Erkennung sowohl für die erfolgreiche Durchführung der Aktion als auch für ihre eigenen Komfort (viele Benutzer werden anfänglich wird davon ausgegangen, dass die Bewegung Frame muss in ihrer Ansicht über HoloLens und zu Verzögerungen bei ihren Arms uncomfortably um interagieren) trainiert werden.</span><span class="sxs-lookup"><span data-stu-id="7cb5d-260">Users need to be trained on this area of recognition both for success of action and for their own comfort (many users will initially assume that the gesture frame must be within their view through HoloLens, and hold their arms up uncomfortably in order to interact).</span></span> <span data-ttu-id="7cb5d-261">Wenn Sie die HoloLens Clicker verwenden zu können, müssen Sie sich nicht innerhalb des Rahmens Geste werden.</span><span class="sxs-lookup"><span data-stu-id="7cb5d-261">When using the HoloLens Clicker, your hands do not need to be within the gesture frame.</span></span>

<span data-ttu-id="7cb5d-262">Im Fall von kontinuierlichen Gesten insbesondere besteht das Risiko von Benutzern, die sich außerhalb der Bewegung Frame in der Mitte Geste (während ein holographic-Objekt, z. B. verschieben) verschieben und dem gewünschten Ergebnis verlieren.</span><span class="sxs-lookup"><span data-stu-id="7cb5d-262">In the case of continuous gestures in particular, there is some risk of users moving their hands outside of the gesture frame while in mid-gesture (while moving some holographic object, for example), and losing their intended outcome.</span></span>

<span data-ttu-id="7cb5d-263">Es gibt drei Dinge, die Sie berücksichtigen sollten:</span><span class="sxs-lookup"><span data-stu-id="7cb5d-263">There are three things that you should consider:</span></span>

- <span data-ttu-id="7cb5d-264">Schulung der Benutzer auf die Bewegung des Frames Vorhandensein und die ungefähre Grenzen (Dies wird während des Setups von HoloLens unterrichtet).</span><span class="sxs-lookup"><span data-stu-id="7cb5d-264">User education on the gesture frame's existence and approximate boundaries (this is taught during HoloLens setup).</span></span>

- <span data-ttu-id="7cb5d-265">Benachrichtigen Benutzer aus, wenn ihre Bewegungen demnächst/der Bewegung Frame Grenzen innerhalb einer Anwendung, die den Grad an wichtige sind, die eine Geste für eine verlorene zu unerwünschten Ergebnissen führen.</span><span class="sxs-lookup"><span data-stu-id="7cb5d-265">Notifying users when their gestures are nearing/breaking the gesture frame boundaries within an application, to the degree that a lost gesture will lead to undesired outcomes.</span></span> <span data-ttu-id="7cb5d-266">Research hat gezeigt, die wichtigsten Qualitäten eines solchen Notification Systems, und die HoloLens-Shell bietet ein gutes Beispiel für diese Art von Benachrichtigung (Visualisierung, auf den zentralen-Cursor, der angibt, der Richtung, in welcher, die begrenzungsgruppe überschreiten stattfindet).</span><span class="sxs-lookup"><span data-stu-id="7cb5d-266">Research has shown the key qualities of such a notification system, and the HoloLens shell provides a good example of this type of notification (visual, on the central cursor, indicating the direction in which boundary crossing is taking place).</span></span>

- <span data-ttu-id="7cb5d-267">Auswirkungen die Bewegung Frame Grenzen zu beschädigen sollte minimiert werden.</span><span class="sxs-lookup"><span data-stu-id="7cb5d-267">Consequences of breaking the gesture frame boundaries should be minimized.</span></span> <span data-ttu-id="7cb5d-268">Im Allgemeinen bedeutet dies, dass das Ergebnis einer Geste an der Grenze beendet, aber nicht rückgängig gemacht werden soll.</span><span class="sxs-lookup"><span data-stu-id="7cb5d-268">In general, this means that the outcome of a gesture should be stopped at the boundary, but not reversed.</span></span> <span data-ttu-id="7cb5d-269">Z. B., wenn ein Benutzer ein holographic Objekt in einem Raum verschoben wird, sollten Bewegung beendet, wenn der Bewegung Frame überschritten wird, aber nicht wieder in den Ausgangspunkt.</span><span class="sxs-lookup"><span data-stu-id="7cb5d-269">For example, if a user is moving some holographic object across a room, movement should stop when the gesture frame is breached, but not be returned to the starting point.</span></span> <span data-ttu-id="7cb5d-270">Der Benutzer kann auftreten, klicken Sie dann einige Frustration jedoch möglicherweise schneller verstehen Sie die Grenzen und nicht die vollständige beabsichtigten Aktionen jedes Mal neu gestartet haben.</span><span class="sxs-lookup"><span data-stu-id="7cb5d-270">The user may experience some frustration then, but may more quickly understand the boundaries, and not have to restart their full intended actions each time.</span></span>


## <a name="see-also"></a><span data-ttu-id="7cb5d-271">Siehe auch</span><span class="sxs-lookup"><span data-stu-id="7cb5d-271">See also</span></span>
* [<span data-ttu-id="7cb5d-272">Direkte Manipulation</span><span class="sxs-lookup"><span data-stu-id="7cb5d-272">Direct manipulation</span></span>](direct-manipulation.md)
* [<span data-ttu-id="7cb5d-273">Zeigen und Ausführen</span><span class="sxs-lookup"><span data-stu-id="7cb5d-273">Point and commit</span></span>](point-and-commit.md)
* [<span data-ttu-id="7cb5d-274">Interaktionsgrundlagen</span><span class="sxs-lookup"><span data-stu-id="7cb5d-274">Interaction fundamentals</span></span>](interaction-fundamentals.md)
* [<span data-ttu-id="7cb5d-275">Anvisieren und Verweilen</span><span class="sxs-lookup"><span data-stu-id="7cb5d-275">Gaze and dwell</span></span>](gaze-targeting.md)
* [<span data-ttu-id="7cb5d-276">Anvisieren und Spracheingabe</span><span class="sxs-lookup"><span data-stu-id="7cb5d-276">Gaze and voice</span></span>](voice-design.md)





