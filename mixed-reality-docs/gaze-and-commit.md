---
title: Anvisieren mit dem Kopf und Ausführen
description: Übersicht über das Eingabemodell „Anvisieren mit dem Kopf und Ausführen“
author: caseymeekhof
ms.author: cmeekhof
ms.date: 03/31/2019
ms.topic: article
keywords: Mixed Reality, Anvisieren, Zielbestimmung, Interaktion, Entwurf
ms.openlocfilehash: aeca5ceacf5ae350aa06cb58cc68162f885f6d78
ms.sourcegitcommit: b0b1b8e1182cce93929d409706cdaa99ff24fdee
ms.translationtype: MT
ms.contentlocale: de-DE
ms.lasthandoff: 07/23/2019
ms.locfileid: "68387678"
---
# <a name="head-gaze-and-commit"></a><span data-ttu-id="91066-104">Anvisieren mit dem Kopf und Ausführen</span><span class="sxs-lookup"><span data-stu-id="91066-104">Head-gaze and commit</span></span>
<span data-ttu-id="91066-105">Der Kopf-und Commit-Vorgang ist ein Eingabe Modell, das die Ausrichtung auf ein Objekt mit der Richtung ihrer Kopfzeile (Kopfzeile) umfasst und dann mit einer sekundären Eingabe, wie z. b. der Handbewegung oder dem Sprachbefehl SELECT, agiert.</span><span class="sxs-lookup"><span data-stu-id="91066-105">Head-gaze and commit is an input model that involves targeting an object with the direction of your head pointing forward (head-direction), and then acting on it with a secondary input, such as the hand gesture air tap or the voice command Select.</span></span> <span data-ttu-id="91066-106">Es wird als ein weitreichendes Eingabe Modell mit indirekter Bearbeitung betrachtet, was bedeutet, dass es am besten für die Interaktion mit Inhalten verwendet werden kann</span><span class="sxs-lookup"><span data-stu-id="91066-106">It is considered a far input model with indirect manipulation, meaning it is best used for interacting with content that is beyond arms reach.</span></span>

## <a name="device-support"></a><span data-ttu-id="91066-107">Unterstützung von Geräten</span><span class="sxs-lookup"><span data-stu-id="91066-107">Device support</span></span>

<table>
    <colgroup>
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    </colgroup>
    <tr>
        <td><span data-ttu-id="91066-108"><strong>Eingabemodell</strong></span><span class="sxs-lookup"><span data-stu-id="91066-108"><strong>Input model</strong></span></span></td>
        <td><span data-ttu-id="91066-109"><a href="hololens-hardware-details.md"><strong>HoloLens (1. Generation)</strong></a></span><span class="sxs-lookup"><span data-stu-id="91066-109"><a href="hololens-hardware-details.md"><strong>HoloLens (1st gen)</strong></a></span></span></td>
        <td><span data-ttu-id="91066-110"><strong>HoloLens 2</strong></span><span class="sxs-lookup"><span data-stu-id="91066-110"><strong>HoloLens 2</strong></span></span></td>
        <td><span data-ttu-id="91066-111"><a href="immersive-headset-hardware-details.md"><strong>Immersive Headsets</strong></a></span><span class="sxs-lookup"><span data-stu-id="91066-111"><a href="immersive-headset-hardware-details.md"><strong>Immersive headsets</strong></a></span></span></td>
    </tr>
     <tr>
        <td><span data-ttu-id="91066-112">Anvisieren mit dem Kopf und Ausführen</span><span class="sxs-lookup"><span data-stu-id="91066-112">Head-gaze and commit</span></span></td>
        <td><span data-ttu-id="91066-113">✔️ Empfohlen</span><span class="sxs-lookup"><span data-stu-id="91066-113">✔️ Recommended</span></span></td>
        <td><span data-ttu-id="91066-114">✔️ Empfohlen (dritte Auswahl – <a href="interaction-fundamentals.md">Siehe andere Optionen</a>)</span><span class="sxs-lookup"><span data-stu-id="91066-114">✔️ Recommended (third choice - <a href="interaction-fundamentals.md">See the other options</a>)</span></span></td>
        <td><span data-ttu-id="91066-115">➕ Alternative Option</span><span class="sxs-lookup"><span data-stu-id="91066-115">➕ Alternate option</span></span></td>
    </tr>
</table>

## <a name="head-gaze"></a><span data-ttu-id="91066-116">Anvisieren mit dem Kopf</span><span class="sxs-lookup"><span data-stu-id="91066-116">Head-gaze</span></span>
<span data-ttu-id="91066-117">Mixed Reality-Headsets nutzen Position und Ausrichtung des Kopfes des Benutzers, um dessen Kopfrichtungsvektor zu bestimmen.</span><span class="sxs-lookup"><span data-stu-id="91066-117">Mixed reality headsets use the position and orientation of the user's head to determine their head direction vector.</span></span> <span data-ttu-id="91066-118">Sie können sich dies als einen Laser vorstellen, der direkt zwischen den Augen des Benutzers geradeaus zeigt.</span><span class="sxs-lookup"><span data-stu-id="91066-118">You can think of this as a laser that points straight ahead from directly between the user's eyes.</span></span> <span data-ttu-id="91066-119">Dies ist eine ziemlich grobe Annäherung hinsichtlich der Position, die der Benutzer betrachtet.</span><span class="sxs-lookup"><span data-stu-id="91066-119">This is a fairly coarse approximation of where the user is looking.</span></span> <span data-ttu-id="91066-120">Die Anwendung kann diesen Strahl mit virtuellen oder echten Objekten überschneiden und einen Cursor an dieser Stelle zeichnen, um dem Benutzer mitzuteilen, was er derzeit als Ziel verwendet.</span><span class="sxs-lookup"><span data-stu-id="91066-120">Your application can intersect this ray with virtual or real-world objects, and draw a cursor at that location to let the user know what they are currently targeting.</span></span>

<span data-ttu-id="91066-121">Zusätzlich zu den Köpfen können einige gemischte Reality-Headsets, wie hololens 2, Eye Tracking-Systeme einschließen, die einen Blick Vektor liefern.</span><span class="sxs-lookup"><span data-stu-id="91066-121">In addition to head gaze, some mixed reality headsets, like HoloLens 2, include eye tracking systems that produce an eye-gaze vector.</span></span> <span data-ttu-id="91066-122">Dies ermöglicht eine präzisere Messung der Position, die der Benutzer betrachtet.</span><span class="sxs-lookup"><span data-stu-id="91066-122">This provides a fine-grained measurement of where the user is looking.</span></span> <span data-ttu-id="91066-123">Es ist möglich, die Interaktion mit Blick und Commit mithilfe des Augenblicks zu erstellen.</span><span class="sxs-lookup"><span data-stu-id="91066-123">It is possible to build gaze and commit interactions using eye gaze.</span></span> <span data-ttu-id="91066-124">Dies ist jedoch mit einem ganz anderen Satz von Entwurfs Einschränkungen zu tun, die separat im [Augenblick Artikel](eye-tracking.md)behandelt werden.</span><span class="sxs-lookup"><span data-stu-id="91066-124">But this comes with a very different set of design constraints, which will be covered separately in the [eye-gaze article](eye-tracking.md).</span></span>

## <a name="commit"></a><span data-ttu-id="91066-125">Ausführen</span><span class="sxs-lookup"><span data-stu-id="91066-125">Commit</span></span>
<span data-ttu-id="91066-126">Nachdem ein Objekt oder ein UI-Element als Ziel verwendet wurde, kann der Benutzer mit einer sekundären Eingabe interagieren oder darauf klicken.</span><span class="sxs-lookup"><span data-stu-id="91066-126">After targeting an object or UI element, the user can interact or click on it using a secondary input.</span></span> <span data-ttu-id="91066-127">Dies wird als „Ausführen“-Schritt des Modells bezeichnet.</span><span class="sxs-lookup"><span data-stu-id="91066-127">This is known as the commit step of the model.</span></span> <span data-ttu-id="91066-128">Die folgenden Methoden zum Ausführen werden unterstützt:</span><span class="sxs-lookup"><span data-stu-id="91066-128">The following commit methods are supported:</span></span>

- <span data-ttu-id="91066-129">Luft tippen Bewegung</span><span class="sxs-lookup"><span data-stu-id="91066-129">Air tap gesture</span></span>
- <span data-ttu-id="91066-130">Sprechen Sie den Voice-Befehl, wählen Sie oder einen der Ziel Sprachbefehle aus.</span><span class="sxs-lookup"><span data-stu-id="91066-130">Speak the voice command, Select, or one of the targeted voice commands</span></span>
- <span data-ttu-id="91066-131">Eine einzelne Schaltfläche auf einem [hololens-Clicker](hardware-accessories.md#hololens-clicker) drücken</span><span class="sxs-lookup"><span data-stu-id="91066-131">Press a single button on a [HoloLens Clicker](hardware-accessories.md#hololens-clicker)</span></span>
- <span data-ttu-id="91066-132">Schaltfläche "A" auf einem Xbox Gamepad drücken</span><span class="sxs-lookup"><span data-stu-id="91066-132">Press the 'A' button on an Xbox gamepad</span></span>
- <span data-ttu-id="91066-133">Schaltfläche "A" auf einem adaptiven Xbox-Controller drücken</span><span class="sxs-lookup"><span data-stu-id="91066-133">Press the 'A' button on an Xbox adaptive controller</span></span>

### <a name="head-gaze-and-air-tap-gesture"></a><span data-ttu-id="91066-134">Anvisieren mit dem Kopf und Tippbewegung in die Luft</span><span class="sxs-lookup"><span data-stu-id="91066-134">Head-gaze and air tap gesture</span></span>
<span data-ttu-id="91066-135">„In die Luft tippen“ ist eine Tippbewegung mit aufrecht gehaltener Hand</span><span class="sxs-lookup"><span data-stu-id="91066-135">Air tap is a tapping gesture with the hand held upright.</span></span> <span data-ttu-id="91066-136">Um eine Luft Abzweigung auszuführen, erhöhen Sie den Finger des Indexes an die bereite Position, und drücken Sie dann mit dem Ziehpunkt.</span><span class="sxs-lookup"><span data-stu-id="91066-136">To perform an air tap, raise your index finger to the ready position, then pinch with your thumb, and raise your index finger back up to release.</span></span> <span data-ttu-id="91066-137">Bei hololens (1. Generation) ist Air Tap die häufigste sekundäre Eingabe.</span><span class="sxs-lookup"><span data-stu-id="91066-137">On HoloLens (1st Gen), air tap is the most common secondary input.</span></span>

![Finger in der Bereitschaftsposition und dann eine Tipp- oder Klickbewegung](images/readyandpress.jpg)<br>

<span data-ttu-id="91066-139">Air Tap ist auch auf hololens 2 verfügbar.</span><span class="sxs-lookup"><span data-stu-id="91066-139">Air tap is also available on HoloLens 2.</span></span> <span data-ttu-id="91066-140">Es wurde von der ursprünglichen Version gelockert.</span><span class="sxs-lookup"><span data-stu-id="91066-140">It has been relaxed from the original version.</span></span> <span data-ttu-id="91066-141">Fast alle Arten von Pinches werden jetzt unterstützt, solange die Hand gleich ist und weiterhin ist.</span><span class="sxs-lookup"><span data-stu-id="91066-141">Nearly all types of pinches are now supported as long as the hand is upright and holding still.</span></span> <span data-ttu-id="91066-142">Dadurch kann der Benutzer die Geste viel einfacher erlernen und ausführen.</span><span class="sxs-lookup"><span data-stu-id="91066-142">This makes it much easier for users to learn and perform the gesture.</span></span> <span data-ttu-id="91066-143">Diese neue Luftlinie ersetzt die alte durch dieselbe API, sodass vorhandene Anwendungen das neue Verhalten automatisch nach der Neukompilierung für hololens 2 aufweisen.</span><span class="sxs-lookup"><span data-stu-id="91066-143">This new air tap replaces the old one through the same API, so existing applications will have the new behavior automatically after recompiling for HoloLens 2.</span></span>

### <a name="head-gaze-and-select-voice-command"></a><span data-ttu-id="91066-144">Anvisieren mit dem Kopf und Sprachbefehl „Auswählen“</span><span class="sxs-lookup"><span data-stu-id="91066-144">Head-gaze and "Select" voice command</span></span>
<span data-ttu-id="91066-145">Voice-Befehle sind eine der primären Interaktions Methoden in gemischter Realität.</span><span class="sxs-lookup"><span data-stu-id="91066-145">Voice commanding is one of the primary interaction methods in mixed reality.</span></span> <span data-ttu-id="91066-146">Es bietet einen sehr leistungsfähigen, kostenlosen Mechanismus zur Steuerung des Systems.</span><span class="sxs-lookup"><span data-stu-id="91066-146">It provides a very powerful hands-free mechanism to control the system.</span></span> <span data-ttu-id="91066-147">Es gibt verschiedene Arten von Modellen für die Sprachinteraktion:</span><span class="sxs-lookup"><span data-stu-id="91066-147">There are diferent types of voice interaction models:</span></span>

- <span data-ttu-id="91066-148">Der generische Befehl SELECT, der eine Klick-oder einen Commit als sekundäre Eingabe ausführt.</span><span class="sxs-lookup"><span data-stu-id="91066-148">The generic command Select that performs a click actuation or commit as a secondary input.</span></span>
- <span data-ttu-id="91066-149">Objekt Befehle wie "Close" oder eine größere Leistung und Commit für eine Aktion als sekundäre Eingabe.</span><span class="sxs-lookup"><span data-stu-id="91066-149">Object commands like Close or Make it bigger performs and commits to an action as a secondary input.</span></span>
- <span data-ttu-id="91066-150">Für globale Kommas wie "Gehe zu Start" ist kein Ziel erforderlich.</span><span class="sxs-lookup"><span data-stu-id="91066-150">Global commnads like Go to start don't require a target.</span></span>
- <span data-ttu-id="91066-151">Benutzeroberflächen für die Konversation oder Entitäten wie Cortana verfügen über eine künstliche Ki-Sprache.</span><span class="sxs-lookup"><span data-stu-id="91066-151">Conversation user interfaces or entities like Cortana have an AI natural language capability.</span></span>
- <span data-ttu-id="91066-152">Benutzerdefinierte Befehle</span><span class="sxs-lookup"><span data-stu-id="91066-152">Custom commnads</span></span>

<span data-ttu-id="91066-153">Weitere Informationen sowie eine comprenhesive Liste der verfügbaren Befehle und deren Verwendung finden Sie in unserem Leitfaden für die [sprach](voice-design.md) Befehlsführung.</span><span class="sxs-lookup"><span data-stu-id="91066-153">To find more details as well as a comprenhesive list of available commands and how to use them, check out our [voice commanding](voice-design.md) guidance.</span></span>


### <a name="head-gaze-and-hololens-clicker"></a><span data-ttu-id="91066-154">Anvisieren mit dem Kopf und HoloLens-Klick-Gerät</span><span class="sxs-lookup"><span data-stu-id="91066-154">Head-gaze and HoloLens Clicker</span></span>
<span data-ttu-id="91066-155">Der hololens-Clicker ist das erste Peripheriegerät, das speziell für hololens erstellt wurde.</span><span class="sxs-lookup"><span data-stu-id="91066-155">The HoloLens Clicker is the first peripheral device built specifically for HoloLens.</span></span> <span data-ttu-id="91066-156">Es ist in der Entwicklungs Edition hololens (1st Gen) enthalten.</span><span class="sxs-lookup"><span data-stu-id="91066-156">It is included with HoloLens (1st Gen) Development Edition.</span></span> <span data-ttu-id="91066-157">Der hololens-Clicker ermöglicht dem Benutzer das Klicken mit minimaler Handbewegung und das Commit als sekundäre Eingabe.</span><span class="sxs-lookup"><span data-stu-id="91066-157">The HoloLens Clicker lets a user click with minimal hand motion, and commit as a secondary input.</span></span> <span data-ttu-id="91066-158">Der hololens-Clicker stellt mithilfe von Bluetooth Low Energy (btle) eine Verbindung mit hololens (1 St Gen) oder hololens 2 her.</span><span class="sxs-lookup"><span data-stu-id="91066-158">The HoloLens Clicker connects to HoloLens (1st Gen) or HoloLens 2 using Bluetooth Low Energy (BTLE).</span></span>

<span data-ttu-id="91066-159">![HoloLens-Klick-Gerät](images/hololens-clicker-500px.jpg)</span><span class="sxs-lookup"><span data-stu-id="91066-159">![HoloLens Clicker](images/hololens-clicker-500px.jpg)</span></span><br>
<span data-ttu-id="91066-160">*HoloLens-Klick-Gerät*</span><span class="sxs-lookup"><span data-stu-id="91066-160">*HoloLens Clicker*</span></span>

<span data-ttu-id="91066-161">Weitere Informationen und Anweisungen zum Koppeln des Geräts finden Sie [hier](hardware-accessories.md#pairing-bluetooth-accessories).</span><span class="sxs-lookup"><span data-stu-id="91066-161">More information and instructions to pair the device can be found [here](hardware-accessories.md#pairing-bluetooth-accessories)</span></span>




### <a name="head-gaze-and-xbox-wireless-controller"></a><span data-ttu-id="91066-162">Anvisieren mit dem Kopf und Xbox Wireless Controller</span><span class="sxs-lookup"><span data-stu-id="91066-162">Head-gaze and Xbox Wireless Controller</span></span>
<span data-ttu-id="91066-163">Der Xbox Wireless-Controller führt mit der Schaltfläche "a" eine Klick-und eine sekundäre Eingabe durch.</span><span class="sxs-lookup"><span data-stu-id="91066-163">The Xbox Wireless Controller performs a click actuation as a secondary input by using the 'A' button.</span></span> <span data-ttu-id="91066-164">Das Gerät ist einem Standardsatz von Aktionen zugeordnet, die bei der Navigation und Steuerung des Systems helfen.</span><span class="sxs-lookup"><span data-stu-id="91066-164">The device is mapped to a default set of actions that help navigate and controll the system.</span></span> <span data-ttu-id="91066-165">Wenn Sie den Controller anpassen möchten, verwenden Sie die Xbox accesories-Anwendung, um Ihren Xbox Wireless-Controller zu konfigurieren.</span><span class="sxs-lookup"><span data-stu-id="91066-165">If you want to customize the controller, use the Xbox Accesories application to configure your Xbox Wireless Controller.</span></span>

<span data-ttu-id="91066-166">![Xbox Wireless Controller](images/xboxcontroller.jpg)</span><span class="sxs-lookup"><span data-stu-id="91066-166">![Xbox Wireless Controller](images/xboxcontroller.jpg)</span></span><br>
<span data-ttu-id="91066-167">*Xbox Wireless Controller*</span><span class="sxs-lookup"><span data-stu-id="91066-167">*Xbox Wireless Controller*</span></span>

[<span data-ttu-id="91066-168">Koppeln eines Xbox-Controllers mit Ihrem PC</span><span class="sxs-lookup"><span data-stu-id="91066-168">Pairing an Xbox controller with your PC</span></span>](hardware-accessories.md#pairing-bluetooth-accessories)


### <a name="head-gaze-and-xbox-adaptive-controller"></a><span data-ttu-id="91066-169">Anvisieren mit dem Kopf und Xbox Adaptive Controller</span><span class="sxs-lookup"><span data-stu-id="91066-169">Head-gaze and Xbox Adaptive Controller</span></span>
<span data-ttu-id="91066-170">Der Xbox Adaptive Controller ist in erster Linie für die Bedürfnisse von Spielern mit eingeschränkter Mobilität konzipiert und stellt einen einheitlichen Hub für Geräte dar, mit denen gemischte Realität leichter zugänglich gemacht werden kann.</span><span class="sxs-lookup"><span data-stu-id="91066-170">Designed primarily to meet the needs of gamers with limited mobility, the Xbox Adaptive Controller is a unified hub for devices that helps make mixed reality more accessible.</span></span>

<span data-ttu-id="91066-171">Der Xbox Adaptive Controller führt mit der Schaltfläche "a" eine Klick-und eine sekundäre Eingabe durch.</span><span class="sxs-lookup"><span data-stu-id="91066-171">The Xbox Adaptive Controller performs a click actuation as a secondary input by using the 'A' button.</span></span> <span data-ttu-id="91066-172">Das Gerät ist einem Standardsatz von Aktionen zugeordnet, die beim Navigieren und Steuern des Systems helfen.</span><span class="sxs-lookup"><span data-stu-id="91066-172">The device is mapped to a default set of actions that help navigate and control the system.</span></span> <span data-ttu-id="91066-173">Wenn Sie den Controller anpassen möchten, verwenden Sie die Xbox accesories-Anwendung, um Ihren Xbox Adaptive Controller zu konfigurieren.</span><span class="sxs-lookup"><span data-stu-id="91066-173">If you want to customize the controller, use the Xbox Accesories application to configure your Xbox Adaptive Controller.</span></span>

<span data-ttu-id="91066-174">![Xbox Adaptive Controller](images/xbox-adaptive-controller-devices.jpg)</span><span class="sxs-lookup"><span data-stu-id="91066-174">![Xbox Adaptive Controller](images/xbox-adaptive-controller-devices.jpg)</span></span><br>
<span data-ttu-id="91066-175">*Xbox Adaptive Controller*</span><span class="sxs-lookup"><span data-stu-id="91066-175">*Xbox Adaptive Controller*</span></span>

<span data-ttu-id="91066-176">Verbinden Sie externe Geräte, wie z. b. Switches, Schaltflächen, bereit Stellungen und Joystick, um eine benutzerdefinierte Controller-benutzerdefinierte Controller Darstellung zu erstellen.</span><span class="sxs-lookup"><span data-stu-id="91066-176">Connect external devices such as switches, buttons, mounts, and joysticks to create a custom controller experience that is uniquely yours.</span></span> <span data-ttu-id="91066-177">Schaltflächen-, fingerstick-und triggereingaben werden mit Hilfsgeräten gesteuert, die über 3.5 mm-und USB-Ports verbunden sind.</span><span class="sxs-lookup"><span data-stu-id="91066-177">Button, thumbstick, and trigger inputs are controlled with assistive devices connected through 3.5mm jacks and USB ports.</span></span>

<span data-ttu-id="91066-178">![Xbox Adaptive Controller-Anschlüsse](images/xbox-adaptive-controller-ports.jpg)</span><span class="sxs-lookup"><span data-stu-id="91066-178">![Xbox Adaptive Controller ports](images/xbox-adaptive-controller-ports.jpg)</span></span><br>
<span data-ttu-id="91066-179">*Xbox Adaptive Controller-Anschlüsse*</span><span class="sxs-lookup"><span data-stu-id="91066-179">*Xbox Adaptive Controller ports*</span></span>

[<span data-ttu-id="91066-180">Anweisungen zum Koppeln des Geräts</span><span class="sxs-lookup"><span data-stu-id="91066-180">Instructions to pair the device</span></span>](hardware-accessories.md#pairing-bluetooth-accessories)

<span data-ttu-id="91066-181"><a href=https://www.xbox.com/en-US/xbox-one/accessories/controllers/xbox-adaptive-controller>Weitere Informationen, die auf der Xbox-Website verfügbar sind</a></span><span class="sxs-lookup"><span data-stu-id="91066-181"><a href=https://www.xbox.com/en-US/xbox-one/accessories/controllers/xbox-adaptive-controller>More info available on the Xbox site</a></span></span>


## <a name="design-guidelines"></a><span data-ttu-id="91066-182">Entwurfsrichtlinien</span><span class="sxs-lookup"><span data-stu-id="91066-182">Design guidelines</span></span>
> [!NOTE]
> <span data-ttu-id="91066-183">Weitere Anleitungen zum Entwurf von „Anvisieren“ sind [bald verfügbar](index.md).</span><span class="sxs-lookup"><span data-stu-id="91066-183">More guidance specific to gaze design [coming soon](index.md).</span></span>

## <a name="head-gaze-targeting"></a><span data-ttu-id="91066-184">Anvisieren mit dem Kopf</span><span class="sxs-lookup"><span data-stu-id="91066-184">Head-gaze targeting</span></span>
<span data-ttu-id="91066-185">Alle Interaktionen basieren auf der Fähigkeit eines Benutzers, das Element, mit dem er interagieren möchte, unabhängig von der Eingabemethode auszuwählen.</span><span class="sxs-lookup"><span data-stu-id="91066-185">All interactions are built upon the ability of a user to target the element they want to interact with, regardless of the input modality.</span></span> <span data-ttu-id="91066-186">In Windows Mixed Reality erfolgt dies in der Regel durch das Anvisieren durch den Benutzer.</span><span class="sxs-lookup"><span data-stu-id="91066-186">In Windows Mixed Reality, this is generally done using the user's gaze.</span></span>
<span data-ttu-id="91066-187">Damit ein Benutzer erfolgreich mit einer Benutzer Arbeit arbeiten kann, muss das System das Verständnis der Absicht eines Benutzers und die tatsächliche Absicht des Benutzers so genau wie möglich ausrichten.</span><span class="sxs-lookup"><span data-stu-id="91066-187">To enable a user to work with an experience successfully, the system's calculated understanding of a user's intent and the user's actual intent must align as closely as possible.</span></span> <span data-ttu-id="91066-188">In dem Maße, in dem das System die beabsichtigten Aktionen des Benutzers richtig interpretiert, steigen Zufriedenheit und Leistung.</span><span class="sxs-lookup"><span data-stu-id="91066-188">To the degree that the system interprets the user's intended actions correctly, satisfaction increases and performance improves.</span></span>


## <a name="target-sizing-and-feedback"></a><span data-ttu-id="91066-189">Skalieren von Zielen und Feedback</span><span class="sxs-lookup"><span data-stu-id="91066-189">Target sizing and feedback</span></span>
<span data-ttu-id="91066-190">Der Gaze-Vektor wurde wiederholt angezeigt, um für die fein Ausrichtung geeignet zu sein. er eignet sich jedoch oft am besten für das anvisieren von Brutto-Zielen.</span><span class="sxs-lookup"><span data-stu-id="91066-190">The gaze vector has been shown repeatedly to be usable for fine targeting, but often works best for gross targeting--acquiring somewhat larger targets.</span></span> <span data-ttu-id="91066-191">Die minimalen Zielgrößen von 1 bis 1,5 Grad ermöglichen in den meisten Szenarien erfolgreiche Benutzeraktionen, wobei Ziele von 3 Grad jedoch häufig eine höhere Geschwindigkeit ermöglichen.</span><span class="sxs-lookup"><span data-stu-id="91066-191">Minimum target sizes of 1 to 1.5 degrees allows successful user actions in most scenarios, though targets of 3 degrees often allow for greater speed.</span></span> <span data-ttu-id="91066-192">Beachten Sie, dass die Größe, auf die der Benutzer ausgerichtet ist, auch für 3D-Elemente effektiv ein 2D-Bereich ist. Die ihm jeweils zugewandte Projektion sollte der Zielbereich sein.</span><span class="sxs-lookup"><span data-stu-id="91066-192">Note that the size that the user targets is effectively a 2D area even for 3D elements--whichever projection is facing them should be the targetable area.</span></span> <span data-ttu-id="91066-193">Ein Hinweis darauf, dass ein Element "aktiv" ist (der der Benutzer als Ziel verwendet), ist äußerst hilfreich.</span><span class="sxs-lookup"><span data-stu-id="91066-193">Providing some salient cue that an element is "active" (that the user is targeting it) is extremely helpful.</span></span> <span data-ttu-id="91066-194">Dies kann z. b. z. b. sichtbare "Hover"-Effekte, audiohighlights oder Klicks oder eine klare Ausrichtung eines Cursors mit einem Element umfassen.</span><span class="sxs-lookup"><span data-stu-id="91066-194">This can include treatments like visible "hover" effects, audio highlights or clicks, or clear alignment of a cursor with an element.</span></span>

<span data-ttu-id="91066-195">![Optimale Zielgröße im Abstand von 2 Metern](images/gazetargeting-size-1000px.jpg)</span><span class="sxs-lookup"><span data-stu-id="91066-195">![Optimal target size at 2 meter distance](images/gazetargeting-size-1000px.jpg)</span></span><br>
<span data-ttu-id="91066-196">*Optimale Zielgröße im Abstand von 2 Metern*</span><span class="sxs-lookup"><span data-stu-id="91066-196">*Optimal target size at 2 meter distance*</span></span>

<span data-ttu-id="91066-197">![Beispiel für die Hervorhebung eines anvisierten Objekts](images/gazetargeting-highlighting-640px.jpg)</span><span class="sxs-lookup"><span data-stu-id="91066-197">![An example of highlighting a gaze targeted object](images/gazetargeting-highlighting-640px.jpg)</span></span><br>
<span data-ttu-id="91066-198">*Beispiel für die Hervorhebung eines anvisierten Objekts*</span><span class="sxs-lookup"><span data-stu-id="91066-198">*An example of highlighting a gaze targeted object*</span></span>

## <a name="target-placement"></a><span data-ttu-id="91066-199">Zielpositionierung</span><span class="sxs-lookup"><span data-stu-id="91066-199">Target placement</span></span>
<span data-ttu-id="91066-200">Benutzer können häufig keine UI-Elemente finden, die in ihrer Ansicht sehr hoch oder sehr niedrig angeordnet sind. Sie konzentrieren sich auf Bereiche, die sich in der Nähe des Hauptfokus befinden, also ungefähr in der Perspektive.</span><span class="sxs-lookup"><span data-stu-id="91066-200">Users often fail to find UI elements that are positioned very high or very low in their field of view, focusing most of their attention on areas around their main focus, which is approximately at eye level.</span></span> <span data-ttu-id="91066-201">Die Positionierung der meisten Ziele in einem vernünftigen Bereich auf Augenhöhe kann helfen.</span><span class="sxs-lookup"><span data-stu-id="91066-201">Placing most targets in some reasonable band around eye level can help.</span></span> <span data-ttu-id="91066-202">Angesichts der Tendenz, dass sich der Benutzer jeweils auf einen relativ kleinen visuellen Bereich konzentrieren kann (der Blickwinkel beträgt etwa 10 Grad), kann die Gruppierung von Benutzeroberflächenelementen in dem Maße, in dem sie konzeptionell verwandt sind, das Verhalten zum Kombinieren der Aufmerksamkeit von Element zu Element nutzen, wenn der Blick eines Benutzers durch einen Bereich schweift.</span><span class="sxs-lookup"><span data-stu-id="91066-202">Given the tendency for users to focus on a relatively small visual area at any time (the attentional cone of vision is roughly 10 degrees), grouping UI elements together to the degree that they're related conceptually can leverage attention-chaining behaviors from item to item as a user moves their gaze through an area.</span></span> <span data-ttu-id="91066-203">Beachten Sie beim Entwerfen der Benutzeroberfläche die potenziellen großen Unterschiede beim Sichtfeld zwischen HoloLens und immersiven Headsets.</span><span class="sxs-lookup"><span data-stu-id="91066-203">When designing UI, keep in mind the potential large variation in field of view between HoloLens and immersive headsets.</span></span>

<span data-ttu-id="91066-204">![Beispiel für gruppierte Benutzeroberflächenelemente zur einfacheren Zielbestimmung in Galaxy Explorer](images/gazetargeting-grouping-1000px.jpg).</span><span class="sxs-lookup"><span data-stu-id="91066-204">![An example of grouped UI elements for easier gaze targeting in Galaxy Explorer](images/gazetargeting-grouping-1000px.jpg)</span></span><br>
<span data-ttu-id="91066-205">*Beispiel für gruppierte Benutzeroberflächenelemente zur einfacheren Zielbestimmung in Galaxy Explorer*.</span><span class="sxs-lookup"><span data-stu-id="91066-205">*An example of grouped UI elements for easier gaze targeting in Galaxy Explorer*</span></span>

## <a name="improving-targeting-behaviors"></a><span data-ttu-id="91066-206">Verbessern des Verhaltens bei der Zielbestimmung</span><span class="sxs-lookup"><span data-stu-id="91066-206">Improving targeting behaviors</span></span>
<span data-ttu-id="91066-207">Wenn der Benutzer beabsichtigt ist, etwas als Ziel festzustellen, kann es sehr hilfreich sein, fast Fehlversuche bei der Interaktion zu akzeptieren, als wären Sie ordnungsgemäß als Ziel festgelegt.</span><span class="sxs-lookup"><span data-stu-id="91066-207">If user intent to target something can be determined (or approximated closely), it can be very helpful to accept near miss attempts at interaction as though they were targeted correctly.</span></span> <span data-ttu-id="91066-208">Im folgenden finden Sie eine Reihe von erfolgreichen Methoden, die in gemischte Realität integriert werden können:</span><span class="sxs-lookup"><span data-stu-id="91066-208">Here are a handful of successful methods that can be incorporated in mixed reality experiences:</span></span>

### <a name="head-gaze-stabilization-gravity-wells"></a><span data-ttu-id="91066-209">Stabilisierung beim Anvisieren mit dem Kopf („Gravitationsbrunnen“)</span><span class="sxs-lookup"><span data-stu-id="91066-209">Head-gaze stabilization ("gravity wells")</span></span>
<span data-ttu-id="91066-210">Dies sollte in den meisten Fällen oder in der Zeit aktiviert werden.</span><span class="sxs-lookup"><span data-stu-id="91066-210">This should be turned on most or all of the time.</span></span> <span data-ttu-id="91066-211">Diese Methode entfernt die natürlichen Kopf-und Hals Jitter, die Benutzer möglicherweise durch das Aussehen und Sprech Verhalten durchsuchen.</span><span class="sxs-lookup"><span data-stu-id="91066-211">This technique removes the natural head and neck jitters that users might have as well movement due to looking and speaking behaviors.</span></span>

### <a name="closest-link-algorithms"></a><span data-ttu-id="91066-212">Algorithmen für die engste Verbindung</span><span class="sxs-lookup"><span data-stu-id="91066-212">Closest link algorithms</span></span>
<span data-ttu-id="91066-213">Diese funktionieren am besten in Bereichen mit wenig interaktiven Inhalten.</span><span class="sxs-lookup"><span data-stu-id="91066-213">These work best in areas with sparse interactive content.</span></span> <span data-ttu-id="91066-214">Wenn eine hohe Wahrscheinlichkeit besteht, dass Sie bestimmen können, mit welchem Benutzer versucht wurde, zu interagieren, können Sie die Zielfunktionen ergänzen, indem Sie eine gewisse Absicht annehmen.</span><span class="sxs-lookup"><span data-stu-id="91066-214">If there is a high probability that you can determine what a user was attempting to interact with, you can supplement their targeting abilities by assuming some level of intent.</span></span>

### <a name="backdating-and-postdating-actions"></a><span data-ttu-id="91066-215">Sicherungs-und postdating-Aktionen</span><span class="sxs-lookup"><span data-stu-id="91066-215">Backdating and postdating actions</span></span>
<span data-ttu-id="91066-216">Dieser Mechanismus ist hilfreich bei Aufgaben, die Geschwindigkeit erfordern.</span><span class="sxs-lookup"><span data-stu-id="91066-216">This mechanism is useful in tasks requiring speed.</span></span> <span data-ttu-id="91066-217">Wenn ein Benutzer mit der Geschwindigkeit eine Reihe von Ziel-und Aktivierungs Manövern durchläuft, ist es sinnvoll, eine Absicht anzunehmen und versäumte Schritte zuzulassen, um auf Ziele zu reagieren, auf die sich der Benutzer vor oder nach dem tippen etwas bewegt hat (50 ms vor/nach war in EA wirksam). RLY-Tests).</span><span class="sxs-lookup"><span data-stu-id="91066-217">When a user is moving through a series of targeting and activation maneuvers at speed, it is useful to assume some intent, and allow missed steps to act upon targets that the user had in focus slightly before or slightly after the tap (50 ms before/after was effective in early testing).</span></span>

### <a name="smoothing"></a><span data-ttu-id="91066-218">Glättung</span><span class="sxs-lookup"><span data-stu-id="91066-218">Smoothing</span></span>
<span data-ttu-id="91066-219">Dieser Mechanismus eignet sich für die Bewegung von bewegungsbewegungen, wodurch das leichte Jitter und das Wackeln aufgrund natürlicher Kopf Verschiebungs Merkmale reduziert werden.</span><span class="sxs-lookup"><span data-stu-id="91066-219">This mechanism is useful for pathing movements, reducing the slight jitter and wobble due to natural head movement characteristics.</span></span> <span data-ttu-id="91066-220">Bei der Glättung von bewegungsbewegungen durch die Größe und die Entfernung von Bewegungen und nicht über die Zeit.</span><span class="sxs-lookup"><span data-stu-id="91066-220">When smoothing over pathing motions, smooth by the size and distance of movements rather than over time.</span></span>

### <a name="magnetism"></a><span data-ttu-id="91066-221">Magnetismus</span><span class="sxs-lookup"><span data-stu-id="91066-221">Magnetism</span></span>
<span data-ttu-id="91066-222">Dieser Mechanismus kann sich als allgemeinere Version der nächstgelegenen Verknüpfungs Algorithmen vorstellen: das Zeichnen eines Cursors in Richtung eines Ziels oder das einfache erhöhen der Treffer Felder, egal ob sichtbar oder nicht, wenn Benutzer wahrscheinliche Ziele erreichen, indem Sie einige Kenntnisse des interaktiven Layouts verwenden, um eine bessere Herangehensweise an die Benutzer Absicht.</span><span class="sxs-lookup"><span data-stu-id="91066-222">This mechanism can be thought of as a more general version of closest link algorithms--drawing a cursor toward a target or simply increasing hitboxes, whether visibly or not, as users approach likely targets by using some knowledge of the interactive layout to better approach user intent.</span></span> <span data-ttu-id="91066-223">Dies kann insbesondere bei kleinen Zielen sehr wirkungsvoll sein.</span><span class="sxs-lookup"><span data-stu-id="91066-223">This can be particularly powerful for small targets.</span></span>

### <a name="focus-stickiness"></a><span data-ttu-id="91066-224">Fokusbindung</span><span class="sxs-lookup"><span data-stu-id="91066-224">Focus stickiness</span></span>
<span data-ttu-id="91066-225">Wenn Sie bestimmen, auf welche nahe gelegenen interaktiven Elemente der Fokus gelegt werden soll, stellt die Fokus Bindung eine Abweichung für das Element bereit, das momentan fokussiert ist.</span><span class="sxs-lookup"><span data-stu-id="91066-225">When determining which nearby interactive elements to give focus to, focus stickiness provides a bias to the element that is currently focused.</span></span> <span data-ttu-id="91066-226">Dies trägt dazu bei, das Verhalten von erratischen Fokuswechsel Verhalten zu verringern, wenn Sie in einem Mittelpunkt zwischen zwei Elementen mit natürlichem Rauschen schweben</span><span class="sxs-lookup"><span data-stu-id="91066-226">This helps reduce erratic focus switching behaviours when floating at a midpoint between two elements with natural noise.</span></span>


## <a name="composite-gestures"></a><span data-ttu-id="91066-227">Zusammengesetzte Gesten</span><span class="sxs-lookup"><span data-stu-id="91066-227">Composite gestures</span></span>

### <a name="air-tap"></a><span data-ttu-id="91066-228">In die Luft tippen</span><span class="sxs-lookup"><span data-stu-id="91066-228">Air tap</span></span>
<span data-ttu-id="91066-229">Die Tap-Bewegung (und die anderen Gesten unten) reagiert nur auf eine bestimmte Abzweigung.</span><span class="sxs-lookup"><span data-stu-id="91066-229">The air tap gesture (as well as the other gestures below) reacts only to a specific tap.</span></span> <span data-ttu-id="91066-230">Um andere Abzweigungen zu erkennen, wie z. b. Menu oder grasp, muss Ihre Anwendung direkt die Interaktionen auf niedrigerer Ebene verwenden, die im obigen Abschnitt mit zwei wichtigen Komponenten Gesten beschrieben werden.</span><span class="sxs-lookup"><span data-stu-id="91066-230">To detect other taps, such as Menu or Grasp, your application must directly use the lower-level interactions described in the two key component gestures section above.</span></span>

### <a name="tap-and-hold"></a><span data-ttu-id="91066-231">Tippen und halten Sie</span><span class="sxs-lookup"><span data-stu-id="91066-231">Tap and hold</span></span>
<span data-ttu-id="91066-232">„Halten“ bedeutet einfach, die Position mit dem Finger nach unten beim „In die Luft tippen“ beizubehalten.</span><span class="sxs-lookup"><span data-stu-id="91066-232">Hold is simply maintaining the downward finger position of the air tap.</span></span> <span data-ttu-id="91066-233">Die Kombination aus Luft tippen und halten ermöglicht eine Vielzahl komplexer "klicken und ziehen"-Interaktionen, wenn Sie mit Arm-Bewegung kombiniert werden, wie z. b. das Auswählen eines Objekts, anstatt es zu aktivieren oder um sekundäre Interaktionen wie das zeigen eines Kontextmenüs zu aktivieren.</span><span class="sxs-lookup"><span data-stu-id="91066-233">The combination of air tap and hold allows for a variety of more complex "click and drag" interactions when combined with arm movement such as picking up an object instead of activating it or mousedown secondary interactions such as showing a context menu.</span></span>
<span data-ttu-id="91066-234">Bei der Gestaltung dieser Geste sollte jedoch mit Bedacht vorgegangen werden, da die Benutzer dazu neigen können, ihre Handhaltungen im Laufe einer längeren Geste zu entspannen.</span><span class="sxs-lookup"><span data-stu-id="91066-234">Caution should be used when designing for this gesture however, as users can be prone to relaxing their hand postures during the course of any extended gesture.</span></span>

### <a name="manipulation"></a><span data-ttu-id="91066-235">Manipulation</span><span class="sxs-lookup"><span data-stu-id="91066-235">Manipulation</span></span>
<span data-ttu-id="91066-236">Manipulations Gesten können zum Verschieben, Ändern der Größe oder Drehen eines holograms verwendet werden, wenn das – Hologramm 1:1 auf die Handbewegungen des Benutzers reagieren soll.</span><span class="sxs-lookup"><span data-stu-id="91066-236">Manipulation gestures can be used to move, resize, or rotate a hologram when you want the hologram to react 1:1 to the user's hand movements.</span></span> <span data-ttu-id="91066-237">Eine Verwendungsmöglichkeit für solche 1:1-Bewegungen ist es, den Benutzer in der Umgebung zeichnen oder malen zu lassen.</span><span class="sxs-lookup"><span data-stu-id="91066-237">One use for such 1:1 movements is to let the user draw or paint in the world.</span></span>
<span data-ttu-id="91066-238">Die anfängliche Zielbestimmung für eine Manipulationsgeste sollte durch Anvisieren oder Zeigen erfolgen.</span><span class="sxs-lookup"><span data-stu-id="91066-238">The initial targeting for a manipulation gesture should be done by gaze or pointing.</span></span> <span data-ttu-id="91066-239">Wenn Tap und Hold gestartet werden, wird jede Bearbeitung des Objekts von Handbewegungen behandelt, sodass der Benutzer bei der Bearbeitung nicht mehr suchen kann.</span><span class="sxs-lookup"><span data-stu-id="91066-239">Once the tap and hold starts, any manipulation of the object is handled by hand movements, freeing the user to look around while they manipulate.</span></span>

### <a name="navigation"></a><span data-ttu-id="91066-240">Navigation</span><span class="sxs-lookup"><span data-stu-id="91066-240">Navigation</span></span>
<span data-ttu-id="91066-241">Navigationsgesten funktionieren wie ein virtueller Joystick und können zur Navigation in Widgets der Benutzeroberfläche, z. B. Radialmenüs, verwendet werden.</span><span class="sxs-lookup"><span data-stu-id="91066-241">Navigation gestures operate like a virtual joystick, and can be used to navigate UI widgets, such as radial menus.</span></span> <span data-ttu-id="91066-242">Sie tippen und halten, um die Geste zu starten, und bewegen dann Ihre Hand in einem normalisierten 3D-Würfel, der um die erste Betätigung herum angeordnet ist.</span><span class="sxs-lookup"><span data-stu-id="91066-242">You tap and hold to start the gesture and then move your hand within a normalized 3D cube, centered around the initial press.</span></span> <span data-ttu-id="91066-243">Sie können Ihre Hand entlang der X-, Y- oder Z-Achse zwischen einem Wert von -1 bis 1 bewegen, wobei 0 der Ausgangspunkt ist.</span><span class="sxs-lookup"><span data-stu-id="91066-243">You can move your hand along the X, Y or Z axis from a value of -1 to 1, with 0 being the starting point.</span></span>
<span data-ttu-id="91066-244">Mithilfe der Navigation können geschwindigkeitsbasierte kontinuierliche Gesten zum Scrollen oder Zoomen erstellt werden, ähnlich dem Scrollen bei einer 2D-Benutzeroberfläche durch Klicken mit der mittleren Maustaste und anschließendes Bewegen der Maus nach oben und unten.</span><span class="sxs-lookup"><span data-stu-id="91066-244">Navigation can be used to build velocity-based continuous scrolling or zooming gestures, similar to scrolling a 2D UI by clicking the middle mouse button and then moving the mouse up and down.</span></span>

<span data-ttu-id="91066-245">Navigation mit Rails bezieht sich auf die Fähigkeit, Bewegungen auf einer bestimmten Achse zu erkennen, bis ein bestimmter Schwellenwert auf dieser Achse erreicht wird.</span><span class="sxs-lookup"><span data-stu-id="91066-245">Navigation with rails refers to the ability of recognizing movements in certain axis until a certain threshold is reached on that axis.</span></span> <span data-ttu-id="91066-246">Dies ist nur nützlich, wenn die Bewegung in mehr als einer Achse durch den Entwickler in einer Anwendung aktiviert ist, z. b. Wenn eine Anwendung so konfiguriert ist, dass Navigations Gesten über die x-, Y-Achse, aber auch die x-Achse mit Rails erkannt werden.</span><span class="sxs-lookup"><span data-stu-id="91066-246">This is only useful when movement in more than one axis is enabled in an application by the developer, such as if an application is configured to recognize navigation gestures across X, Y axis but also specified X axis with rails.</span></span> <span data-ttu-id="91066-247">In diesem Fall erkennt das System Handbewegungen über die x-Achse, solange Sie auf der x-Achse innerhalb eines imaginären Rails (Handbuchs) bleiben, wenn die Handbewegung auch auf der Y-Achse auftritt.</span><span class="sxs-lookup"><span data-stu-id="91066-247">In this case the system will recognize hand movements across X axis as long as they remain within an imaginary rails (guide) on the X axis, if hand movement also occurs on the Y axis.</span></span>

<span data-ttu-id="91066-248">Innerhalb von 2D-Apps können Benutzer mit vertikalen Navigationsgesten innerhalb der App scrollen, zoomen oder ziehen.</span><span class="sxs-lookup"><span data-stu-id="91066-248">Within 2D apps, users can use vertical navigation gestures to scroll, zoom, or drag inside the app.</span></span> <span data-ttu-id="91066-249">Dadurch werden virtuelle Fingerberührungen in der App eingeführt, um Gesten für die Toucheingabe desselben Typs zu simulieren.</span><span class="sxs-lookup"><span data-stu-id="91066-249">This injects virtual finger touches to the app to simulate touch gestures of the same type.</span></span> <span data-ttu-id="91066-250">Benutzer können auswählen, welche dieser Aktionen durchgeführt werden, indem Sie zwischen den Tools auf der Leiste oberhalb der Anwendung wechseln, indem Sie entweder die Schaltfläche auswählen oder die Option "< Scrollmodus/Drag & Zoom > Tools" verwenden.</span><span class="sxs-lookup"><span data-stu-id="91066-250">Users can select which of these actions take place by toggling between the tools on the bar above the application, either by selecting the button or saying '<Scroll/Drag/Zoom> Tool'.</span></span>

[<span data-ttu-id="91066-251">Weitere Informationen zu zusammengesetzten Gesten</span><span class="sxs-lookup"><span data-stu-id="91066-251">More info on composite gestures</span></span>](gestures.md#composite-gestures)

## <a name="gesture-recognizers"></a><span data-ttu-id="91066-252">Gestenerkennung</span><span class="sxs-lookup"><span data-stu-id="91066-252">Gesture recognizers</span></span>

<span data-ttu-id="91066-253">Ein Vorteil bei der Verwendung der Gestenerkennung besteht darin, dass Sie eine Gestenerkennung nur für die Gesten konfigurieren können, die das derzeit zielgerichtete – Hologramm annehmen kann.</span><span class="sxs-lookup"><span data-stu-id="91066-253">One benefit of using gesture recognition is that you can configure a gesture recognizer only for the gestures the currently targeted hologram can accept.</span></span> <span data-ttu-id="91066-254">Die Plattform ist nur bei Bedarf eindeutig, um die unterstützten Gesten unterscheiden zu können.</span><span class="sxs-lookup"><span data-stu-id="91066-254">The platform only does disambiguation as necessary to distinguish those particular supported gestures.</span></span> <span data-ttu-id="91066-255">Auf diese Weise kann ein – Hologramm, das nur Air Tap unterstützt, jede Zeitspanne zwischen dem Drücken und dem Release akzeptieren, während ein – Hologramm, das sowohl Tap als auch Hold unterstützt, die Abzweigung nach dem Schwellenwert für die Aufbewahrungszeit auf einen Halt herauf Stufen kann.</span><span class="sxs-lookup"><span data-stu-id="91066-255">In this way, a hologram that just supports air tap can accept any length of time between press and release, while a hologram that supports both tap and hold can promote the tap to a hold after the hold time threshold.</span></span>

## <a name="hand-recognition"></a><span data-ttu-id="91066-256">Handerkennung</span><span class="sxs-lookup"><span data-stu-id="91066-256">Hand recognition</span></span>
<span data-ttu-id="91066-257">HoloLens erkennt Handgesten, indem die Position einer oder beider Hände, die für das Gerät sichtbar sind, verfolgt wird.</span><span class="sxs-lookup"><span data-stu-id="91066-257">HoloLens recognizes hand gestures by tracking the position of either or both hands that are visible to the device.</span></span> <span data-ttu-id="91066-258">HoloLens erkennt Hände, wenn sie sich entweder im Bereitschaftszustand (Handrücken mit nach oben gerichtetem Zeigefinger zu Ihnen gewandt) oder im gedrückten Zustand (Handrücken mit nach unten gerichtetem Zeigefinger zu Ihnen gewandt) befinden.</span><span class="sxs-lookup"><span data-stu-id="91066-258">HoloLens sees hands when they are in either the ready state (back of the hand facing you with index finger up) or the pressed state (back of the hand facing you with the index finger down).</span></span> <span data-ttu-id="91066-259">Wenn sich die Hände in anderen Posen befinden, ignorieren hololens themz.</span><span class="sxs-lookup"><span data-stu-id="91066-259">When hands are in other poses, HoloLens ignore themz.</span></span>
<span data-ttu-id="91066-260">Für jede Hand, die hololens erkennt, können Sie ohne Ausrichtung und gedrücktem Zustand auf seine Position zugreifen.</span><span class="sxs-lookup"><span data-stu-id="91066-260">For each hand that HoloLens detects, you can access its position without orientation and its pressed state.</span></span> <span data-ttu-id="91066-261">Wenn sich die Hand dem Rand des Gestenrahmens nähert, erhalten Sie auch einen Richtungsvektor, den Sie dem Benutzer zeigen können, damit er weiß, wie er seine Hand bewegen muss, um sie dorthin zurückzubringen, wo sie von HoloLens erkannt werden kann.</span><span class="sxs-lookup"><span data-stu-id="91066-261">As the hand nears the edge of the gesture frame, you're also provided with a direction vector, which you can show to the user so they know how to move their hand to get it back where HoloLens can see it.</span></span>

## <a name="gesture-frame"></a><span data-ttu-id="91066-262">Gestenrahmen</span><span class="sxs-lookup"><span data-stu-id="91066-262">Gesture frame</span></span>
<span data-ttu-id="91066-263">Für Gesten in hololens muss sich die Hand innerhalb eines Gesten Rahmens befinden, der sich in einem Bereich befindet, der von der Bewegung zur Gesten Messung von der Nase bis zur Taille und von der Schulter aus angezeigt werden kann.</span><span class="sxs-lookup"><span data-stu-id="91066-263">For gestures on HoloLens, the hand must be within a gesture frame, in a range that the gesture-sensing cameras can see appropriately,  from nose to waist and between the shoulders.</span></span> <span data-ttu-id="91066-264">Benutzer müssen in diesem Bereich geschult werden, um den Erfolg der Aktion und ihren eigenen Komfort zu erzielen.</span><span class="sxs-lookup"><span data-stu-id="91066-264">Users need to be trained on this area of recognition both for success of action and for their own comfort.</span></span> <span data-ttu-id="91066-265">Viele Benutzer werden anfänglich davon ausgehen, dass sich der Gesten Rahmen in der Ansicht über hololens befinden muss</span><span class="sxs-lookup"><span data-stu-id="91066-265">Many users will initially assume that the gesture frame must be within their view through HoloLens, and hold their arms up uncomfortably in order to interact.</span></span> <span data-ttu-id="91066-266">Wenn Sie das hololens-Clicker verwenden, ist es nicht erforderlich, dass sich die Hände innerhalb des Gesten Rahmens befinden.</span><span class="sxs-lookup"><span data-stu-id="91066-266">When using the HoloLens Clicker, it's not necessary for hands to be within the gesture frame.</span></span>

<span data-ttu-id="91066-267">Im Fall von fortlaufenden Gesten besteht das Risiko, dass Benutzer ihre Hände außerhalb des Gesten Rahmens bewegen, während Sie sich in der Mitte der Bewegung befinden, wenn Sie z. b. ein Holographic-Objekt verschieben und das gewünschte Ergebnis verlieren.</span><span class="sxs-lookup"><span data-stu-id="91066-267">In the case of continuous gestures in particular, there is some risk of users moving their hands outside of the gesture frame while in mid-gesture when moving a holographic object, for example, and losing their intended outcome.</span></span>

<span data-ttu-id="91066-268">Sie sollten die folgenden drei Aspekte berücksichtigen:</span><span class="sxs-lookup"><span data-stu-id="91066-268">There are three things that you should consider:</span></span>

- <span data-ttu-id="91066-269">Benutzer Bildung für das vorhanden sein und die ungefähren Grenzen des Gesten Rahmens.</span><span class="sxs-lookup"><span data-stu-id="91066-269">User education on the gesture frame's existence and approximate boundaries.</span></span> <span data-ttu-id="91066-270">Dies wird während der hololens-Einrichtung vermittelt.</span><span class="sxs-lookup"><span data-stu-id="91066-270">This is taught during HoloLens setup.</span></span>

- <span data-ttu-id="91066-271">Benachrichtigen von Benutzern, wenn ihre Gesten die Gesten Rahmen Begrenzungen innerhalb einer Anwendung nähern oder unterbrechen, bis zu dem Ausmaß, in dem eine verlorene Bewegung zu unerwünschten Ergebnissen führt.</span><span class="sxs-lookup"><span data-stu-id="91066-271">Notifying users when their gestures are nearing or breaking the gesture frame boundaries within an application to the degree that a lost gesture leads to undesired outcomes.</span></span> <span data-ttu-id="91066-272">Research hat die Hauptqualitäten eines solchen Benachrichtigungs Systems aufgezeigt.</span><span class="sxs-lookup"><span data-stu-id="91066-272">Research has shown the key qualities of such a notification system.</span></span> <span data-ttu-id="91066-273">Die hololens-Shell stellt ein gutes Beispiel für diese Art von Benachrichtigung dar: Visual, auf dem zentralen Cursor, der die Richtung angibt, in der der Begrenzungs Übergang stattfindet.</span><span class="sxs-lookup"><span data-stu-id="91066-273">The HoloLens shell provides a good example of this type of notification--visual, on the central cursor, indicating the direction in which boundary crossing is taking place.</span></span>

- <span data-ttu-id="91066-274">Die Folgen des Überschreitens der Begrenzungen des Gestenrahmens sollten minimiert werden.</span><span class="sxs-lookup"><span data-stu-id="91066-274">Consequences of breaking the gesture frame boundaries should be minimized.</span></span> <span data-ttu-id="91066-275">Im Allgemeinen bedeutet dies, dass das Ergebnis einer Geste an der Grenze angehalten und nicht umgekehrt werden soll.</span><span class="sxs-lookup"><span data-stu-id="91066-275">In general, this means that the outcome of a gesture should be stopped at the boundary, and not reversed.</span></span> <span data-ttu-id="91066-276">Wenn ein Benutzer beispielsweise ein Holographic-Objekt über einen Raum verschiebt, sollte die Bewegung angehalten werden, wenn der Gesten Rahmen verletzt wird und nicht an den Ausgangspunkt zurückgegeben wird.</span><span class="sxs-lookup"><span data-stu-id="91066-276">For example, if a user is moving some holographic object across a room, the movement should stop when the gesture frame is breached, and not returned to the starting point.</span></span> <span data-ttu-id="91066-277">Der Benutzer kann einige Frustrationen erkennen, aber die Grenzen vielleicht besser verstehen und nicht jedes Mal die vollständigen beabsichtigten Aktionen neu starten.</span><span class="sxs-lookup"><span data-stu-id="91066-277">The user might experience some frustration, but might more quickly understand the boundaries, and not have to restart their full intended actions each time.</span></span>


## <a name="see-also"></a><span data-ttu-id="91066-278">Siehe auch</span><span class="sxs-lookup"><span data-stu-id="91066-278">See also</span></span>
* [<span data-ttu-id="91066-279">Direkte Manipulation mit den Händen</span><span class="sxs-lookup"><span data-stu-id="91066-279">Direct manipulation with hands</span></span>](direct-manipulation.md)
* [<span data-ttu-id="91066-280">Zeigen und Ausführen mit den Händen</span><span class="sxs-lookup"><span data-stu-id="91066-280">Point and commit with hands</span></span>](point-and-commit.md)
* [<span data-ttu-id="91066-281">Instinktive Interaktionen</span><span class="sxs-lookup"><span data-stu-id="91066-281">Instinctual interactions</span></span>](interaction-fundamentals.md)
* [<span data-ttu-id="91066-282">Anvisieren mit dem Kopf und Verweilen</span><span class="sxs-lookup"><span data-stu-id="91066-282">Head-gaze and dwell</span></span>](gaze-and-dwell.md)
* [<span data-ttu-id="91066-283">Sprachbefehle</span><span class="sxs-lookup"><span data-stu-id="91066-283">Voice commanding</span></span>](voice-design.md)





