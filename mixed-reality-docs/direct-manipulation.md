---
title: Direkte Manipulation mit den Händen
description: Übersicht über das Eingabemodell „Direkte Manipulation“
author: caseymeekhof
ms.author: cmeekhof
ms.date: 04/02/2019
ms.topic: article
ms.localizationpriority: high
keywords: Mixed Reality, Anvisieren, Zielbestimmung, Interaktion, Entwurf, Hände nah beieinander, HoloLens
ms.openlocfilehash: 6e3512eab4070680c48ee8e95240a17e9925822f
ms.sourcegitcommit: f20beea6a539d04e1d1fc98116f7601137eebebe
ms.translationtype: HT
ms.contentlocale: de-DE
ms.lasthandoff: 06/05/2019
ms.locfileid: "66402390"
---
# <a name="direct-manipulation-with-hands"></a><span data-ttu-id="d7a9f-104">Direkte Manipulation mit den Händen</span><span class="sxs-lookup"><span data-stu-id="d7a9f-104">Direct manipulation with hands</span></span>
<span data-ttu-id="d7a9f-105">Die direkte Manipulation ist ein Eingabemodell, bei dem Hologramme direkt mit den Händen berührt werden.</span><span class="sxs-lookup"><span data-stu-id="d7a9f-105">Direct manipulation is an input model that involves touching holograms directly with your hands.</span></span> <span data-ttu-id="d7a9f-106">Das Ziel bei der direkten Manipulation ist, dass sich Objekte wie in der realen Welt verhalten.</span><span class="sxs-lookup"><span data-stu-id="d7a9f-106">The goal with direct manipulation is that objects behave just as they do in the real world.</span></span> <span data-ttu-id="d7a9f-107">Schaltflächen können einfach durch Drücken aktiviert werden, Objekte können durch Greifen aufgenommen werden und 2D-Inhalte verhalten sich wie ein virtueller Touchscreen.</span><span class="sxs-lookup"><span data-stu-id="d7a9f-107">Buttons can be activated simply by pressing them, objects can be picked up by grabbing them, and 2D content behaves like a virtual touchscreen.</span></span>  <span data-ttu-id="d7a9f-108">Aus diesem Grund ist die direkte Manipulation für den Benutzer leicht erlernbar und macht auch Spaß.</span><span class="sxs-lookup"><span data-stu-id="d7a9f-108">Because of this, direct manipulation is easy for users to learn, and it's fun too.</span></span>  <span data-ttu-id="d7a9f-109">Es gilt als „nahes“ Eingabemodell, d. h. es wird am besten für die Interaktion mit Inhalten verwendet, die innerhalb der Reichweite der Arme liegen.</span><span class="sxs-lookup"><span data-stu-id="d7a9f-109">It is considered a "near" input model, meaning it is best used for interacting with content that is within arms reach.</span></span>

<span data-ttu-id="d7a9f-110">Die direkte Manipulation ist angebotsbasiert, d. h. benutzerfreundlich.</span><span class="sxs-lookup"><span data-stu-id="d7a9f-110">Direct manipulation is affordance-based, meaning it's user friendly.</span></span> <span data-ttu-id="d7a9f-111">Es gibt keine symbolischen Gesten, die den Benutzern vermittelt werden müssen.</span><span class="sxs-lookup"><span data-stu-id="d7a9f-111">There are no symbolic gestures to teach users.</span></span> <span data-ttu-id="d7a9f-112">Alle Interaktionen basieren auf einem visuellen Element, das Sie berühren oder greifen können.</span><span class="sxs-lookup"><span data-stu-id="d7a9f-112">All interactions are built around a visual element that you can touch or grab.</span></span>

## <a name="device-support"></a><span data-ttu-id="d7a9f-113">Unterstützung von Geräten</span><span class="sxs-lookup"><span data-stu-id="d7a9f-113">Device support</span></span>


| <span data-ttu-id="d7a9f-114">Eingabemodell</span><span class="sxs-lookup"><span data-stu-id="d7a9f-114">Input Model</span></span> | [<span data-ttu-id="d7a9f-115">HoloLens (1. Generation)</span><span class="sxs-lookup"><span data-stu-id="d7a9f-115">HoloLens (1st gen)</span></span>](hololens-hardware-details.md) | <span data-ttu-id="d7a9f-116">HoloLens 2</span><span class="sxs-lookup"><span data-stu-id="d7a9f-116">HoloLens 2</span></span> |[<span data-ttu-id="d7a9f-117">Immersive Headsets</span><span class="sxs-lookup"><span data-stu-id="d7a9f-117">Immersive headsets</span></span>](immersive-headset-hardware-details.md)|
|:-------- | :-------| :--------| :------------|
| <span data-ttu-id="d7a9f-118">Direkte Manipulation mit den Händen</span><span class="sxs-lookup"><span data-stu-id="d7a9f-118">Direct manipulation with hands</span></span> | <span data-ttu-id="d7a9f-119">❌ Nicht unterstützt</span><span class="sxs-lookup"><span data-stu-id="d7a9f-119">❌ Not supported</span></span> | <span data-ttu-id="d7a9f-120">✔️ Empfohlen</span><span class="sxs-lookup"><span data-stu-id="d7a9f-120">✔️ Recommended</span></span> | <span data-ttu-id="d7a9f-121">➕ Eine Alternative wird empfohlen: [Zeigen und Ausführen mit den Händen](point-and-commit.md).</span><span class="sxs-lookup"><span data-stu-id="d7a9f-121">➕ An alternative, [point and commit with hands](point-and-commit.md) is recommended.</span></span>

<span data-ttu-id="d7a9f-122">Die direkte Manipulation ist ein primäres Eingabemodell für HoloLens 2 und nutzt das neue artikulierte Handtracking-System.</span><span class="sxs-lookup"><span data-stu-id="d7a9f-122">Direct manipulation is a primary input model on HoloLens 2, and utilizes the new articulated hand-tracking system.</span></span> <span data-ttu-id="d7a9f-123">Das Eingabemodell ist auch bei immersiven Headsets durch den Einsatz von Motion-Controllern verfügbar, wird aber nicht als primäre Möglichkeit zur Interaktion außerhalb der Objektmanipulation empfohlen.</span><span class="sxs-lookup"><span data-stu-id="d7a9f-123">The input model is also available on immersive headsets through the use of motion controllers, but is not recommended as a primary means of interaction outside of object manipulation.</span></span>  <span data-ttu-id="d7a9f-124">Die direkte Manipulation ist bei HoloLens (1. Generation) nicht verfügbar.</span><span class="sxs-lookup"><span data-stu-id="d7a9f-124">Direct manipluation is not available on HoloLens (1st gen).</span></span>


## <a name="collidable-fingertip"></a><span data-ttu-id="d7a9f-125">Kollisionsfähige Fingerspitze</span><span class="sxs-lookup"><span data-stu-id="d7a9f-125">Collidable fingertip</span></span>

<span data-ttu-id="d7a9f-126">Bei HoloLens 2 werden die echten Hände des Benutzers als Skelettmodelle der linken und rechten Hand erkannt und interpretiert.</span><span class="sxs-lookup"><span data-stu-id="d7a9f-126">On HoloLens 2, the user's real hands are recognized and interpreted as left and right hand skeletal models.</span></span> <span data-ttu-id="d7a9f-127">Um die Idee, Hologramme direkt mit den Händen zu berühren, zu implementieren, könnten idealerweise fünf Collider an fünf Fingerspitzen der einzelnen Handskelettmodelle angefügt werden.</span><span class="sxs-lookup"><span data-stu-id="d7a9f-127">To implement the idea of touching holograms directly with hands, ideally, 5 colliders could be attached to 5 fingertips of each hand skeletal model.</span></span> <span data-ttu-id="d7a9f-128">Aufgrund der fehlenden taktilen Rückmeldung haben jedoch zehn kollisionsfähige Fingerspitzen unerwartete und unvorhersehbare Kollisionen mit Hologrammen verursacht.</span><span class="sxs-lookup"><span data-stu-id="d7a9f-128">However, practically, due to the lack of tactile feedback, 10 collidable fingertips caused unexpected and unpredictable collisions with holograms.</span></span> 

<span data-ttu-id="d7a9f-129">Wir empfehlen daher, nur einen Collider an jedem Zeigefinger anzufügen.</span><span class="sxs-lookup"><span data-stu-id="d7a9f-129">Hence, we suggest to only put a collider on each index finger.</span></span> <span data-ttu-id="d7a9f-130">Die kollidierbaren Zeigefingerspitzen können weiterhin als aktive Berührungspunkte für verschiedene Berührungsgesten mit anderen Fingern dienen, z. B. Drücken mit einem Finger, Tippbewegung mit einem Finger, Drücken mit zwei Fingern und Drücken mit fünf Fingern, wie in der folgenden Abbildung dargestellt.</span><span class="sxs-lookup"><span data-stu-id="d7a9f-130">The collidable index fingertips can still serve as active touch points for diverse touch gestures involving other fingers, such as 1-finger press, 1-finger tap, 2-finger press and 5-finger press, as shown in the image below.</span></span>

![Abbildung zur kollisionsfähigen Fingerspitze](images/Collidable-Fingertip-720px.jpg)

### <a name="sphere-collider"></a><span data-ttu-id="d7a9f-132">Kugel-Collider</span><span class="sxs-lookup"><span data-stu-id="d7a9f-132">Sphere collider</span></span>

<span data-ttu-id="d7a9f-133">Anstatt eine zufällige generische Form zu verwenden, empfehlen wir, einen Kugel-Collider einzusetzen und ihn visuell zu rendern, um bessere Hinweise für die Zielbestimmung in der Nähe bereitzustellen.</span><span class="sxs-lookup"><span data-stu-id="d7a9f-133">Instead of using a random generic shape, we suggest to use a sphere collider and to visually render it to provide better cues for near targeting.</span></span> <span data-ttu-id="d7a9f-134">Der Durchmesser der Kugel muss der Dicke des Zeigefingers entsprechen, um die Genauigkeit bei der Toucheingabe zu erhöhen.</span><span class="sxs-lookup"><span data-stu-id="d7a9f-134">The sphere's diameter should match the thickness of the index finger to increase touch accuracy.</span></span> <span data-ttu-id="d7a9f-135">Das Abrufen der Variablen für die Fingerdicke gestaltet sich durch den Aufruf der Hand-API einfach.</span><span class="sxs-lookup"><span data-stu-id="d7a9f-135">It will be easy to retrieve the variable of finger thickness by calling the hand API.</span></span>

### <a name="fingertip-cursor"></a><span data-ttu-id="d7a9f-136">Fingerspitzencursor</span><span class="sxs-lookup"><span data-stu-id="d7a9f-136">Fingertip cursor</span></span>

<span data-ttu-id="d7a9f-137">Zusätzlich zum Rendern einer kollisionsfähigen Kugel an der Zeigefingerspitze haben wir eine erweiterte Lösung, den Fingerspitzencursor, entwickelt, um interaktiv ein besseres Erlebnis bei der Bestimmung nahegelegener Ziele zu erreichen.</span><span class="sxs-lookup"><span data-stu-id="d7a9f-137">In addition to rendering a collidable sphere on the index fingertip, we've created an advanced solution, fingertip cursor, to achieve better near-targeting experience interactively.</span></span> <span data-ttu-id="d7a9f-138">Es handelt sich um einen ringförmigen Cursor, der an der Zeigefingerspitze angebracht ist.</span><span class="sxs-lookup"><span data-stu-id="d7a9f-138">It is a donut-shaped cursor attached on the index fingertip.</span></span> <span data-ttu-id="d7a9f-139">Entsprechend der Nähe reagiert er dynamisch auf ein Ziel in Bezug auf Ausrichtung und Größe, wie unten beschrieben:</span><span class="sxs-lookup"><span data-stu-id="d7a9f-139">According to proximity, it dynamically reacts to a target in terms of orientation and size as detailed below:</span></span>

* <span data-ttu-id="d7a9f-140">Wenn sich ein Zeigefinger auf ein Hologramm zubewegt, befindet sich der Cursor immer parallel zur Oberfläche des Hologramms und verkleinert seine Größe entsprechend.</span><span class="sxs-lookup"><span data-stu-id="d7a9f-140">When an index finger moves toward a hologram, the cursor is always parallel to the hologram's surface  and gradually shrinks its size accordingly.</span></span>
* <span data-ttu-id="d7a9f-141">Sobald der Finger die Oberfläche berührt, schrumpft der Cursor zu einem Punkt und gibt ein Toucheingabeereignis aus.</span><span class="sxs-lookup"><span data-stu-id="d7a9f-141">As soon as the finger touches the surface, the cursor shrinks into a dot and emits a touch event.</span></span>

<span data-ttu-id="d7a9f-142">Mit dem interaktiven Feedback können Benutzer eine hohe Genauigkeit bei Aufgaben zur Zielbestimmung erreichen, z. B. das Auslösen eines Hyperlinks zu Webinhalten oder das Drücken einer Schaltfläche, wie nachfolgend veranschaulicht.</span><span class="sxs-lookup"><span data-stu-id="d7a9f-142">With the interactive feedback, users can achieve high precision near targeting tasks, such as triggering a hyperlink on web content or pressing a button, as shown, below.</span></span> 

![Abbildung zum Fingerspitzencursor](images/Fingertip-Cursor-720px.jpg)

## <a name="bounding-box-with-proximity-shader"></a><span data-ttu-id="d7a9f-144">Begrenzungsrahmen mit Näherungsshader</span><span class="sxs-lookup"><span data-stu-id="d7a9f-144">Bounding box with proximity shader</span></span>

<span data-ttu-id="d7a9f-145">Das Hologramm selbst erfordert auch die Fähigkeit, sowohl visuelles als auch akustisches Feedback zu liefern, um den Mangel an taktilem Feedback auszugleichen.</span><span class="sxs-lookup"><span data-stu-id="d7a9f-145">The hologram itself also requires the ability to provide both visual and audio feedback to compensate the lack of tactile feedback.</span></span> <span data-ttu-id="d7a9f-146">Dazu erstellen wir das Konzept eines Begrenzungsrahmens mit Näherungsshader.</span><span class="sxs-lookup"><span data-stu-id="d7a9f-146">For that, we generate the concept of a bounding box with proximity shader.</span></span> <span data-ttu-id="d7a9f-147">Ein Begrenzungsrahmen ist ein minimaler volumetrischer Bereich, der ein 3D-Objekt umgibt.</span><span class="sxs-lookup"><span data-stu-id="d7a9f-147">A bounding box is a minimum volumetric area that encloses a 3D object.</span></span> <span data-ttu-id="d7a9f-148">Der Begrenzungsrahmen verfügt über einen interaktiven Renderingmechanismus, der als Näherungsshader bezeichnet wird.</span><span class="sxs-lookup"><span data-stu-id="d7a9f-148">The bounding box has an interactive rendering mechanism called proximity shader.</span></span> <span data-ttu-id="d7a9f-149">Der Näherungsshader verhält sich wie folgt:</span><span class="sxs-lookup"><span data-stu-id="d7a9f-149">The proximity shader behaves:</span></span>

* <span data-ttu-id="d7a9f-150">Wenn sich der Zeigefinger innerhalb eines Bereichs befindet, wird ein Fingerspitzenspotlight auf die Oberfläche des Begrenzungsrahmens gerichtet.</span><span class="sxs-lookup"><span data-stu-id="d7a9f-150">When the index finger is within a range, a fingertip spotlight is cast on the surface of bounding box.</span></span>
* <span data-ttu-id="d7a9f-151">Wenn sich die Fingerspitze der Oberfläche nähert, verdichtet sich das Spotlight entsprechend.</span><span class="sxs-lookup"><span data-stu-id="d7a9f-151">When the fingertip gets closer to the surface, the spotlight condenses accordingly.</span></span>
* <span data-ttu-id="d7a9f-152">Sobald die Fingerspitze die Oberfläche berührt, wechselt der gesamte Begrenzungsrahmen die Farbe oder erzeugt einen visuellen Effekt, um den Toucheingabezustand zu reflektieren.</span><span class="sxs-lookup"><span data-stu-id="d7a9f-152">As soon as the fingertip touch the surface, the whole bounding box changes the color or generate visual effect to reflect the touch state.</span></span>
* <span data-ttu-id="d7a9f-153">In der Zwischenzeit kann ein Soundeffekt aktiviert werden, um das visuelle Feedback der Toucheingabe zu verbessern.</span><span class="sxs-lookup"><span data-stu-id="d7a9f-153">Meanwhile, a sound effect can be activated to enhance the visual touch feedback.</span></span>

![Abbildung zum Begrenzungsrahmen mit Näherungsshader](images/Bounding-Box-With-Proximity-Shader-720px.jpg)

## <a name="pressable-button"></a><span data-ttu-id="d7a9f-155">Drückbare Schaltfläche</span><span class="sxs-lookup"><span data-stu-id="d7a9f-155">Pressable button</span></span>

<span data-ttu-id="d7a9f-156">Mit einer kollisionsfähigen Fingerspitze sind die Benutzer jetzt bereit, mit der sehr grundlegenden holografischen Benutzeroberflächenkomponente, der drückbaren Schaltfläche, zu interagieren.</span><span class="sxs-lookup"><span data-stu-id="d7a9f-156">With a collidable fingertip, users are now ready to interact with the very fundamental holographic UI component, pressable button.</span></span> <span data-ttu-id="d7a9f-157">Eine drückbare Schaltfläche ist eine holografische Schaltfläche, die auf den direkten Fingerdruck angepasst ist.</span><span class="sxs-lookup"><span data-stu-id="d7a9f-157">A pressable button is a holographic button tailored for direct finger press.</span></span> <span data-ttu-id="d7a9f-158">Da es an taktilen Feedback mangelt, sorgt eine drückbare Schaltfläche für einige Mechanismen, um auf dem taktilen Feedback basierende Probleme zu beheben.</span><span class="sxs-lookup"><span data-stu-id="d7a9f-158">Again, due to the lack of tactile feedback, a pressable button equips a couple mechanisms to tackle tactile feedback-related issues.</span></span>

* <span data-ttu-id="d7a9f-159">Der erste Mechanismus ist ein Begrenzungsrahmen mit Näherungsshader, wie im vorherigen Abschnitt beschrieben.</span><span class="sxs-lookup"><span data-stu-id="d7a9f-159">The first mechanism is a bounding box with proximity shader, detailed in the previous section.</span></span> <span data-ttu-id="d7a9f-160">Er dient dazu, den Benutzern ein besseres Gefühl von Nähe zu vermitteln, damit sie sich einer Schaltfläche nähern und mit ihr Kontakt aufnehmen können.</span><span class="sxs-lookup"><span data-stu-id="d7a9f-160">It serves to provide better sense of proximity for users to approach and make contact with a button.</span></span>
* <span data-ttu-id="d7a9f-161">Der zweite Mechanismus ist die Absenkung.</span><span class="sxs-lookup"><span data-stu-id="d7a9f-161">The second one is depression.</span></span> <span data-ttu-id="d7a9f-162">Er erzeugt ein Druckgefühl, nachdem eine Fingerspitze die Schaltfläche berührt hat.</span><span class="sxs-lookup"><span data-stu-id="d7a9f-162">It creates sense of press, after a fingertip contacts the button.</span></span> <span data-ttu-id="d7a9f-163">Der Mechanismus besteht darin, dass sich die Schaltfläche mit der Fingerspitze eng entlang der Tiefenachse bewegt.</span><span class="sxs-lookup"><span data-stu-id="d7a9f-163">The mechanism is that the button tightly moves with the fingertip along the depth axis.</span></span> <span data-ttu-id="d7a9f-164">Die Schaltfläche kann ausgelöst werden, wenn sie eine bestimmte Tiefe erreicht (beim Drücken) oder die Tiefe wieder verlässt (beim Loslassen), nachdem sie passiert wurde.</span><span class="sxs-lookup"><span data-stu-id="d7a9f-164">The button can be triggered when it reaches a designated depth (on press) or leaves the depth (on release) after passing through it.</span></span>
* <span data-ttu-id="d7a9f-165">Der Soundeffekt sollte hinzugefügt werden, um das Feedback zu verbessern, wenn die Schaltfläche ausgelöst wird.</span><span class="sxs-lookup"><span data-stu-id="d7a9f-165">The sound effect should be added to enhance feedback, when the button is triggered.</span></span>

![Abbildung zur drückbaren Schaltfläche](images/Pressable-Button-720px.jpg)

## <a name="2d-slate-interaction"></a><span data-ttu-id="d7a9f-167">2D-Tafel – Interaktion</span><span class="sxs-lookup"><span data-stu-id="d7a9f-167">2D slate interaction</span></span>

<span data-ttu-id="d7a9f-168">Eine 2D-Tafel ist ein holografischer Container, der 2D-App-Inhalte hostet (z. B. Webbrowser).</span><span class="sxs-lookup"><span data-stu-id="d7a9f-168">A 2D slate is a holographic container hosting 2D app contents, such as web browser.</span></span> <span data-ttu-id="d7a9f-169">Das Konzept für die Interaktion mit einer 2D-Tafel durch direkte Manipulation besteht darin, das mentale Modell der Interaktion mit einem physischen Touchscreen zu nutzen.</span><span class="sxs-lookup"><span data-stu-id="d7a9f-169">The design concept for interacting with a 2D slate via direct manipulation is to leverage the mental model of interacting with a physical touch screen.</span></span>

<span data-ttu-id="d7a9f-170">So interagieren Sie mit dem Tafelkontakt</span><span class="sxs-lookup"><span data-stu-id="d7a9f-170">To interact with the slate contact:</span></span>

* <span data-ttu-id="d7a9f-171">Verwenden Sie einen Zeigefinger, um einen Link oder eine Schaltfläche zu drücken.</span><span class="sxs-lookup"><span data-stu-id="d7a9f-171">Use an index finger to press a hyperlink or a button.</span></span>
* <span data-ttu-id="d7a9f-172">Verwenden Sie einen Zeigefinger, um einen Tafelinhalt nach oben und unten zu scrollen.</span><span class="sxs-lookup"><span data-stu-id="d7a9f-172">Use an index finger to scroll a slate content up and down.</span></span>
* <span data-ttu-id="d7a9f-173">Benutzer verwenden zwei Zeigefinger, um den Tafelinhalt entsprechend der relativen Bewegung der Finger zu vergrößern oder zu verkleinern.</span><span class="sxs-lookup"><span data-stu-id="d7a9f-173">Users use two index fingers to zoom in and out the slate content according to relative motion of fingers.</span></span>

![Abbildung zur 2D-Tafel](images/2D-Slate-Interaction-720px.jpg)

<span data-ttu-id="d7a9f-175">So bearbeiten Sie die eigentliche 2D-Tafel</span><span class="sxs-lookup"><span data-stu-id="d7a9f-175">For manipulating the 2D slate itself:</span></span>

* <span data-ttu-id="d7a9f-176">Nähern Sie sich mit Ihren Händen den Ecken und Kanten, um die nächstgelegenen Manipulationsangebote zu enthüllen.</span><span class="sxs-lookup"><span data-stu-id="d7a9f-176">Approach your hands toward corners and edges to reveal the closest manipulation affordances.</span></span>
* <span data-ttu-id="d7a9f-177">Greifen Sie die Manipulationsangebote, und führen Sie über die Eckenangebote eine einheitliche Skalierung und über die Kantenangebote die Neuanordnung der Tafel aus.</span><span class="sxs-lookup"><span data-stu-id="d7a9f-177">Grab the manipulation affordances, and perform uniform scaling through the corner affordances and reflow via the edge affordances.</span></span>
* <span data-ttu-id="d7a9f-178">Greifen Sie die Hololeiste im oberen Bereich der 2D-Tafel, mit der Sie die gesamte Tafel verschieben können.</span><span class="sxs-lookup"><span data-stu-id="d7a9f-178">Grab the holobar at the top of the 2D slate, which lets you move the whole slate.</span></span>

![Abbildung zur Tafelmanipulation](images/Manipulate-2d-slate-720px.jpg)

## <a name="3d-object-manipulation"></a><span data-ttu-id="d7a9f-180">3D-Objektbearbeitung</span><span class="sxs-lookup"><span data-stu-id="d7a9f-180">3D object manipulation</span></span>

<span data-ttu-id="d7a9f-181">Bei HoloLens 2 können Benutzer ihre Hände in die Lage versetzen, holografische 3D-Objekte direkt zu bearbeiten, indem sie auf die einzelnen 3D-Objekte einen Begrenzungsrahmen anwenden.</span><span class="sxs-lookup"><span data-stu-id="d7a9f-181">HoloLens 2 lets lets users enable their hands to direct manipulate 3D hologramphic objects by applying a bounding box to each 3D object.</span></span> <span data-ttu-id="d7a9f-182">Der Begrenzungsrahmen sorgt durch seinen Näherungsshader für eine bessere Tiefenwahrnehmung.</span><span class="sxs-lookup"><span data-stu-id="d7a9f-182">The bounding box provides better depth perception through its proximity shader.</span></span> <span data-ttu-id="d7a9f-183">Mit dem Begrenzungsrahmen gibt es zwei Konstruktionsansätze für die 3D-Objektbearbeitung.</span><span class="sxs-lookup"><span data-stu-id="d7a9f-183">With the bounding box, there are two design approaches for 3D object manipulation.</span></span>

### <a name="affordance-based-manipulation"></a><span data-ttu-id="d7a9f-184">Angebotsbasierte Bearbeitung</span><span class="sxs-lookup"><span data-stu-id="d7a9f-184">Affordance-based manipulation</span></span>

<span data-ttu-id="d7a9f-185">Auf diese Weise können Sie das 3D-Objekt durch einen Begrenzungsrahmen und die damit verbundenen Bearbeitungsangebote manipulieren.</span><span class="sxs-lookup"><span data-stu-id="d7a9f-185">This lets you manipulate the 3D object through a bounding box and the manipulation affordances around it.</span></span> <span data-ttu-id="d7a9f-186">Sobald sich die Hand eines Benutzers in der Nähe eines 3D-Objekts befindet, werden der Begrenzungsrahmen und das nächstgelegene Angebot angezeigt.</span><span class="sxs-lookup"><span data-stu-id="d7a9f-186">As soon as a user's hand is close to a 3D object, the bounding box and the nearest affordance are revealed.</span></span> <span data-ttu-id="d7a9f-187">Der Benutzer kann den Begrenzungsrahmen greifen, um das gesamte Objekt zu verschieben, die Kantenangebote greifen, um das Objekt zu drehen, und die Eckenangebote greifen, um eine einheitliche Skalierung vorzunehmen.</span><span class="sxs-lookup"><span data-stu-id="d7a9f-187">Users can grab the bounding box to move the whole object, the edge affordances to rotate and the corner affordances to scale uniformly.</span></span>

![Abbildung zur 3D-Objektbearbeitung](images/3D-Object-Manipulation-720px.jpg)

### <a name="non-affordance-based-manipulation"></a><span data-ttu-id="d7a9f-189">Bearbeitung ohne Angebot</span><span class="sxs-lookup"><span data-stu-id="d7a9f-189">Non-affordance based manipulation</span></span>

<span data-ttu-id="d7a9f-190">Bei diesem Mechanismus ist an den Begrenzungsrahmen kein Angebot angefügt.</span><span class="sxs-lookup"><span data-stu-id="d7a9f-190">In this mechanism, no affordance is attached to the bounding box.</span></span> <span data-ttu-id="d7a9f-191">Benutzer können den Begrenzungsrahmen nur anzeigen und dann direkt mit ihm interagieren.</span><span class="sxs-lookup"><span data-stu-id="d7a9f-191">Users can only reveal the bounding box, then directly interact with it.</span></span> <span data-ttu-id="d7a9f-192">Wenn der Begrenzungsrahmen mit einer Hand gegriffen wird, sind Verschiebung und Drehung des Objekts der Bewegung und Ausrichtung der Hand zugeordnet.</span><span class="sxs-lookup"><span data-stu-id="d7a9f-192">If the bounding box is grabbed with one hand, the translation and rotation of the object are associated to motion and orientation of the hand.</span></span> <span data-ttu-id="d7a9f-193">Wenn das Objekt mit zwei Händen gegriffen wird, kann der Benutzer Verschiebung, Drehung und Skalierung entsprechend der relativen Bewegung der beiden Hände vornehmen.</span><span class="sxs-lookup"><span data-stu-id="d7a9f-193">When the object is grabbed with two hands, users can translate, scale and rotate it according to relative motions of two hands.</span></span>

<span data-ttu-id="d7a9f-194">Bestimmte Bearbeitungen erfordern Genauigkeit, wir empfehlen daher die Verwendung von **angebotsbasierter Bearbeitung**, da sie ein hohes Maß an Granularität bietet.</span><span class="sxs-lookup"><span data-stu-id="d7a9f-194">Specific manipulation requires precision, we recommend you use **affordance-based manipulation**, because it provides a high level of granularity.</span></span> <span data-ttu-id="d7a9f-195">Für eine flexible Bearbeitung empfehlen wir Ihnen, **eine angebotsfreie Bearbeitung** zu verwenden, da sie sofortige und spielerische Umgebungen ermöglicht.</span><span class="sxs-lookup"><span data-stu-id="d7a9f-195">For flexible manipulation, we recommend you uses **non-affordance manipulation** is as it allows for instant and playful experiences.</span></span>

## <a name="instinctual-gestures"></a><span data-ttu-id="d7a9f-196">Instinktive Gesten</span><span class="sxs-lookup"><span data-stu-id="d7a9f-196">Instinctual gestures</span></span>

<span data-ttu-id="d7a9f-197">Mit HoloLens (1. Generation) haben wir den Benutzern eine Reihe vordefinierter Gesten vermittelt, z. B. „Öffnen“ und „In die Luft tippen“.</span><span class="sxs-lookup"><span data-stu-id="d7a9f-197">With HoloLens (1st gen), we taught users a couple predefined gestures,such as Bloom and Air Tap.</span></span> <span data-ttu-id="d7a9f-198">Bei HoloLens 2 werden die Benutzer nicht aufgefordert, sich symbolische Gesten zu merken.</span><span class="sxs-lookup"><span data-stu-id="d7a9f-198">For HoloLens 2, we don't ask users to memorize any symbolic gestures.</span></span> <span data-ttu-id="d7a9f-199">Alle erforderlichen Benutzergesten, die der Benutzer zur Interaktion mit Hologrammen und Inhalten benötigt, sind instinktiv.</span><span class="sxs-lookup"><span data-stu-id="d7a9f-199">All required user gestures, users need to interact with holograms and contents, are instinctual.</span></span> <span data-ttu-id="d7a9f-200">Um instinktive Gesten zu erreichen, müssen Benutzer durch den Entwurf von Benutzeroberflächenangeboten dazu angeleitet werden, Gesten auszuführen.</span><span class="sxs-lookup"><span data-stu-id="d7a9f-200">The way to achieve instinctual gesture is to guide users to perform gestures through the design of UI affordances.</span></span>

<span data-ttu-id="d7a9f-201">Wenn wir Sie z. B. bestärken, ein Objekt oder einen Kontrollpunkt durch Zusammenführen von zwei Fingern zu greifen, sollte das Objekt oder der Kontrollpunkt klein sein.</span><span class="sxs-lookup"><span data-stu-id="d7a9f-201">For example, if we encourage you to grab an object or a control point with two finger pinch, the object or the control point should be small.</span></span> <span data-ttu-id="d7a9f-202">Wenn Sie mit fünf Fingern greifen sollen, sollte das Objekt oder der Kontrollpunkt relativ groß sein.</span><span class="sxs-lookup"><span data-stu-id="d7a9f-202">If we want you to perform five finger grab, the object or the control point should be relatively big.</span></span> <span data-ttu-id="d7a9f-203">Bezogen auf Schaltflächen würde eine winzige Schaltfläche die Benutzer darauf beschränken, sie mit einem einzelnen Finger zu drücken, während eine große Schaltfläche die Benutzer veranlassen würde, sie mit ihren Handflächen zu drücken.</span><span class="sxs-lookup"><span data-stu-id="d7a9f-203">Similar to buttons, a tiny button would limit users to press it with a single finger, while a huge button would encourage users to press it with their palms.</span></span>

![](images/Instinctual-Gestures-720px.jpg)

## <a name="symmetric-design-between-hands-and-6-dof-controllers"></a><span data-ttu-id="d7a9f-204">Symmetrisches Design zwischen Händen und Controllern mit 6 Freiheitsgraden</span><span class="sxs-lookup"><span data-stu-id="d7a9f-204">Symmetric design between hands and 6 DoF controllers</span></span>

<span data-ttu-id="d7a9f-205">Sie haben vielleicht bemerkt, dass es jetzt Interaktionsparallelen gibt, die wir zwischen Händen in AR und Motion-Controllern in VR ziehen können.</span><span class="sxs-lookup"><span data-stu-id="d7a9f-205">You may have noticed that there are now interaction parallels we can draw between hands in AR and motion controllers in VR.</span></span> <span data-ttu-id="d7a9f-206">Beide Eingabemethoden können verwendet werden, um direkte Bearbeitungen in ihrer jeweiligen Umgebung auszulösen.</span><span class="sxs-lookup"><span data-stu-id="d7a9f-206">Both inputs can be used to trigger direct manipulations in their respective environments.</span></span> <span data-ttu-id="d7a9f-207">In HoloLens 2 funktioniert das Greifen und Ziehen mit den Händen aus nächster Nähe weitgehend so wie die Taste zum Greifen an den Motion-Controllern in WMR.</span><span class="sxs-lookup"><span data-stu-id="d7a9f-207">In HoloLens 2, grabbing and dragging with hands at a close distance works much in the same way as the grab button does on the motion controllers in WMR.</span></span> <span data-ttu-id="d7a9f-208">Dies bietet den Benutzern die vertraute Interaktion zwischen den beiden Plattformen, die sich als nützlich erweisen kann, falls Sie sich jemals dazu entscheiden, Ihre App von einer zur anderen Plattform zu portieren.</span><span class="sxs-lookup"><span data-stu-id="d7a9f-208">This provides users with interaction familiarity between the two platforms and may prove useful should you ever decide to port your app from one to the other.</span></span>

## <a name="optimize-with-eye-tracking"></a><span data-ttu-id="d7a9f-209">Optimieren mit Eyetracking</span><span class="sxs-lookup"><span data-stu-id="d7a9f-209">Optimize with eye tracking</span></span>

<span data-ttu-id="d7a9f-210">Die direkte Bearbeitung kann sich magisch anfühlen, wenn sie wie beabsichtigt funktioniert. Sie kann aber auch schnell zu Enttäuschungen führen, wenn Sie Ihre Hand nicht mehr bewegen können, ohne unbeabsichtigt ein Hologramm zu aktivieren.</span><span class="sxs-lookup"><span data-stu-id="d7a9f-210">Direct manipulation can feel magical if it works as intended, but can also quickly become frustrating if you can’t move your hand anywhere anymore without unintentionally triggering a hologram.</span></span>
<span data-ttu-id="d7a9f-211">Das Eyetracking kann potenziell helfen, die Absicht des Benutzers besser zu erkennen.</span><span class="sxs-lookup"><span data-stu-id="d7a9f-211">Eye tracking can potentially help in better identifying what the user’s intent is.</span></span>

* <span data-ttu-id="d7a9f-212">**Wann**: Reduzieren der fehlerhaften Auslösung einer Bearbeitungsreaktion.</span><span class="sxs-lookup"><span data-stu-id="d7a9f-212">**When**: Reduce falsely triggering a manipulation response.</span></span> <span data-ttu-id="d7a9f-213">Das Eyetracking ermöglicht ein besseres Verständnis dafür, womit sich ein Benutzer gerade beschäftigt.</span><span class="sxs-lookup"><span data-stu-id="d7a9f-213">Eye tracking allows for better understanding what a user is currently engaged with.</span></span>
<span data-ttu-id="d7a9f-214">Stellen Sie sich z. B. vor, Sie lesen einen holografischen (lehrreichen) Text durch, wenn Sie rübergreifen, um Ihr reales Arbeitsgerät aufzunehmen.</span><span class="sxs-lookup"><span data-stu-id="d7a9f-214">For example, imagine you are reading through a holographic (instructional) text when reaching over to grab you real-world work tool.</span></span>

<span data-ttu-id="d7a9f-215">Dabei bewegen Sie Ihre Hand versehentlich über einige interaktive holografische Schaltflächen, die Sie vorher noch nicht einmal bemerkt haben (vielleicht lagen sie sogar außerhalb des Sichtfelds des Benutzers).</span><span class="sxs-lookup"><span data-stu-id="d7a9f-215">By doing so, you accidentally move your hand across some interactive holographic buttons that you hadn't even noticed before (maybe it even was outside of the user's Field-of-View (FOV)).</span></span>

  <span data-ttu-id="d7a9f-216">Lange Rede kurzer Sinn: Wenn der Benutzer ein Hologramm eine Weile nicht betrachtet hat, aber ein Toucheingabe- oder Greifereignis dafür erkannt wurde, ist es wahrscheinlich, dass der Benutzer nicht wirklich beabsichtigt hat, mit diesem Hologramm zu interagieren.</span><span class="sxs-lookup"><span data-stu-id="d7a9f-216">Long story short: If the user hasn't looked at a hologram for a while, yet a touch or grasp event has been detected for it, it is likely that the user wasn't actually intending to interact with that hologram.</span></span>

* <span data-ttu-id="d7a9f-217">**Welche**:  Abgesehen von der Behandlung falsch positiver Aktivierungen umfasst ein weiteres Beispiel die bessere Identifizierung, welche Hologramme zu greifen oder zu drücken sind, da der genaue Schnittpunkt aus Ihrer Sicht möglicherweise nicht eindeutig ist, insbesondere wenn mehrere Hologramme nahe beieinander positioniert sind.</span><span class="sxs-lookup"><span data-stu-id="d7a9f-217">**Which one**:  Aside from addressing false positive activations, another example includes better identifying which holograms to grab or poke as the precise intersection point may not be clear from your perspective especially if several holograms are positioned close to each other.</span></span>

  <span data-ttu-id="d7a9f-218">Während das Eyetracking bei HoloLens 2 eine gewisse Einschränkung aufweist, wie genau es Ihr Anvisieren mit dem Kopf bestimmen kann, ist dies bei nahen Interaktionen aufgrund von Tiefenunterschieden bei der Interaktion mit der Handeingabe möglicherweise sehr hilfreich.</span><span class="sxs-lookup"><span data-stu-id="d7a9f-218">While eye tracking on HoloLens 2 has a certain limitation on how accurately it can determine you eye gaze, this can still be very helpful for near interactions due to depth disparity when interacting with hand input.</span></span>  <span data-ttu-id="d7a9f-219">Das bedeutet, dass es manchmal schwierig ist, festzustellen, ob sich Ihre Hand hinter oder vor einem Hologramm befindet, um z. B. ein Widget für die Bearbeitung präzise zu greifen.</span><span class="sxs-lookup"><span data-stu-id="d7a9f-219">This means that it is sometimes difficult to determine whether your hand is behind or in front of a hologram to precisely grab a manipulation widget for example.</span></span>

* <span data-ttu-id="d7a9f-220">**Wohin**: Verwenden Sie Informationen darüber, was sich ein Benutzer ansieht, mit schnell auslösenden Gesten.</span><span class="sxs-lookup"><span data-stu-id="d7a9f-220">**Where to**: Use information about what a user is looking at with quick- throwing gestures.</span></span> <span data-ttu-id="d7a9f-221">Greifen Sie ein Hologramm, und werfen Sie es grob in Richtung Ihres beabsichtigten Ziels.</span><span class="sxs-lookup"><span data-stu-id="d7a9f-221">Grab a hologram and roughly toss it toward your intended destination.</span></span>  

    <span data-ttu-id="d7a9f-222">Obwohl dies manchmal sehr gut funktioniert, können schnell ausgeführte Handgesten zu sehr ungenauen Zielen führen.</span><span class="sxs-lookup"><span data-stu-id="d7a9f-222">While this may sometimes works just fine, quickly performing hand gestures may result in highly inaccurate destinations.</span></span> <span data-ttu-id="d7a9f-223">Hier könnte das Eyetracking helfen, den Vektor für den Wurf mit der Hand wieder an die gewünschte Position zu bringen.</span><span class="sxs-lookup"><span data-stu-id="d7a9f-223">This is where eye tracking could help out to lean the hand throwing vector back to your intended position.</span></span>

## <a name="see-also"></a><span data-ttu-id="d7a9f-224">Weitere Informationen</span><span class="sxs-lookup"><span data-stu-id="d7a9f-224">See also</span></span>

* [<span data-ttu-id="d7a9f-225">Anvisieren mit dem Kopf und Ausführen</span><span class="sxs-lookup"><span data-stu-id="d7a9f-225">Head-gaze and commit</span></span>](gaze-and-commit.md)
* [<span data-ttu-id="d7a9f-226">Zeigen und Ausführen mit den Händen</span><span class="sxs-lookup"><span data-stu-id="d7a9f-226">Point and commit with hands</span></span>](point-and-commit.md)
* [<span data-ttu-id="d7a9f-227">Instinktive Interaktionen</span><span class="sxs-lookup"><span data-stu-id="d7a9f-227">Instinctual interactions</span></span>](interaction-fundamentals.md)

