---
title: Hands-und Motion-Controller in DirectX
description: Entwicklerhandbuch zur Verwendung von Hand Verfolgungs-und Bewegungs Controllern in nativen DirectX-apps.
author: caseymeekhof
ms.author: cmeekhof
ms.date: 04/30/2019
ms.topic: article
keywords: Hands, Motion Controllers, DirectX, Input, holograms
ms.openlocfilehash: 54eaacc3f0dccf728b5438c020a5efd7e0788251
ms.sourcegitcommit: 4081dc2356fec0ea3625f1d989689cfbbb3fcf5f
ms.translationtype: MT
ms.contentlocale: de-DE
ms.lasthandoff: 11/20/2019
ms.locfileid: "74203330"
---
# <a name="hands-and-motion-controllers-in-directx"></a><span data-ttu-id="2b056-104">Hands-und Motion-Controller in DirectX</span><span class="sxs-lookup"><span data-stu-id="2b056-104">Hands and motion controllers in DirectX</span></span>

<span data-ttu-id="2b056-105">In der gemischten Realität von Windows werden sowohl Hand-als auch [Bewegungs Controller](motion-controllers.md) Eingaben über die räumlichen Eingabe-APIs behandelt, die sich im [Windows. UI. Input. Spatial](https://docs.microsoft.com/uwp/api/windows.ui.input.spatial) -Namespace befinden.</span><span class="sxs-lookup"><span data-stu-id="2b056-105">In Windows Mixed Reality, both hand and [motion controller](motion-controllers.md) input is handled through the spatial input APIs, found in the [Windows.UI.Input.Spatial](https://docs.microsoft.com/uwp/api/windows.ui.input.spatial) namespace.</span></span> <span data-ttu-id="2b056-106">Dadurch **haben Sie die** Möglichkeit, häufig gängige Aktionen zu behandeln, z. b</span><span class="sxs-lookup"><span data-stu-id="2b056-106">This enables you to easily handle common actions like **Select** presses the same way across both hands and motion controllers.</span></span>

## <a name="getting-started"></a><span data-ttu-id="2b056-107">Erste Schritte</span><span class="sxs-lookup"><span data-stu-id="2b056-107">Getting started</span></span>

<span data-ttu-id="2b056-108">Wenn Sie in Windows Mixed Reality auf räumliche Eingaben zugreifen möchten, beginnen Sie mit der spatialinteraktionmanager-Schnittstelle.</span><span class="sxs-lookup"><span data-stu-id="2b056-108">To access spatial input in Windows Mixed Reality, start with the SpatialInteractionManager interface.</span></span>  <span data-ttu-id="2b056-109">Sie können auf diese Schnittstelle zugreifen, indem Sie [spatialinteraktionmanager:: getforcurrentview](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.getforcurrentview)aufrufen, in der Regel beim Starten der app.</span><span class="sxs-lookup"><span data-stu-id="2b056-109">You can access this interface by calling  [SpatialInteractionManager::GetForCurrentView](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.getforcurrentview), typically sometime during app startup.</span></span>

```cpp
using namespace winrt::Windows::UI::Input::Spatial;

SpatialInteractionManager interactionManager = SpatialInteractionManager::GetForCurrentView();
```

<span data-ttu-id="2b056-110">Die Aufgabe von spatialinteraktionmanager besteht darin, den Zugriff auf [spatialinteraktionsources](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsource)bereitzustellen, die eine Quelle für Eingaben darstellen.</span><span class="sxs-lookup"><span data-stu-id="2b056-110">The SpatialInteractionManager's job is to provide access to [SpatialInteractionSources](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsource), which represent a source of input.</span></span>  <span data-ttu-id="2b056-111">Im System sind drei Arten von spatialinteraktionsources verfügbar.</span><span class="sxs-lookup"><span data-stu-id="2b056-111">There are three kinds of SpatialInteractionSources available in the system.</span></span>
* <span data-ttu-id="2b056-112">**Hand** stellt die erkannte Hand eines Benutzers dar.</span><span class="sxs-lookup"><span data-stu-id="2b056-112">**Hand** represents a user's detected hand.</span></span> <span data-ttu-id="2b056-113">Hand Quellen bieten verschiedene Features, die auf dem Gerät basieren, von grundlegenden Gesten auf hololens bis hin zur vollständigen manuellen Nachverfolgung auf hololens 2.</span><span class="sxs-lookup"><span data-stu-id="2b056-113">Hand sources offer different features based on the device, ranging from basic gestures on HoloLens to fully articulated hand tracking on HoloLens 2.</span></span> 
* <span data-ttu-id="2b056-114">**Controller** stellt einen gekoppelten Bewegungs Controller dar.</span><span class="sxs-lookup"><span data-stu-id="2b056-114">**Controller** represents a paired motion controller.</span></span> <span data-ttu-id="2b056-115">Bewegungs Controller können eine Vielzahl von Funktionen bieten.</span><span class="sxs-lookup"><span data-stu-id="2b056-115">Motion controllers can offer a variety of capabilities.</span></span>  <span data-ttu-id="2b056-116">Beispiel: Auswählen von Triggern, Menü Schaltflächen, Zieh Schaltflächen, Touchpads und fingerstäbchen.</span><span class="sxs-lookup"><span data-stu-id="2b056-116">For example: Select triggers, Menu buttons, Grasp buttons, touchpads and thumbsticks.</span></span>
* <span data-ttu-id="2b056-117">**Voice** repräsentiert die von einem Benutzer festgestellten sprach Schlüsselwörter.</span><span class="sxs-lookup"><span data-stu-id="2b056-117">**Voice** represents the user's voice speaking system-detected keywords.</span></span> <span data-ttu-id="2b056-118">Beispielsweise fügt diese Quelle eine SELECT Press-und-Freigabe ein, wenn der Benutzer "Select" anzeigt.</span><span class="sxs-lookup"><span data-stu-id="2b056-118">For example, this source will inject a Select press and release whenever the user says "Select".</span></span>

<span data-ttu-id="2b056-119">Pro-Frame-Daten für eine Quelle werden von der [spatialinteraktionsourcestate](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate) -Schnittstelle dargestellt.</span><span class="sxs-lookup"><span data-stu-id="2b056-119">Per-frame data for a source is represented by the  [SpatialInteractionSourceState](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate) interface.</span></span> <span data-ttu-id="2b056-120">Es gibt zwei verschiedene Möglichkeiten, auf diese Daten zuzugreifen, je nachdem, ob Sie ein Ereignis gesteuertem oder Abruf basiertes Modell in der Anwendung verwenden möchten.</span><span class="sxs-lookup"><span data-stu-id="2b056-120">There are two different ways to access this data, depending on whether you want to use an event-driven or polling-based model in your application.</span></span>

### <a name="event-driven-input"></a><span data-ttu-id="2b056-121">Ereignisgesteuerte Eingabe</span><span class="sxs-lookup"><span data-stu-id="2b056-121">Event-driven input</span></span>
<span data-ttu-id="2b056-122">Der spatialinteraktionsmanager stellt eine Reihe von Ereignissen bereit, die Ihre APP überwachen kann.</span><span class="sxs-lookup"><span data-stu-id="2b056-122">The SpatialInteractionManager provides a number of events that your app can listen for.</span></span>  <span data-ttu-id="2b056-123">Einige Beispiele hierfür sind " [sourcepressed](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcepressed)", " [sourcereleasing](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcereleased) " und " [sourceupveraltet](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourceupdated)".</span><span class="sxs-lookup"><span data-stu-id="2b056-123">A few examples include   [SourcePressed](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcepressed), [SourceReleased](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcereleased) and [SourceUpdated](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourceupdated).</span></span>

<span data-ttu-id="2b056-124">Der folgende Code verknüpft z. b. einen Ereignishandler mit dem Namen MyApp:: onsourcepressed zum sourcepressed-Ereignis.</span><span class="sxs-lookup"><span data-stu-id="2b056-124">For example, the following code hooks up an event handler called MyApp::OnSourcePressed to the SourcePressed event.</span></span>  <span data-ttu-id="2b056-125">Dadurch kann Ihre APP auf jeder Art von Interaktions Quelle drückt erkennen.</span><span class="sxs-lookup"><span data-stu-id="2b056-125">This allows your app to detect presses on any type of interaction source.</span></span>

```cpp
using namespace winrt::Windows::UI::Input::Spatial;

auto interactionManager = SpatialInteractionManager::GetForCurrentView();
interactionManager.SourcePressed({ this, &MyApp::OnSourcePressed });

```

<span data-ttu-id="2b056-126">Dieses gedrückte Ereignis wird asynchron an die APP gesendet, zusammen mit dem entsprechenden spatialinteraktionsourcestate zu dem Zeitpunkt, zu dem der Druck erfolgt ist.</span><span class="sxs-lookup"><span data-stu-id="2b056-126">This pressed event is sent to your app asynchronously, along with the corresponding SpatialInteractionSourceState at the time the press happened.</span></span> <span data-ttu-id="2b056-127">Ihre APP-oder Spiel-Engine möchte möglicherweise einige Verarbeitungsvorgänge ausführen, oder Sie möchten die Ereignisdaten in der Eingabe Verarbeitungsroutine in eine Warteschlange stellen.</span><span class="sxs-lookup"><span data-stu-id="2b056-127">Your app or game engine may want to perform some processing right away or you may want to queue up the event data in your input processing routine.</span></span> <span data-ttu-id="2b056-128">Hier ist eine Ereignishandlerfunktion für das sourcepressed-Ereignis, das zeigt, wie Sie überprüfen, ob die Select-Schaltfläche gedrückt wurde.</span><span class="sxs-lookup"><span data-stu-id="2b056-128">Here is an event handler function for the SourcePressed event, which shows how to check whether the select button was pressed.</span></span>

```cpp
using namespace winrt::Windows::UI::Input::Spatial;

void MyApp::OnSourcePressed(SpatialInteractionManager const& sender, SpatialInteractionSourceEventArgs const& args)
{
    if (args.PressKind() == SpatialInteractionPressKind::Select)
    {
        // Select button was pressed, update app state
    }
}
```

<span data-ttu-id="2b056-129">Der obige Code überprüft nur die SELECT-Taste, die der primären Aktion auf dem Gerät entspricht.</span><span class="sxs-lookup"><span data-stu-id="2b056-129">The above code only checks for the 'Select' press, which corresponds to the primary action on the device.</span></span> <span data-ttu-id="2b056-130">Beispiele hierfür sind die Durchführung einer airtap auf hololens oder das Abrufen des Auslösers auf einem Bewegungs Controller.</span><span class="sxs-lookup"><span data-stu-id="2b056-130">Examples include doing an AirTap on HoloLens or pulling the trigger on a motion controller.</span></span>  <span data-ttu-id="2b056-131">"Select"-Pressen stellen dar, dass die Absicht des Benutzers ist, das Hologramm zu aktivieren, auf das Sie abzielen</span><span class="sxs-lookup"><span data-stu-id="2b056-131">'Select' presses represent the user's intention to activate the hologram they are targeting.</span></span>  <span data-ttu-id="2b056-132">Das sourcepressed-Ereignis wird für eine Reihe unterschiedlicher Schaltflächen und Gesten ausgelöst, und Sie können andere Eigenschaften auf der spatialinteraktionsource überprüfen, um diese Fälle zu testen.</span><span class="sxs-lookup"><span data-stu-id="2b056-132">The SourcePressed event will fire for a number of different buttons and gestures, and you can inspect other properties on the SpatialInteractionSource to test for those cases.</span></span>

### <a name="polling-based-input"></a><span data-ttu-id="2b056-133">Abruf basierte Eingabe</span><span class="sxs-lookup"><span data-stu-id="2b056-133">Polling-based input</span></span>
<span data-ttu-id="2b056-134">Sie können auch spatialinteraktionmanager verwenden, um den aktuellen Status der Eingabe jedes Frame abzufragen.</span><span class="sxs-lookup"><span data-stu-id="2b056-134">You can also use SpatialInteractionManager to poll for the current state of input every frame.</span></span>  <span data-ttu-id="2b056-135">Um dies zu erreichen, nennen Sie einfach [getdetectedsourcesattimestamp](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.getdetectedsourcesattimestamp) jeden Frame.</span><span class="sxs-lookup"><span data-stu-id="2b056-135">To do this, simply call [GetDetectedSourcesAtTimestamp](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.getdetectedsourcesattimestamp) every frame.</span></span>  <span data-ttu-id="2b056-136">Diese Funktion gibt ein Array zurück, das eine [spatialinteraktionsourcestate](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate) für jede aktive [spatialinteraktionsource](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsource)enthält.</span><span class="sxs-lookup"><span data-stu-id="2b056-136">This function returns an array containing one [SpatialInteractionSourceState](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate) for every active [SpatialInteractionSource](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsource).</span></span> <span data-ttu-id="2b056-137">Dies bedeutet, dass eine für jeden aktiven Motion-Controller, eine für jede verfolgte Hand und eine für die Sprache, wenn ein SELECT-Befehl vor kurzem ausgesprochen wurde.</span><span class="sxs-lookup"><span data-stu-id="2b056-137">This means one for each active motion controller, one for each tracked hand, and one for speech if a 'select' command was recently uttered.</span></span> <span data-ttu-id="2b056-138">Sie können dann die Eigenschaften auf den einzelnen spatialinteraktionsourcestate-Objekten überprüfen, um Eingaben in Ihre Anwendung zu steuern.</span><span class="sxs-lookup"><span data-stu-id="2b056-138">You can then inspect the properties on each SpatialInteractionSourceState to drive input into your application.</span></span> 

<span data-ttu-id="2b056-139">Im folgenden finden Sie ein Beispiel für die Überprüfung der SELECT-Aktion mithilfe der Abruf Methode.</span><span class="sxs-lookup"><span data-stu-id="2b056-139">Here is an example of how to check for the 'select' action using the polling method.</span></span> <span data-ttu-id="2b056-140">Beachten Sie, dass die *Vorhersage* Variable ein [holographicframevorhersage](https://docs.microsoft.com//uwp/api/Windows.Graphics.Holographic.HolographicFramePrediction) -Objekt darstellt, das aus dem [holographicframe](https://docs.microsoft.com//uwp/api/windows.graphics.holographic.holographicframe)abgerufen werden kann.</span><span class="sxs-lookup"><span data-stu-id="2b056-140">Note that the *prediction* variable represents a [HolographicFramePrediction](https://docs.microsoft.com//uwp/api/Windows.Graphics.Holographic.HolographicFramePrediction) object, which can be obtained from the [HolographicFrame](https://docs.microsoft.com//uwp/api/windows.graphics.holographic.holographicframe).</span></span>

```cpp
using namespace winrt::Windows::UI::Input::Spatial;

auto interactionManager = SpatialInteractionManager::GetForCurrentView();
auto sourceStates = m_spatialInteractionManager.GetDetectedSourcesAtTimestamp(prediction.Timestamp());

for (auto& sourceState : sourceStates)
{
    if (sourceState.IsSelectPressed())
    {
        // Select button is down, update app state
    }
}
```

<span data-ttu-id="2b056-141">Jede spatialinteraktionsource verfügt über eine ID, mit der Sie neue Quellen identifizieren und vorhandene Quellen von Frame zu Frame korrelieren können.</span><span class="sxs-lookup"><span data-stu-id="2b056-141">Each SpatialInteractionSource has an ID, which you can use to identify new sources and correlate existing sources from frame to frame.</span></span>  <span data-ttu-id="2b056-142">Den Händen wird immer dann eine neue ID zugewiesen, wenn Sie den FOV verlassen, während die Controller-IDs für die Dauer der Sitzung statisch bleiben.</span><span class="sxs-lookup"><span data-stu-id="2b056-142">Hands are assigned a new ID every time they leave and enter the FOV, but controller IDs remain static for the duration of the session.</span></span>  <span data-ttu-id="2b056-143">Sie können die Ereignisse in spatialinteraktionmanager, wie z. b. [sourceerkannten](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcedetected) und [sourcelost](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcelost), verwenden, um zu reagieren, wenn die Hände in die Ansicht des Geräts eingegeben oder verlassen werden oder wenn Bewegungs Controller eingeschaltet/ausgeschaltet sind oder gekoppelt bzw. nicht gekoppelt sind.</span><span class="sxs-lookup"><span data-stu-id="2b056-143">You can use the events on SpatialInteractionManager such as [SourceDetected](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcedetected) and [SourceLost](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcelost), to react when hands enter or leave the device's view, or when motion controllers are turned on/off or are paired/unpaired.</span></span>

### <a name="predicted-vs-historical-poses"></a><span data-ttu-id="2b056-144">Vorhergesagte und Vergangenheits darstellen</span><span class="sxs-lookup"><span data-stu-id="2b056-144">Predicted vs. historical poses</span></span>
<span data-ttu-id="2b056-145">Beachten Sie, dass getdetectedsourcesattimestamp über einen Zeitstempel-Parameter verfügt.</span><span class="sxs-lookup"><span data-stu-id="2b056-145">Note that GetDetectedSourcesAtTimestamp has a timestamp parameter.</span></span> <span data-ttu-id="2b056-146">Dies ermöglicht es Ihnen, den Zustand anzufordern und die vorhergesagten oder Verlaufs Daten darzustellen, sodass Sie räumliche Interaktionen mit anderen Quellen der Eingabe korrelieren können.</span><span class="sxs-lookup"><span data-stu-id="2b056-146">This enables you to request state and pose data that is either predicted or historical, letting you correlate spatial interactions with other sources of input.</span></span> <span data-ttu-id="2b056-147">Wenn Sie z. b. die Position der Hand im aktuellen Frame rendern, können Sie den vorhergesagten Zeitstempel übergeben, der von [holographicframe](https://docs.microsoft.com//uwp/api/windows.graphics.holographic.holographicframe)bereitgestellt wird.</span><span class="sxs-lookup"><span data-stu-id="2b056-147">For example, when rendering the hand's position in the current frame, you can pass in the predicted timestamp provided by the [HolographicFrame](https://docs.microsoft.com//uwp/api/windows.graphics.holographic.holographicframe).</span></span> <span data-ttu-id="2b056-148">Dies ermöglicht es dem System, die Position der Hand an der gerenderten Frame Ausgabe zu weiterleiten und die erkannte Latenz zu minimieren.</span><span class="sxs-lookup"><span data-stu-id="2b056-148">This enables the system to forward-predict the hand position to closely align with the rendered frame output, minimizing perceived latency.</span></span>

<span data-ttu-id="2b056-149">Eine solche vorhergesagte Pose erzeugt jedoch keinen idealen Zeige-Ray für das Ziel einer Interaktions Quelle.</span><span class="sxs-lookup"><span data-stu-id="2b056-149">However, such a predicted pose does not produce an ideal pointing ray for targeting with an interaction source.</span></span> <span data-ttu-id="2b056-150">Wenn z. b. eine Bewegungs Controller Schaltfläche gedrückt wird, kann es bis zu 20 ms dauern, bis das Ereignis durch Bluetooth bis zum Betriebssystem hochskalieren kann.</span><span class="sxs-lookup"><span data-stu-id="2b056-150">For example, when a motion controller button is pressed, it can take up to 20ms for that event to bubble up through Bluetooth to the operating system.</span></span> <span data-ttu-id="2b056-151">Wenn ein Benutzer eine Handbewegung durchführt, kann es auch passieren, dass eine gewisse Zeit verstreichen kann, bevor das System die Geste erkennt, und die APP anschließend abruft.</span><span class="sxs-lookup"><span data-stu-id="2b056-151">Similarly, after a user performs a hand gesture, some amount of time may pass before the system detects the gesture and your app then polls for it.</span></span> <span data-ttu-id="2b056-152">Wenn Ihre APP eine Zustandsänderung abruft, werden die Kopfzeile und die Hand zum Ziel der Interaktion verwendet, die tatsächlich in der Vergangenheit aufgetreten ist.</span><span class="sxs-lookup"><span data-stu-id="2b056-152">By the time your app polls for a state change, the head and hand poses used to target that interaction actually happened in the past.</span></span> <span data-ttu-id="2b056-153">Wenn Sie als Ziel verwenden, indem Sie den Zeitstempel Ihres aktuellen holographicframe-Werts an getdetectedsourcesattimestamp übergeben, wird die Pose stattdessen auf dem Ziel-Ray zum Zeitpunkt der Anzeige des Frames (in der Zukunft mehr als 20 ms) vorhergesagt.</span><span class="sxs-lookup"><span data-stu-id="2b056-153">If you target by passing your current HolographicFrame's timestamp to GetDetectedSourcesAtTimestamp, the pose will instead be forward predicted to the targeting ray at the time the frame will be displayed, which could be more than 20ms in the future.</span></span> <span data-ttu-id="2b056-154">Diese zukünftige Darstellung eignet sich gut zum *Rendern* der Interaktions Quelle, aber sorgt für unser Zeitproblem *für die Interaktion* , da die Zielvorgabe des Benutzers in der Vergangenheit erfolgte.</span><span class="sxs-lookup"><span data-stu-id="2b056-154">This future pose is good for *rendering* the interaction source, but compounds our time problem for *targeting* the interaction, as the user's targeting occurred in the past.</span></span>

<span data-ttu-id="2b056-155">Glücklicherweise stellen die Ereignisse " [sourcepressed](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcepressed)", " [sourcereleasing](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcereleased) " und " [sourceupveralteten](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourceupdated) " den dem jeweiligen Eingabe Ereignis zugeordneten Verlaufs [Status](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourceeventargs.state) bereit.</span><span class="sxs-lookup"><span data-stu-id="2b056-155">Fortunately, the [SourcePressed](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcepressed), [SourceReleased](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcereleased) and [SourceUpdated](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourceupdated) events provide the historical [State](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourceeventargs.state) associated with each input event.</span></span>  <span data-ttu-id="2b056-156">Dies umfasst direkt die von [trygetpointerpose](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.trygetpointerpose)verfügbaren Verlaufs Daten und Handschrift stellen sowie einen historischen [Zeitstempel](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.timestamp) , den Sie an andere APIs übergeben können, um mit diesem Ereignis zu korrelieren.</span><span class="sxs-lookup"><span data-stu-id="2b056-156">This directly includes the historical head and hand poses available through [TryGetPointerPose](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.trygetpointerpose), along with a historical [Timestamp](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.timestamp) that you can pass to other APIs to correlate with this event.</span></span>

<span data-ttu-id="2b056-157">Dies führt zu den folgenden bewährten Vorgehensweisen beim Rendern und als Ziel für die Verwendung von Händen und Controllern jedes Frames:</span><span class="sxs-lookup"><span data-stu-id="2b056-157">That leads to the following best practices when rendering and targeting with hands and controllers each frame:</span></span>
* <span data-ttu-id="2b056-158">Für das **Hand-/controllerrendering** der einzelnen Frames sollte Ihre APP die **Vorwärts Gesagte** Darstellung der einzelnen Interaktions Quellen in der Photonen Zeit des aktuellen Frames **Abfragen** .</span><span class="sxs-lookup"><span data-stu-id="2b056-158">For **hand/controller rendering** each frame, your app should **poll** for the **forward-predicted** pose of each interaction source at the current frame’s photon time.</span></span>  <span data-ttu-id="2b056-159">Sie können alle Interaktions Quellen abrufen, indem Sie [getdetectedsourcesattimestamp](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.getdetectedsourcesattimestamp) jedes Frame aufrufen und den von [holographicframe:: currentvorhersage](https://docs.microsoft.com//uwp/api/windows.graphics.holographic.holographicframe.currentprediction)bereitgestellten vorhergesagten Zeitstempel übergeben.</span><span class="sxs-lookup"><span data-stu-id="2b056-159">You can poll for all interaction sources by calling [GetDetectedSourcesAtTimestamp](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.getdetectedsourcesattimestamp) each frame, passing in the predicted timestamp provided by [HolographicFrame::CurrentPrediction](https://docs.microsoft.com//uwp/api/windows.graphics.holographic.holographicframe.currentprediction).</span></span>
* <span data-ttu-id="2b056-160">Für die Verwendung von **Hand/Controller** , die auf einen Press oder eine Freigabe abzielen, sollte Ihre APP gedrückte/freigegebene **Ereignisse**verarbeiten, und zwar basierend **auf der** Verlaufs Kopfzeile für dieses Ereignis.</span><span class="sxs-lookup"><span data-stu-id="2b056-160">For **hand/controller targeting** upon a press or release, your app should handle pressed/released **events**, raycasting based on the **historical** head or hand pose for that event.</span></span> <span data-ttu-id="2b056-161">Sie erhalten diesen Ziel-Ray, indem Sie das [sourcepressed](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcepressed) -oder [sourcereleasing](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcereleased) -Ereignis verarbeiten, die [State](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourceeventargs.state) -Eigenschaft von den Ereignis Argumenten abrufen und dann die [trygetpointerpose](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.trygetpointerpose) -Methode aufrufen.</span><span class="sxs-lookup"><span data-stu-id="2b056-161">You get this targeting ray by handling the [SourcePressed](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcepressed) or [SourceReleased](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcereleased) event, getting the [State](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourceeventargs.state) property from the event arguments, and then calling its [TryGetPointerPose](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.trygetpointerpose) method.</span></span>

## <a name="cross-device-input-properties"></a><span data-ttu-id="2b056-162">Geräte übergreifende Eingabe Eigenschaften</span><span class="sxs-lookup"><span data-stu-id="2b056-162">Cross-device input properties</span></span>
<span data-ttu-id="2b056-163">Die spatialinteraktionsource-API unterstützt Controller und Hand Verfolgungs Systeme mit einer Vielzahl von Funktionen.</span><span class="sxs-lookup"><span data-stu-id="2b056-163">The SpatialInteractionSource API supports controllers and hand tracking systems with a wide range of capabilities.</span></span> <span data-ttu-id="2b056-164">Eine Reihe dieser Funktionen sind zwischen den Gerätetypen üblich.</span><span class="sxs-lookup"><span data-stu-id="2b056-164">A number of these capabilities are common between device types.</span></span> <span data-ttu-id="2b056-165">Beispielsweise stellen Hand Verfolgungs-und Bewegungs Controller eine SELECT-Aktion und eine 3D-Position bereit.</span><span class="sxs-lookup"><span data-stu-id="2b056-165">For example, hand tracking and motion controllers both provide a 'select' action and a 3D position.</span></span> <span data-ttu-id="2b056-166">Wenn möglich, ordnet die API diese gemeinsamen Funktionen denselben Eigenschaften auf der spatialinteraktionsource zu.</span><span class="sxs-lookup"><span data-stu-id="2b056-166">Wherever possible, the API maps these common capabilities to the same properties on the SpatialInteractionSource.</span></span>  <span data-ttu-id="2b056-167">Dies ermöglicht es Anwendungen, eine breite Palette von Eingabetypen leichter zu unterstützen.</span><span class="sxs-lookup"><span data-stu-id="2b056-167">This enables applications to more easily support a wide range of input types.</span></span> <span data-ttu-id="2b056-168">In der folgenden Tabelle werden die Eigenschaften, die unterstützt werden, und deren Vergleich zwischen Eingabetypen beschrieben.</span><span class="sxs-lookup"><span data-stu-id="2b056-168">The following table describes the properties that are supported, and how they compare across input types.</span></span>

| <span data-ttu-id="2b056-169">Eigenschaft</span><span class="sxs-lookup"><span data-stu-id="2b056-169">Property</span></span> | <span data-ttu-id="2b056-170">Beschreibung</span><span class="sxs-lookup"><span data-stu-id="2b056-170">Description</span></span> | <span data-ttu-id="2b056-171">Bewegungen von hololens (1. Gen)</span><span class="sxs-lookup"><span data-stu-id="2b056-171">HoloLens(1st gen) Gestures</span></span> | <span data-ttu-id="2b056-172">Motion-Controller</span><span class="sxs-lookup"><span data-stu-id="2b056-172">Motion Controllers</span></span> | <span data-ttu-id="2b056-173">Handgelenk</span><span class="sxs-lookup"><span data-stu-id="2b056-173">Articulated Hands</span></span>|
|--- |--- |--- |--- |--- |
| [<span data-ttu-id="2b056-174">Spatialinteraktionsource::**hängkeit**</span><span class="sxs-lookup"><span data-stu-id="2b056-174">SpatialInteractionSource::**Handedness**</span></span>](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsource.handedness) | <span data-ttu-id="2b056-175">Rechts oder Links/Controller.</span><span class="sxs-lookup"><span data-stu-id="2b056-175">Right or left hand / controller.</span></span> | <span data-ttu-id="2b056-176">Nicht unterstützt</span><span class="sxs-lookup"><span data-stu-id="2b056-176">Not Supported</span></span> | <span data-ttu-id="2b056-177">Unterstützt</span><span class="sxs-lookup"><span data-stu-id="2b056-177">Supported</span></span> | <span data-ttu-id="2b056-178">Unterstützt</span><span class="sxs-lookup"><span data-stu-id="2b056-178">Supported</span></span> |
| [<span data-ttu-id="2b056-179">Spatialinteraktionsourcestate::**isselectpressed**</span><span class="sxs-lookup"><span data-stu-id="2b056-179">SpatialInteractionSourceState::**IsSelectPressed**</span></span>](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.isselectpressed) | <span data-ttu-id="2b056-180">Aktueller Zustand der primären Schaltfläche.</span><span class="sxs-lookup"><span data-stu-id="2b056-180">Current state of the primary button.</span></span> | <span data-ttu-id="2b056-181">Luft tippen</span><span class="sxs-lookup"><span data-stu-id="2b056-181">Air Tap</span></span> | <span data-ttu-id="2b056-182">Trigger</span><span class="sxs-lookup"><span data-stu-id="2b056-182">Trigger</span></span> | <span data-ttu-id="2b056-183">Gelockerte Luft tippen (Aufrufe)</span><span class="sxs-lookup"><span data-stu-id="2b056-183">Relaxed Air Tap (upright pinch)</span></span> |
| [<span data-ttu-id="2b056-184">Spatialinteraktionsourcestate::**isfasste**</span><span class="sxs-lookup"><span data-stu-id="2b056-184">SpatialInteractionSourceState::**IsGrasped**</span></span>](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.isgrasped) | <span data-ttu-id="2b056-185">Aktueller Status der Schaltfläche "übernehmen".</span><span class="sxs-lookup"><span data-stu-id="2b056-185">Current state of the grab button.</span></span> | <span data-ttu-id="2b056-186">Nicht unterstützt</span><span class="sxs-lookup"><span data-stu-id="2b056-186">Not Supported</span></span> | <span data-ttu-id="2b056-187">Schaltfläche ""</span><span class="sxs-lookup"><span data-stu-id="2b056-187">Grab button</span></span> | <span data-ttu-id="2b056-188">Ein-oder geschlossene Hand Zeiger</span><span class="sxs-lookup"><span data-stu-id="2b056-188">Pinch or Closed Hand</span></span> |
| [<span data-ttu-id="2b056-189">Spatialinteraktionsourcestate::**ismenupressed**</span><span class="sxs-lookup"><span data-stu-id="2b056-189">SpatialInteractionSourceState::**IsMenuPressed**</span></span>](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.ismenupressed) | <span data-ttu-id="2b056-190">Aktueller Zustand der Menü Schaltfläche.</span><span class="sxs-lookup"><span data-stu-id="2b056-190">Current state of the menu button.</span></span>    | <span data-ttu-id="2b056-191">Nicht unterstützt</span><span class="sxs-lookup"><span data-stu-id="2b056-191">Not Supported</span></span> | <span data-ttu-id="2b056-192">Menü Schaltfläche</span><span class="sxs-lookup"><span data-stu-id="2b056-192">Menu Button</span></span> | <span data-ttu-id="2b056-193">Nicht unterstützt</span><span class="sxs-lookup"><span data-stu-id="2b056-193">Not Supported</span></span> |
| [<span data-ttu-id="2b056-194">Spatialinteraktionsourcelokation::**Position**</span><span class="sxs-lookup"><span data-stu-id="2b056-194">SpatialInteractionSourceLocation::**Position**</span></span>](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourcelocation.position) | <span data-ttu-id="2b056-195">XYZ-Speicherort der Hand-oder Ziehpunkt Position auf dem Controller.</span><span class="sxs-lookup"><span data-stu-id="2b056-195">XYZ location of the hand or grip position on the controller.</span></span> | <span data-ttu-id="2b056-196">Palmen Standort</span><span class="sxs-lookup"><span data-stu-id="2b056-196">Palm location</span></span> | <span data-ttu-id="2b056-197">Position der Zieh Punktposition</span><span class="sxs-lookup"><span data-stu-id="2b056-197">Grip pose position</span></span> | <span data-ttu-id="2b056-198">Palmen Standort</span><span class="sxs-lookup"><span data-stu-id="2b056-198">Palm location</span></span> |
| [<span data-ttu-id="2b056-199">Spatialinteraktionsourcelokation::**Orientation**</span><span class="sxs-lookup"><span data-stu-id="2b056-199">SpatialInteractionSourceLocation::**Orientation**</span></span>](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourcelocation.orientation) | <span data-ttu-id="2b056-200">Die Quaternion, die die Ausrichtung der Hand oder des Zieh Punkts auf dem Controller darstellt.</span><span class="sxs-lookup"><span data-stu-id="2b056-200">Quaternion representing the orientation of the hand or grip pose on the controller.</span></span> | <span data-ttu-id="2b056-201">Nicht unterstützt</span><span class="sxs-lookup"><span data-stu-id="2b056-201">Not Supported</span></span> | <span data-ttu-id="2b056-202">Ziehpunkt Ausrichtung</span><span class="sxs-lookup"><span data-stu-id="2b056-202">Grip pose orientation</span></span> | <span data-ttu-id="2b056-203">Palmen Ausrichtung</span><span class="sxs-lookup"><span data-stu-id="2b056-203">Palm orientation</span></span> |
| [<span data-ttu-id="2b056-204">Spatialpointerinteraktionsourcepose::**Position**</span><span class="sxs-lookup"><span data-stu-id="2b056-204">SpatialPointerInteractionSourcePose::**Position**</span></span>](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialpointerinteractionsourcepose.position#Windows_UI_Input_Spatial_SpatialPointerInteractionSourcePose_Position) | <span data-ttu-id="2b056-205">Ursprung des zeigenden Strahl.</span><span class="sxs-lookup"><span data-stu-id="2b056-205">Origin of the pointing ray.</span></span> | <span data-ttu-id="2b056-206">Nicht unterstützt</span><span class="sxs-lookup"><span data-stu-id="2b056-206">Not Supported</span></span> | <span data-ttu-id="2b056-207">Unterstützt</span><span class="sxs-lookup"><span data-stu-id="2b056-207">Supported</span></span> | <span data-ttu-id="2b056-208">Unterstützt</span><span class="sxs-lookup"><span data-stu-id="2b056-208">Supported</span></span> |
| [<span data-ttu-id="2b056-209">Spatialpointerinteraktionsourcepose::**forwarddirection**</span><span class="sxs-lookup"><span data-stu-id="2b056-209">SpatialPointerInteractionSourcePose::**ForwardDirection**</span></span>](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialpointerinteractionsourcepose.forwarddirection#Windows_UI_Input_Spatial_SpatialPointerInteractionSourcePose_ForwardDirection) | <span data-ttu-id="2b056-210">Richtung des zeigenden Strahls.</span><span class="sxs-lookup"><span data-stu-id="2b056-210">Direction of the pointing ray.</span></span> | <span data-ttu-id="2b056-211">Nicht unterstützt</span><span class="sxs-lookup"><span data-stu-id="2b056-211">Not Supported</span></span> | <span data-ttu-id="2b056-212">Unterstützt</span><span class="sxs-lookup"><span data-stu-id="2b056-212">Supported</span></span> | <span data-ttu-id="2b056-213">Unterstützt</span><span class="sxs-lookup"><span data-stu-id="2b056-213">Supported</span></span> |

<span data-ttu-id="2b056-214">Einige der oben aufgeführten Eigenschaften sind auf allen Geräten nicht verfügbar, und die API bietet eine Möglichkeit, um dies zu testen.</span><span class="sxs-lookup"><span data-stu-id="2b056-214">Some of the above properties are not available on all devices, and the API provides a means to test for this.</span></span> <span data-ttu-id="2b056-215">Beispielsweise können Sie die Eigenschaft [spatialinteraktionsource:: isgrasp unterstützt](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsource.isgraspsupported) überprüfen, um zu bestimmen, ob die Quelle eine vergrauaktion bereitstellt.</span><span class="sxs-lookup"><span data-stu-id="2b056-215">For example, you can inspect the [SpatialInteractionSource::IsGraspSupported](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsource.isgraspsupported) property to determine whether the source provides a grasp action.</span></span>

### <a name="grip-pose-vs-pointing-pose"></a><span data-ttu-id="2b056-216">Ziehpunkt im Vergleich zu Zeige darstellen</span><span class="sxs-lookup"><span data-stu-id="2b056-216">Grip pose vs. pointing pose</span></span>

<span data-ttu-id="2b056-217">Windows Mixed Reality unterstützt Bewegungs Controller in einer Vielzahl von Formfaktoren.</span><span class="sxs-lookup"><span data-stu-id="2b056-217">Windows Mixed Reality supports motion controllers in a variety of form factors.</span></span>  <span data-ttu-id="2b056-218">Sie unterstützt auch die Systeme für die Nachverfolgung von Hand</span><span class="sxs-lookup"><span data-stu-id="2b056-218">It also supports articulated hand tracking systems.</span></span>  <span data-ttu-id="2b056-219">Alle diese Systeme verfügen über unterschiedliche Beziehungen zwischen der Handposition und der natürlichen Vorwärtsrichtung, die apps zum zeigen oder Rendern von Objekten in der Hand verwenden sollten.</span><span class="sxs-lookup"><span data-stu-id="2b056-219">All of these systems have different relationships between the hand position and the natural "forward" direction that apps should use for pointing or rendering objects in the user's hand.</span></span>  <span data-ttu-id="2b056-220">Um dies zu unterstützen, gibt es zwei Arten von 3D-Posen, die sowohl für die Hand Verfolgung als auch für Bewegungs Controller bereitgestellt werden.</span><span class="sxs-lookup"><span data-stu-id="2b056-220">To support all of this, there are two types of 3D poses provided for both hand tracking and motion controllers.</span></span>  <span data-ttu-id="2b056-221">Der erste ist Ziehpunkt, der die Position des Benutzers darstellt.</span><span class="sxs-lookup"><span data-stu-id="2b056-221">The first is grip pose, which represents the user's hand position.</span></span>  <span data-ttu-id="2b056-222">Die zweite zeigt eine Darstellung, die ein zeigendes Strahl darstellt, das aus der Hand oder dem Controller des Benutzers stammt.</span><span class="sxs-lookup"><span data-stu-id="2b056-222">The second is pointing pose, which represents a pointing ray originating from the user's hand or controller.</span></span> <span data-ttu-id="2b056-223">Wenn Sie also **die Hand des Benutzers** oder ein Objekt, das **in der Hand des Benutzers gehalten**wird (z. b. ein Schwert oder eine Waffe), wiedergeben möchten, verwenden Sie die Ziehpunkt-Pose.</span><span class="sxs-lookup"><span data-stu-id="2b056-223">So, if you want to render **the user's hand** or **an object held in the user's hand**, such as a sword or gun, use the grip pose.</span></span> <span data-ttu-id="2b056-224">Wenn Sie einen raycast von Controller oder Hand durchführen möchten, z. b. wenn der Benutzer auf die Benutzer **Oberfläche zeigt** , verwenden Sie die Zeige Pose.</span><span class="sxs-lookup"><span data-stu-id="2b056-224">If you want to raycast from the controller or hand, for example when the user is **pointing at UI** , use the pointing pose.</span></span>

<span data-ttu-id="2b056-225">Sie können auf die Ziehpunkt- **Pose** über [spatialinteraktionsourcestate zugreifen::P roperties:: trygetlocation (...)](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourceproperties.trygetlocation#Windows_UI_Input_Spatial_SpatialInteractionSourceProperties_TryGetLocation_Windows_Perception_Spatial_SpatialCoordinateSystem_).  Es wird wie folgt definiert:</span><span class="sxs-lookup"><span data-stu-id="2b056-225">You can access the **grip pose** through [SpatialInteractionSourceState::Properties::TryGetLocation(...)](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourceproperties.trygetlocation#Windows_UI_Input_Spatial_SpatialInteractionSourceProperties_TryGetLocation_Windows_Perception_Spatial_SpatialCoordinateSystem_).  It is defined as follows:</span></span>
* <span data-ttu-id="2b056-226">Die Zieh **Punktposition**: der Palmen Schwerpunkt bei der natürlichen Aufbewahrung des Controllers, nach links oder rechts, um die Position im Ziehpunkt zu zentrieren.</span><span class="sxs-lookup"><span data-stu-id="2b056-226">The **grip position**: The palm centroid when holding the controller naturally, adjusted left or right to center the position within the grip.</span></span>
* <span data-ttu-id="2b056-227">Die **Rechte Achse**der Ziehpunkt Ausrichtung: Wenn Sie Ihre Hand vollständig geöffnet haben, um eine flache 5-Finger-Darstellung zu bilden, ist das Strahl-Ray, das normal ist (vorwärts von links nach links, rückwärts von rechter Palme).</span><span class="sxs-lookup"><span data-stu-id="2b056-227">The **grip orientation's Right axis**: When you completely open your hand to form a flat 5-finger pose, the ray that is normal to your palm (forward from left palm, backward from right palm)</span></span>
* <span data-ttu-id="2b056-228">Die **Forward-Achse**der Ziehpunkt Ausrichtung: Wenn Sie die Hand teilweise schließen (wie beim Halten des Controllers), wird der Strahl, der durch das durch ihre nicht-Thumb-Finger formatierte Rohr auf "Vorwärts" zeigt.</span><span class="sxs-lookup"><span data-stu-id="2b056-228">The **grip orientation's Forward axis**: When you close your hand partially (as if holding the controller), the ray that points "forward" through the tube formed by your non-thumb fingers.</span></span>
* <span data-ttu-id="2b056-229">Die **aufwärts Achse**der Ziehpunkt Ausrichtung: die aufwärts Achse, die durch die Rechte-und vorwärts Definitionen impliziert wird.</span><span class="sxs-lookup"><span data-stu-id="2b056-229">The **grip orientation's Up axis**: The Up axis implied by the Right and Forward definitions.</span></span>

<span data-ttu-id="2b056-230">Sie können auf die **Zeiger Pose** über [spatialinteraktionsourcestate zugreifen::P roperties:: trygetlocation (...):: sourcepointerpose](https://docs.microsoft.com/uwp/api/windows.ui.input.spatial.spatialinteractionsourcelocation#Windows_UI_Input_Spatial_SpatialInteractionSourceLocation_SourcePointerPose) oder [spatialinteraktionsourcestate:: trygetpointerpose (...):: trygetinteraktionsourcepose](https://docs.microsoft.com/uwp/api/windows.ui.input.spatial.spatialpointerpose#Windows_UI_Input_Spatial_SpatialPointerPose_TryGetInteractionSourcePose_Windows_UI_Input_Spatial_SpatialInteractionSource_).</span><span class="sxs-lookup"><span data-stu-id="2b056-230">You can access the **pointer pose** through [SpatialInteractionSourceState::Properties::TryGetLocation(...)::SourcePointerPose](https://docs.microsoft.com/uwp/api/windows.ui.input.spatial.spatialinteractionsourcelocation#Windows_UI_Input_Spatial_SpatialInteractionSourceLocation_SourcePointerPose) or [SpatialInteractionSourceState::TryGetPointerPose(...)::TryGetInteractionSourcePose](https://docs.microsoft.com/uwp/api/windows.ui.input.spatial.spatialpointerpose#Windows_UI_Input_Spatial_SpatialPointerPose_TryGetInteractionSourcePose_Windows_UI_Input_Spatial_SpatialInteractionSource_).</span></span>

## <a name="controller-specific-input-properties"></a><span data-ttu-id="2b056-231">Controller spezifische Eingabe Eigenschaften</span><span class="sxs-lookup"><span data-stu-id="2b056-231">Controller-specific input properties</span></span>
<span data-ttu-id="2b056-232">Für Controller verfügt spatialinteraktionsource über eine Controller Eigenschaft mit zusätzlichen Funktionen.</span><span class="sxs-lookup"><span data-stu-id="2b056-232">For controllers, the SpatialInteractionSource has a Controller property with additional capabilities.</span></span>
* <span data-ttu-id="2b056-233">**Hasthumbstick:** True gibt an, dass der Controller über einen Finger Stick verfügt.</span><span class="sxs-lookup"><span data-stu-id="2b056-233">**HasThumbstick:** If true, the controller has a thumbstick.</span></span> <span data-ttu-id="2b056-234">Überprüfen Sie die [controllerproperties](https://docs.microsoft.com/uwp/api/windows.ui.input.spatial.spatialinteractioncontrollerproperties) -Eigenschaft des spatialinteraction SourceState-Objekts, um die x-und y-Werte des Finger Anrufs (thumbstickx und thumbthumb) sowie den gedrückten Zustand (isthumbstickpressed) abzurufen.</span><span class="sxs-lookup"><span data-stu-id="2b056-234">Inspect the [ControllerProperties](https://docs.microsoft.com/uwp/api/windows.ui.input.spatial.spatialinteractioncontrollerproperties) property of the SpatialInteractionSourceState to acquire the thumbstick x and y values (ThumbstickX and ThumbstickY), as well as its pressed state (IsThumbstickPressed).</span></span>
* <span data-ttu-id="2b056-235">**Hastouchpad:** True gibt an, dass der Controller über einen Touchpad verfügt.</span><span class="sxs-lookup"><span data-stu-id="2b056-235">**HasTouchpad:** If true, the controller has a touchpad.</span></span> <span data-ttu-id="2b056-236">Überprüfen Sie die controllerproperties-Eigenschaft von spatialinteraction SourceState, um die Touchpad x-und y-Werte (touchpadx und touchpady) abzurufen und um zu ermitteln, ob der Benutzer den Pad berührt (istouchpadtoud) und ob er das Touchpad nach unten drückt ( Istouchpadpressed).</span><span class="sxs-lookup"><span data-stu-id="2b056-236">Inspect the ControllerProperties property of the SpatialInteractionSourceState to acquire the touchpad x and y values (TouchpadX and TouchpadY), and to know if the user is touching the pad (IsTouchpadTouched) and if they are pressing the touchpad down (IsTouchpadPressed).</span></span>
* <span data-ttu-id="2b056-237">**Simplehapticscontroller:** Die simplehapticscontroller-API für den Controller ermöglicht es Ihnen, die Haptik Funktionen des Controllers zu überprüfen. Außerdem können Sie das haptische Feedback steuern.</span><span class="sxs-lookup"><span data-stu-id="2b056-237">**SimpleHapticsController:** The SimpleHapticsController API for the controller allows you to inspect the haptics capabilities of the controller, and it also allows you to control haptic feedback.</span></span>

<span data-ttu-id="2b056-238">Beachten Sie, dass der Bereich für Touchpad und Ministick für beide Achsen-1 bis 1 ist (von unten nach oben und von links nach rechts).</span><span class="sxs-lookup"><span data-stu-id="2b056-238">Note that the range for touchpad and thumbstick is -1 to 1 for both axes (from bottom to top, and from left to right).</span></span> <span data-ttu-id="2b056-239">Der Bereich für den analogen-Auslösers, auf den mit der spatialinteraktionsourcestate:: selectpressedvalue-Eigenschaft zugegriffen wird, weist einen Bereich von 0 bis 1 auf.</span><span class="sxs-lookup"><span data-stu-id="2b056-239">The range for the analog trigger, which is accessed using the SpatialInteractionSourceState::SelectPressedValue property, has a range of 0 to 1.</span></span> <span data-ttu-id="2b056-240">Der Wert 1 korreliert mit isselectpressed, das gleich true ist. alle anderen Werte korrelieren mit isselectpressed, das gleich false ist.</span><span class="sxs-lookup"><span data-stu-id="2b056-240">A value of 1 correlates with IsSelectPressed being equal to true; any other value correlates with IsSelectPressed being equal to false.</span></span>

## <a name="articulated-hand-tracking"></a><span data-ttu-id="2b056-241">Handgelenk Verfolgung</span><span class="sxs-lookup"><span data-stu-id="2b056-241">Articulated hand tracking</span></span>
<span data-ttu-id="2b056-242">Die Windows Mixed Reality-API bietet vollständige Unterstützung für die Weitergabe von Handgelenk, z. b. auf hololens 2.</span><span class="sxs-lookup"><span data-stu-id="2b056-242">The Windows Mixed Reality API provides full support for articulated hand tracking, for example on HoloLens 2.</span></span> <span data-ttu-id="2b056-243">Die Handschrift Nachverfolgung kann verwendet werden, um direkte Manipulations-und Punkt-und Commit-Eingabe Modelle in Ihren Anwendungen zu implementieren.</span><span class="sxs-lookup"><span data-stu-id="2b056-243">Articulated hand tracking can be used to implement direct manipulation and point-and-commit input models in your applications.</span></span> <span data-ttu-id="2b056-244">Sie kann auch zum Erstellen vollständig benutzerdefinierter Interaktionen verwendet werden.</span><span class="sxs-lookup"><span data-stu-id="2b056-244">It can also be used to author fully custom interactions.</span></span>

### <a name="hand-skeleton"></a><span data-ttu-id="2b056-245">Hand Gerüst</span><span class="sxs-lookup"><span data-stu-id="2b056-245">Hand skeleton</span></span>
<span data-ttu-id="2b056-246">Die gemischte Nachverfolgung bietet ein 25-Gerüst Gerüst, das viele verschiedene Arten von Interaktionen ermöglicht.</span><span class="sxs-lookup"><span data-stu-id="2b056-246">Articulated hand tracking provides a 25 joint skeleton that enables many different types of interactions.</span></span>  <span data-ttu-id="2b056-247">Das Gerüst bietet fünf Gelenke für den Index/den Mittelwert bzw. Ring/kleine Finger, vier Gelenke für den Ziehpunkt und 1 Gelenk Gelenk.</span><span class="sxs-lookup"><span data-stu-id="2b056-247">The skeleton provides 5 joints for the index/middle/ring/little fingers, 4 joints for the thumb, and 1 wrist joint.</span></span>  <span data-ttu-id="2b056-248">Das gemischte Gelenk fungiert als Basis der Hierarchie.</span><span class="sxs-lookup"><span data-stu-id="2b056-248">The wrist joint serves as the base of the hierarchy.</span></span> <span data-ttu-id="2b056-249">Das folgende Bild veranschaulicht das Layout des Skeleton.</span><span class="sxs-lookup"><span data-stu-id="2b056-249">The following picture illustrates the layout of the skeleton.</span></span>

![Hand Gerüst](images/hand-skeleton.png)

<span data-ttu-id="2b056-251">In den meisten Fällen wird jedes Joint auf der Grundlage des von ihm dargestellten Knochens benannt.</span><span class="sxs-lookup"><span data-stu-id="2b056-251">In most cases, each joint is named based on the bone that it represents.</span></span>  <span data-ttu-id="2b056-252">Da bei jedem Joint zwei gedankenfelder vorhanden sind, verwenden wir eine Konvention, die jedes Joint-Element auf der Grundlage des untergeordneten knotes an diesem Speicherort zu benennen.</span><span class="sxs-lookup"><span data-stu-id="2b056-252">Since there are two bones at every joint, we use a convention of naming each joint based on the child bone at that location.</span></span>  <span data-ttu-id="2b056-253">Der untergeordnete Knochen ist als der Knochen weiter vom Handgelenk definiert.</span><span class="sxs-lookup"><span data-stu-id="2b056-253">The child bone is defined as the bone further from the wrist.</span></span>  <span data-ttu-id="2b056-254">Beispielsweise enthält die Zusammenstellung "Index proximal" die Anfangsposition des Index "proximal" und die Ausrichtung dieses Knochens.</span><span class="sxs-lookup"><span data-stu-id="2b056-254">For example, the "Index Proximal" joint contains the beginning position of the index proximal bone, and the orientation of that bone.</span></span>  <span data-ttu-id="2b056-255">Die Endposition des-Knochens ist nicht enthalten.</span><span class="sxs-lookup"><span data-stu-id="2b056-255">It does not contain the ending position of the bone.</span></span>  <span data-ttu-id="2b056-256">Wenn Sie diese benötigen, erhalten Sie diese vom nächsten gemeinsamen Zusammenhang in der Hierarchie, dem "Index Intermediate"-Joint.</span><span class="sxs-lookup"><span data-stu-id="2b056-256">If you need that, you'd get it from the next joint in the hierarchy, the "Index Intermediate" joint.</span></span>

<span data-ttu-id="2b056-257">Zusätzlich zu den 25 hierarchischen Gelenken bietet das System eine Palmen Verbindung.</span><span class="sxs-lookup"><span data-stu-id="2b056-257">In addition to the 25 hierarchical joints, the system provides a palm joint.</span></span>  <span data-ttu-id="2b056-258">Die Palme wird in der Regel nicht als Teil der Skelettstruktur betrachtet.</span><span class="sxs-lookup"><span data-stu-id="2b056-258">The palm is not typically considered part of the skeletal structure.</span></span>  <span data-ttu-id="2b056-259">Sie wird nur als bequeme Möglichkeit zur Verfügung gestellt, um die allgemeine Position und Ausrichtung der Hand zu erhalten.</span><span class="sxs-lookup"><span data-stu-id="2b056-259">It is provided only as a convenient way to get the hand's overall position and orientation.</span></span>

<span data-ttu-id="2b056-260">Die folgenden Informationen werden für jedes Joint bereitgestellt:</span><span class="sxs-lookup"><span data-stu-id="2b056-260">The following information is provided for each joint:</span></span>

| <span data-ttu-id="2b056-261">Name</span><span class="sxs-lookup"><span data-stu-id="2b056-261">Name</span></span> | <span data-ttu-id="2b056-262">Beschreibung</span><span class="sxs-lookup"><span data-stu-id="2b056-262">Description</span></span> |
|--- |--- |
|<span data-ttu-id="2b056-263">Position</span><span class="sxs-lookup"><span data-stu-id="2b056-263">Position</span></span> | <span data-ttu-id="2b056-264">3D-Position des gemeinsamen, in jedem angeforderten Koordinatensystem verfügbar.</span><span class="sxs-lookup"><span data-stu-id="2b056-264">3D position of the joint, available in any requested coordinate system.</span></span> |
|<span data-ttu-id="2b056-265">Ausrichtung</span><span class="sxs-lookup"><span data-stu-id="2b056-265">Orientation</span></span> | <span data-ttu-id="2b056-266">3D-Ausrichtung des in jedem angeforderten Koordinatensystem verfügbaren knotes.</span><span class="sxs-lookup"><span data-stu-id="2b056-266">3D orientation of the bone, available in any requested coordinate system.</span></span> |
|<span data-ttu-id="2b056-267">Radius</span><span class="sxs-lookup"><span data-stu-id="2b056-267">Radius</span></span> | <span data-ttu-id="2b056-268">Abstand zur Oberfläche der Skin an der gemeinsamen Position.</span><span class="sxs-lookup"><span data-stu-id="2b056-268">Distance to surface of the skin at the joint position.</span></span> <span data-ttu-id="2b056-269">Nützlich für das optimieren direkter Interaktionen oder Visualisierungen, die auf der fingerbreite basieren.</span><span class="sxs-lookup"><span data-stu-id="2b056-269">Useful for tuning direct interactions or visualizations that rely on finger width.</span></span> |
|<span data-ttu-id="2b056-270">Genauigkeit</span><span class="sxs-lookup"><span data-stu-id="2b056-270">Accuracy</span></span> | <span data-ttu-id="2b056-271">Gibt Aufschluss darüber, wie sicher das System über diese gemeinsamen Informationen verfügt.</span><span class="sxs-lookup"><span data-stu-id="2b056-271">Provides a hint on how confident the system feels about this joint's information.</span></span> |

<span data-ttu-id="2b056-272">Sie können auf die Hand Skeleton-Daten über eine Funktion auf dem [spatialinteraktionsourcestate](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate)zugreifen.</span><span class="sxs-lookup"><span data-stu-id="2b056-272">You can access the hand skeleton data through a function on the [SpatialInteractionSourceState](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate).</span></span>  <span data-ttu-id="2b056-273">Die Funktion heißt [trygethandpose](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.trygethandpose#Windows_UI_Input_Spatial_SpatialInteractionSourceState_TryGetHandPose)und gibt ein Objekt mit dem Namen [handpose](https://docs.microsoft.com//uwp/api/windows.perception.people.handpose)zurück.</span><span class="sxs-lookup"><span data-stu-id="2b056-273">The function is called [TryGetHandPose](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.trygethandpose#Windows_UI_Input_Spatial_SpatialInteractionSourceState_TryGetHandPose), and it returns an object called [HandPose](https://docs.microsoft.com//uwp/api/windows.perception.people.handpose).</span></span>  <span data-ttu-id="2b056-274">Wenn die Quelle keine Handgelenk Zeichen unterstützt, gibt diese Funktion NULL zurück.</span><span class="sxs-lookup"><span data-stu-id="2b056-274">If the source does not support articulated hands, then this function will return null.</span></span>  <span data-ttu-id="2b056-275">Sobald Sie über eine Hand Pose verfügen, können Sie aktuelle gemeinsame Daten abrufen, indem Sie [trygetjoint](https://docs.microsoft.com//uwp/api/windows.perception.people.handpose.trygetjoint#Windows_Perception_People_HandPose_TryGetJoint_Windows_Perception_Spatial_SpatialCoordinateSystem_Windows_Perception_People_HandJointKind_Windows_Perception_People_JointPose__)mit dem Namen der zusammenhängenden aufrufen, an der Sie interessiert sind.</span><span class="sxs-lookup"><span data-stu-id="2b056-275">Once you have a HandPose, you can get current joint data by calling [TryGetJoint](https://docs.microsoft.com//uwp/api/windows.perception.people.handpose.trygetjoint#Windows_Perception_People_HandPose_TryGetJoint_Windows_Perception_Spatial_SpatialCoordinateSystem_Windows_Perception_People_HandJointKind_Windows_Perception_People_JointPose__), with the name of the joint you are interested in.</span></span>  <span data-ttu-id="2b056-276">Die Daten werden als [jointpose](https://docs.microsoft.com//uwp/api/windows.perception.people.jointpose) -Struktur zurückgegeben.</span><span class="sxs-lookup"><span data-stu-id="2b056-276">The data is returned as a [JointPose](https://docs.microsoft.com//uwp/api/windows.perception.people.jointpose) structure.</span></span>  <span data-ttu-id="2b056-277">Der folgende Code Ruft die Position des Finger Abbilds für den Index ab.</span><span class="sxs-lookup"><span data-stu-id="2b056-277">The following code gets the position of the index finger tip.</span></span> <span data-ttu-id="2b056-278">Die Variable *CurrentState* stellt eine Instanz von [spatialinteraktionsourcestate](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate)dar.</span><span class="sxs-lookup"><span data-stu-id="2b056-278">The variable *currentState* represents an instance of [SpatialInteractionSourceState](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate).</span></span>

```cpp
using namespace winrt::Windows::Perception::People;
using namespace winrt::Windows::Foundation::Numerics;

auto handPose = currentState.TryGetHandPose();
if (handPose)
{
    JointPose joint;
    if (handPose.TryGetJoint(desiredCoordinateSystem, HandJointKind::IndexTip, joint))
    {
        float3 indexTipPosition = joint.Position;

        // Do something with the index tip position
    }
}
```

### <a name="hand-mesh"></a><span data-ttu-id="2b056-279">Hand Netz</span><span class="sxs-lookup"><span data-stu-id="2b056-279">Hand mesh</span></span>

<span data-ttu-id="2b056-280">Die API für die Nachverfolgung von Handschriften ermöglicht ein vollständig zu entformbares Dreieck-Mesh-Mesh.</span><span class="sxs-lookup"><span data-stu-id="2b056-280">The articulated hand tracking API allows for a fully deformable triangle hand mesh.</span></span>  <span data-ttu-id="2b056-281">Dieses Mesh kann sich zusammen mit dem Hand Gerüst in Echtzeit deformen und eignet sich für die Visualisierung sowie erweiterte Physik Techniken.</span><span class="sxs-lookup"><span data-stu-id="2b056-281">This mesh can deform in real time along with the hand skeleton, and is useful for visualization as well as advanced physics techniques.</span></span>  <span data-ttu-id="2b056-282">Um auf das Hand Mesh zuzugreifen, müssen Sie zuerst ein [handmeshobserver](https://docs.microsoft.com//uwp/api/windows.perception.people.handmeshobserver) -Objekt erstellen, indem Sie [trycreatehandmeshobserverasync](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsource.trycreatehandmeshobserverasync) auf der [spatialinteraktionsource](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsource)aufrufen.</span><span class="sxs-lookup"><span data-stu-id="2b056-282">To access the hand mesh, you need to first create a [HandMeshObserver](https://docs.microsoft.com//uwp/api/windows.perception.people.handmeshobserver) object by calling [TryCreateHandMeshObserverAsync](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsource.trycreatehandmeshobserverasync) on the [SpatialInteractionSource](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsource).</span></span>  <span data-ttu-id="2b056-283">Dies muss nur einmal pro Quelle erfolgen, normalerweise wenn Sie das erste Mal sehen.</span><span class="sxs-lookup"><span data-stu-id="2b056-283">This only needs to be done once per source, typically the first time you see it.</span></span>  <span data-ttu-id="2b056-284">Das heißt, Sie rufen diese Funktion auf, um ein handmeshobserver-Objekt zu erstellen, wenn eine Hand in den FOV gelangt.</span><span class="sxs-lookup"><span data-stu-id="2b056-284">That means you'll call this function to create a HandMeshObserver object whenever a hand enters the FOV.</span></span>  <span data-ttu-id="2b056-285">Beachten Sie, dass es sich hierbei um eine asynchrone Funktion handelt, sodass Sie hier ein bisschen Parallelität behandeln müssen.</span><span class="sxs-lookup"><span data-stu-id="2b056-285">Note that this is an async function, so you'll have to deal with a bit of concurrency here.</span></span>  <span data-ttu-id="2b056-286">Sobald Sie verfügbar sind, können Sie das handmeshobserver-Objekt für den Dreiecks Index Puffer durch Aufrufen von [gettriangleindices](https://docs.microsoft.com//uwp/api/windows.perception.people.handmeshobserver.gettriangleindices#Windows_Perception_People_HandMeshObserver_GetTriangleIndices_System_UInt16___)Abfragen.</span><span class="sxs-lookup"><span data-stu-id="2b056-286">Once available, you can ask the HandMeshObserver object for the triangle index buffer by calling [GetTriangleIndices](https://docs.microsoft.com//uwp/api/windows.perception.people.handmeshobserver.gettriangleindices#Windows_Perception_People_HandMeshObserver_GetTriangleIndices_System_UInt16___).</span></span>  <span data-ttu-id="2b056-287">Indizes ändern den Frame nicht über Frame, sodass Sie diese einmal erhalten und für die Lebensdauer der Quelle Zwischenspeichern können.</span><span class="sxs-lookup"><span data-stu-id="2b056-287">Indices don't change frame over frame, so you can get those once and cache them for the lifetime of the source.</span></span>  <span data-ttu-id="2b056-288">Indizes werden in der Reihenfolge im Uhrzeigersinn bereitgestellt.</span><span class="sxs-lookup"><span data-stu-id="2b056-288">Indices are provided in clockwise winding order.</span></span>

<span data-ttu-id="2b056-289">Der folgende Code startet einen getrennten Std:: Thread, um den Mesh-Beobachter zu erstellen, und extrahiert den Index Puffer, sobald der Mesh-Beobachter verfügbar ist.</span><span class="sxs-lookup"><span data-stu-id="2b056-289">The following code spins up a detached std::thread to create the mesh observer and extracts the index buffer once the mesh observer is available.</span></span>  <span data-ttu-id="2b056-290">Sie beginnt mit einer Variablen namens *CurrentState*, bei der es sich um eine Instanz von [spatialinteraktionsourcestate](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate) handelt, die eine nach verfolgte Hand darstellt.</span><span class="sxs-lookup"><span data-stu-id="2b056-290">It starts from a variable called *currentState*, which is an instance of [SpatialInteractionSourceState](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate) representing a tracked hand.</span></span>

```cpp
using namespace Windows::Perception::People;

std::thread createObserverThread([this, currentState]()
{
    HandMeshObserver newHandMeshObserver = currentState.Source().TryCreateHandMeshObserverAsync().get();
    if (newHandMeshObserver)
    {
        unsigned indexCount = newHandMeshObserver.TriangleIndexCount();
        vector<unsigned short> indices(indexCount);
        newHandMeshObserver.GetTriangleIndices(indices);

        // Save the indices and handMeshObserver for later use - and use a mutex to synchronize access if needed!
     }
});
createObserverThread.detach();
```
<span data-ttu-id="2b056-291">Das Starten eines getrennten Threads ist nur eine Option für die Behandlung von asynchronen Aufrufen.</span><span class="sxs-lookup"><span data-stu-id="2b056-291">Starting a detached thread is just one option for handling async calls.</span></span>  <span data-ttu-id="2b056-292">Alternativ dazu können Sie die neue von [](https://docs.microsoft.com//windows/uwp/cpp-and-winrt-apis/concurrency) C++/WinRT. unterstützte co_await Funktionalität verwenden.</span><span class="sxs-lookup"><span data-stu-id="2b056-292">Alternatively, you could use the new [co_await](https://docs.microsoft.com//windows/uwp/cpp-and-winrt-apis/concurrency) functionality supported by C++/WinRT.</span></span>

<span data-ttu-id="2b056-293">Wenn Sie über ein handmeshobserver-Objekt verfügen, sollten Sie es für die Dauer aufbewahren, in der die zugehörige spatialinteraktionsource aktiv ist.</span><span class="sxs-lookup"><span data-stu-id="2b056-293">Once you have a HandMeshObserver object, you should hold onto it for the duration that its corresponding SpatialInteractionSource is active.</span></span>  <span data-ttu-id="2b056-294">Anschließend können Sie den einzelnen Frame aufrufen, um den aktuellen Vertex-Puffer zu Fragen, der die Hand darstellt, indem Sie [getvertexstateforpose](https://docs.microsoft.com//uwp/api/windows.perception.people.handmeshobserver.getvertexstateforpose) aufrufen und eine [handpose](https://docs.microsoft.com//uwp/api/windows.perception.people.handpose) -Instanz übergeben, die die Darstellung darstellt, für die Sie Vertices wünschen.</span><span class="sxs-lookup"><span data-stu-id="2b056-294">Then each frame, you can ask it for the latest vertex buffer that represents the hand by calling [GetVertexStateForPose](https://docs.microsoft.com//uwp/api/windows.perception.people.handmeshobserver.getvertexstateforpose) and passing in a [HandPose](https://docs.microsoft.com//uwp/api/windows.perception.people.handpose) instance that represents the pose that you want vertices for.</span></span>  <span data-ttu-id="2b056-295">Jeder Scheitelpunkt im Puffer hat eine Position und einen normalen.</span><span class="sxs-lookup"><span data-stu-id="2b056-295">Each vertex in the buffer has a position and a normal.</span></span>  <span data-ttu-id="2b056-296">Im folgenden finden Sie ein Beispiel dafür, wie Sie den aktuellen Satz von Scheitel Punkten für ein Hand Mesh erhalten.</span><span class="sxs-lookup"><span data-stu-id="2b056-296">Here's an example of how to get the current set of vertices for a hand mesh.</span></span>  <span data-ttu-id="2b056-297">Ebenso wie zuvor stellt die *CurrentState* -Variable eine Instanz von [spatialinteraktionsourcestate](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate)dar.</span><span class="sxs-lookup"><span data-stu-id="2b056-297">Just as before, the *currentState* variable represents an instance of [SpatialInteractionSourceState](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate).</span></span>

```cpp
using namespace winrt::Windows::Perception::People;

auto handPose = currentState.TryGetHandPose();
if (handPose)
{
    std::vector<HandMeshVertex> vertices(handMeshObserver.VertexCount());
    auto vertexState = handMeshObserver.GetVertexStateForPose(handPose);
    vertexState.GetVertices(vertices);

    auto meshTransform = vertexState.CoordinateSystem().TryGetTransformTo(desiredCoordinateSystem);
    if (meshTransform != nullptr)
    {
        // Do something with the vertices and mesh transform, along with the indices that you saved earlier
    }
}
```

<span data-ttu-id="2b056-298">Im Gegensatz zu Skelett Gelenken lässt die Hand Mesh-API nicht zu, dass Sie ein Koordinatensystem für die Scheitel Punkte angeben.</span><span class="sxs-lookup"><span data-stu-id="2b056-298">In contrast to skeleton joints, the hand mesh API does not allow you to specify a coordinate system for the vertices.</span></span>  <span data-ttu-id="2b056-299">Stattdessen gibt der [handmeshvertexstate](https://docs.microsoft.com//uwp/api/windows.perception.people.handmeshvertexstate) das Koordinatensystem an, in dem die Vertices bereitgestellt werden.</span><span class="sxs-lookup"><span data-stu-id="2b056-299">Instead, the [HandMeshVertexState](https://docs.microsoft.com//uwp/api/windows.perception.people.handmeshvertexstate) specifies the coordinate system that the vertices are provided in.</span></span>  <span data-ttu-id="2b056-300">Sie können dann eine Mesh-Transformation abrufen, indem Sie [trygettransformto](https://docs.microsoft.com//uwp/api/windows.perception.spatial.spatialcoordinatesystem.trygettransformto#Windows_Perception_Spatial_SpatialCoordinateSystem_TryGetTransformTo_Windows_Perception_Spatial_SpatialCoordinateSystem_) aufrufen und das gewünschte Koordinatensystem angeben.</span><span class="sxs-lookup"><span data-stu-id="2b056-300">You can then get a mesh transform by calling [TryGetTransformTo](https://docs.microsoft.com//uwp/api/windows.perception.spatial.spatialcoordinatesystem.trygettransformto#Windows_Perception_Spatial_SpatialCoordinateSystem_TryGetTransformTo_Windows_Perception_Spatial_SpatialCoordinateSystem_) and specifying your desired coordinate system.</span></span>  <span data-ttu-id="2b056-301">Sie müssen diese Mesh-Transformation verwenden, wenn Sie mit den Scheitel Punkten arbeiten.</span><span class="sxs-lookup"><span data-stu-id="2b056-301">You'll need to use this mesh transform whenever you work with the vertices.</span></span>  <span data-ttu-id="2b056-302">Dieser Ansatz reduziert den CPU-Overhead, insbesondere dann, wenn Sie nur das Mesh für renderingzwecke verwenden.</span><span class="sxs-lookup"><span data-stu-id="2b056-302">This approach reduces CPU overhead, especially if you are only using the mesh for rendering purposes.</span></span>

## <a name="gaze-and-commit-composite-gestures"></a><span data-ttu-id="2b056-303">Zusammengesetzte Gesten durchschauen und Commit</span><span class="sxs-lookup"><span data-stu-id="2b056-303">Gaze and Commit composite gestures</span></span>
<span data-ttu-id="2b056-304">Für Anwendungen, die das "Blick-und Commit"-Eingabe Modell verwenden, insbesondere in hololens (erste Generation), bietet die räumliche Eingabe-API einen optionalen [spatialgesturerecognizer](https://msdn.microsoft.com/library/windows/apps/windows.ui.input.spatial.spatialgesturerecognizer.aspx) , der verwendet werden kann, um zusammengesetzte Gesten zu aktivieren, die auf dem "Select"-Ereignis basieren.</span><span class="sxs-lookup"><span data-stu-id="2b056-304">For applications using the gaze-and-commit input model, particularly on HoloLens (first gen), the Spatial Input API provides an optional [SpatialGestureRecognizer](https://msdn.microsoft.com/library/windows/apps/windows.ui.input.spatial.spatialgesturerecognizer.aspx) that can be used to to enable composite gestures built on top of the 'select' event.</span></span>  <span data-ttu-id="2b056-305">Durch die Weiterleitung von Interaktionen zwischen spatialinteraktionmanager und dem spatialgesturerecognizer eines holograms können apps Tap-, Hold-, Bearbeitungs-und Navigations Ereignisse gleichmäßig über die Hand-, sprach-und räumliche Eingabegeräte hinweg erkennen, ohne dass die Pressen behandelt werden müssen. und werden manuell freigegeben.</span><span class="sxs-lookup"><span data-stu-id="2b056-305">By routing interactions from the SpatialInteractionManager to a hologram's SpatialGestureRecognizer, apps can detect Tap, Hold, Manipulation, and Navigation events uniformly across hands, voice, and spatial input devices, without having to handle presses and releases manually.</span></span>

<span data-ttu-id="2b056-306">Spatialgesturerecognizer führt nur die minimale Eindeutigkeit zwischen dem Satz von Gesten aus, den Sie anfordern.</span><span class="sxs-lookup"><span data-stu-id="2b056-306">SpatialGestureRecognizer performs only the minimal disambiguation between the set of gestures that you request.</span></span> <span data-ttu-id="2b056-307">Wenn Sie z. b. "nur tippen" anfordern, kann der Benutzer den Finger so lange herunterhalten, wie er aussieht, und es tritt immer noch ein tippen auf.</span><span class="sxs-lookup"><span data-stu-id="2b056-307">For example, if you request just Tap, the user may hold their finger down as long as they like and a Tap will still occur.</span></span> <span data-ttu-id="2b056-308">Wenn Sie sowohl Tippen als auch halten anfordern, wird die Stift Bewegung nach ungefähr einer Sekunde angehalten, und es wird kein Tippen mehr angezeigt.</span><span class="sxs-lookup"><span data-stu-id="2b056-308">If you request both Tap and Hold, after about a second of holding down their finger, the gesture will promote to a Hold and a Tap will no longer occur.</span></span>

<span data-ttu-id="2b056-309">Wenn Sie spatialgesturerecognizer verwenden möchten, behandeln Sie das [interaktionerkannte](https://msdn.microsoft.com/library/windows/apps/xaml/Windows.UI.Input.Spatial.SpatialInteractionManager.InteractionDetected) -Ereignis von spatialinteraktionmanager, und rufen Sie das dort verfügbare spatialpointerpose-Element ab.</span><span class="sxs-lookup"><span data-stu-id="2b056-309">To use SpatialGestureRecognizer, handle the SpatialInteractionManager's [InteractionDetected](https://msdn.microsoft.com/library/windows/apps/xaml/Windows.UI.Input.Spatial.SpatialInteractionManager.InteractionDetected) event and grab the SpatialPointerPose exposed there.</span></span> <span data-ttu-id="2b056-310">Verwenden Sie den Head-Gaze-Strahl des Benutzers aus dieser Pose, um sich mit den Hologrammen und Oberflächen Netzen in der Benutzerumgebung auszutauschen, um zu bestimmen, mit welchem Benutzer interagiert werden soll.</span><span class="sxs-lookup"><span data-stu-id="2b056-310">Use the user's head gaze ray from this pose to intersect with the holograms and surface meshes in the user's surroundings, in order to determine what the user is intending to interact with.</span></span> <span data-ttu-id="2b056-311">Leiten Sie dann die spatialinteraktion in den Ereignis Argumenten an den spatialgesturerecognizer des Ziel-Hologramms weiter, indem Sie die zugehörige [captureinteraktions](https://msdn.microsoft.com/library/windows/apps/xaml/Windows.UI.Input.Spatial.SpatialGestureRecognizer.CaptureInteraction) -Methode verwenden.</span><span class="sxs-lookup"><span data-stu-id="2b056-311">Then, route the SpatialInteraction in the event arguments to the target hologram's SpatialGestureRecognizer, using its [CaptureInteraction](https://msdn.microsoft.com/library/windows/apps/xaml/Windows.UI.Input.Spatial.SpatialGestureRecognizer.CaptureInteraction) method.</span></span> <span data-ttu-id="2b056-312">Dies beginnt mit der Interpretation dieser Interaktion gemäß der [spatialgesturesettings-Einstellung](https://msdn.microsoft.com/library/windows/apps/xaml/Windows.UI.Input.Spatial.SpatialGestureSettings) , die bei der Erstellungszeit für diese Erkennung festgelegt wurde, oder durch [trysetgesturesettings](https://msdn.microsoft.com/library/windows/apps/xaml/Windows.UI.Input.Spatial.SpatialGestureRecognizer.TrySetGestureSettings).</span><span class="sxs-lookup"><span data-stu-id="2b056-312">This starts interpreting that interaction according to the [SpatialGestureSettings](https://msdn.microsoft.com/library/windows/apps/xaml/Windows.UI.Input.Spatial.SpatialGestureSettings) set on that recognizer at creation time - or by [TrySetGestureSettings](https://msdn.microsoft.com/library/windows/apps/xaml/Windows.UI.Input.Spatial.SpatialGestureRecognizer.TrySetGestureSettings).</span></span>

<span data-ttu-id="2b056-313">Bei hololens (erste Generation) sollten Interaktionen und Gesten im Allgemeinen die Zielvorgabe von der Kopfzeile des Benutzers ableiten, anstatt zu versuchen, direkt an der Position der Hand zu arbeiten.</span><span class="sxs-lookup"><span data-stu-id="2b056-313">On HoloLens (first gen), interactions and gestures should generally derive their targeting from the user's head gaze, rather than trying to render or interact at the hand's location directly.</span></span> <span data-ttu-id="2b056-314">Nachdem eine Interaktion begonnen hat, können relative Bewegungen der Hand verwendet werden, um die Bewegung zu steuern, wie bei der Manipulation oder Navigation.</span><span class="sxs-lookup"><span data-stu-id="2b056-314">Once an interaction has started, relative motions of the hand may be used to control the gesture, as with the Manipulation or Navigation gesture.</span></span>

## <a name="see-also"></a><span data-ttu-id="2b056-315">Weitere Informationen</span><span class="sxs-lookup"><span data-stu-id="2b056-315">See also</span></span>
* [<span data-ttu-id="2b056-316">Anvisieren mit dem Kopf und mit den Augen in DirectX</span><span class="sxs-lookup"><span data-stu-id="2b056-316">Head and eye gaze in DirectX</span></span>](gaze-in-directx.md)
* [<span data-ttu-id="2b056-317">Eingabe Modell für direkte Manipulation</span><span class="sxs-lookup"><span data-stu-id="2b056-317">Direct manipulation input model</span></span>](direct-manipulation.md)
* [<span data-ttu-id="2b056-318">Punkt-und Commit-Eingabe Modell</span><span class="sxs-lookup"><span data-stu-id="2b056-318">Point-and-commit input model</span></span>](point-and-commit.md)
* [<span data-ttu-id="2b056-319">Überblicks-und Commit-Eingabe Modell</span><span class="sxs-lookup"><span data-stu-id="2b056-319">Gaze and commit input model</span></span>](gaze-and-commit.md)
* [<span data-ttu-id="2b056-320">Motion-Controller</span><span class="sxs-lookup"><span data-stu-id="2b056-320">Motion controllers</span></span>](motion-controllers.md)
