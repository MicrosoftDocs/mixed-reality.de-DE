---
title: Praktische und Motion-Controllern in DirectX
description: Entwicklerhandbuch für die Verwendung von Hand nachverfolgen und während der Übertragung-Controllern in systemeigenen DirectX-apps.
author: caseymeekhof
ms.author: cmeekhof
ms.date: 04/30/2019
ms.topic: article
keywords: praktische Motion-Controller "," Directx "," Input ","-Hologramme
ms.openlocfilehash: 08666c8c26cd4851c0c003a96a9e96d7a90228ac
ms.sourcegitcommit: 45676da11ebe33a2aa3dccec0e8ad7d714420853
ms.translationtype: MT
ms.contentlocale: de-DE
ms.lasthandoff: 05/15/2019
ms.locfileid: "65629643"
---
# <a name="hands-and-motion-controllers-in-directx"></a><span data-ttu-id="24103-104">Praktische und Motion-Controllern in DirectX</span><span class="sxs-lookup"><span data-stu-id="24103-104">Hands and motion controllers in DirectX</span></span>

<span data-ttu-id="24103-105">In Windows Mixed Reality, beide übergeben und [Motion-Controller](motion-controllers.md) Eingabe erfolgt über die die räumlichen Eingabe-APIs finden Sie in der [Windows.UI.Input.Spatial](https://docs.microsoft.com/uwp/api/windows.ui.input.spatial) Namespace.</span><span class="sxs-lookup"><span data-stu-id="24103-105">In Windows Mixed Reality, both hand and [motion controller](motion-controllers.md) input is handled through the spatial input APIs, found in the [Windows.UI.Input.Spatial](https://docs.microsoft.com/uwp/api/windows.ui.input.spatial) namespace.</span></span> <span data-ttu-id="24103-106">Dadurch können Sie Baseler Ausschusses für häufig verwendete Aktionen wie **wählen** drückt die gleiche Weise wie für praktische und Motion-Controller.</span><span class="sxs-lookup"><span data-stu-id="24103-106">This enables you to easily handle common actions like **Select** presses the same way across both hands and motion controllers.</span></span>

## <a name="getting-started"></a><span data-ttu-id="24103-107">Erste Schritte</span><span class="sxs-lookup"><span data-stu-id="24103-107">Getting started</span></span>

<span data-ttu-id="24103-108">Zugriff auf räumliche Geben Sie in Windows Mixed Reality beginnen Sie mit der SpatialInteractionManager-Schnittstelle.</span><span class="sxs-lookup"><span data-stu-id="24103-108">To access spatial input in Windows Mixed Reality, start with the SpatialInteractionManager interface.</span></span>  <span data-ttu-id="24103-109">Sie können diese Schnittstelle zugreifen, durch den Aufruf [SpatialInteractionManager::GetForCurrentView](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.getforcurrentview), in der Regel manchmal während des Starts der app.</span><span class="sxs-lookup"><span data-stu-id="24103-109">You can access this interface by calling  [SpatialInteractionManager::GetForCurrentView](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.getforcurrentview), typically sometime during app startup.</span></span>

```cpp
using namespace winrt::Windows::UI::Input::Spatial;

SpatialInteractionManager interactionManager = SpatialInteractionManager::GetForCurrentView();
```

<span data-ttu-id="24103-110">Die SpatialInteractionManagers Aufgabe besteht darin, geben Sie den Zugriff auf [SpatialInteractionSources](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsource), die eine Quelle für die Eingabe darstellen.</span><span class="sxs-lookup"><span data-stu-id="24103-110">The SpatialInteractionManager's job is to provide access to [SpatialInteractionSources](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsource), which represent a source of input.</span></span>  <span data-ttu-id="24103-111">Es gibt drei Arten von SpatialInteractionSources im System verfügbar.</span><span class="sxs-lookup"><span data-stu-id="24103-111">There are three kinds of SpatialInteractionSources available in the system.</span></span>
* <span data-ttu-id="24103-112">**Hand** erkannte Hand eines Benutzers darstellt.</span><span class="sxs-lookup"><span data-stu-id="24103-112">**Hand** represents a user's detected hand.</span></span> <span data-ttu-id="24103-113">Verfügbare Quellen bieten verschiedene Funktionen, die basierend auf dem Gerät, von der grundlegenden Gesten für HoloLens bis hin zu vollständig angezeigte Seite, die workflowüberwachung HoloLens 2.</span><span class="sxs-lookup"><span data-stu-id="24103-113">Hand sources offer different features based on the device, ranging from basic gestures on HoloLens to fully articulated hand tracking on HoloLens 2.</span></span> 
* <span data-ttu-id="24103-114">**Controller** einen gekoppelten Motion-Controller darstellt.</span><span class="sxs-lookup"><span data-stu-id="24103-114">**Controller** represents a paired motion controller.</span></span> <span data-ttu-id="24103-115">Während der Übertragung Controller können es sich um eine Vielzahl von Funktionen bieten.</span><span class="sxs-lookup"><span data-stu-id="24103-115">Motion controllers can offer a variety of capabilities.</span></span>  <span data-ttu-id="24103-116">Zum Beispiel: Wählen Sie die Trigger, Menüschaltflächen, verstehen Schaltflächen, Touchpad und Thumbsticks.</span><span class="sxs-lookup"><span data-stu-id="24103-116">For example: Select triggers, Menu buttons, Grasp buttons, touchpads and thumbsticks.</span></span>
* <span data-ttu-id="24103-117">**Voice** des Benutzers Voice Schlüsselwörter System hat Vorträge darstellt.</span><span class="sxs-lookup"><span data-stu-id="24103-117">**Voice** represents the user's voice speaking system-detected keywords.</span></span> <span data-ttu-id="24103-118">Beispielsweise wird dieser Quelle einfügen drücken, auf einer Option und freizugeben, wenn der Benutzer sagt "Select".</span><span class="sxs-lookup"><span data-stu-id="24103-118">For example, this source will inject a Select press and release whenever the user says "Select".</span></span>

<span data-ttu-id="24103-119">Pro-Frame Daten für eine Quelle entspricht der [SpatialInteractionSourceState](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate) Schnittstelle.</span><span class="sxs-lookup"><span data-stu-id="24103-119">Per-frame data for a source is represented by the  [SpatialInteractionSourceState](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate) interface.</span></span> <span data-ttu-id="24103-120">Es gibt zwei Möglichkeiten zum Zugriff auf diese Daten, je nachdem, ob Sie ein ereignisgesteuertes oder abrufbasierten-Modell in Ihrer Anwendung verwenden möchten.</span><span class="sxs-lookup"><span data-stu-id="24103-120">There are two different ways to access this data, depending on whether you want to use an event-driven or polling-based model in your application.</span></span>

### <a name="event-driven-input"></a><span data-ttu-id="24103-121">Ereignisgesteuerte Eingabe</span><span class="sxs-lookup"><span data-stu-id="24103-121">Event-driven input</span></span>
<span data-ttu-id="24103-122">Die SpatialInteractionManager bietet es sich um eine Reihe von Ereignissen, denen Ihrer app überwachen kann.</span><span class="sxs-lookup"><span data-stu-id="24103-122">The SpatialInteractionManager provides a number of events that your app can listen for.</span></span>  <span data-ttu-id="24103-123">Einige Beispiele hierfür sind [SourcePressed](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcepressed), [SourceReleased](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcereleased) und [SourceUpdated](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourceupdated).</span><span class="sxs-lookup"><span data-stu-id="24103-123">A few examples include   [SourcePressed](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcepressed), [SourceReleased](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcereleased) and [SourceUpdated](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourceupdated).</span></span>

<span data-ttu-id="24103-124">Der folgende Code z. B. verknüpft einen Ereignishandler namens MyApp::OnSourcePressed auf das Ereignis SourcePressed.</span><span class="sxs-lookup"><span data-stu-id="24103-124">For example, the following code hooks up an event handler called MyApp::OnSourcePressed to the SourcePressed event.</span></span>  <span data-ttu-id="24103-125">Dadurch kann es sich um Ihre app um drückt auf jede Art von Interaktion Quelle zu erkennen.</span><span class="sxs-lookup"><span data-stu-id="24103-125">This allows your app to detect presses on any type of interaction source.</span></span>

```cpp
using namespace winrt::Windows::UI::Input::Spatial;

auto interactionManager = SpatialInteractionManager::GetForCurrentView();
interactionManager.SourcePressed({ this, &MyApp::OnSourcePressed });

```

<span data-ttu-id="24103-126">Dieses Ereignis gedrückte wird zu Ihrer app asynchron zusammen mit den entsprechenden SpatialInteractionSourceState zum Zeitpunkt gesendet, drücken Sie die aufgetreten sind.</span><span class="sxs-lookup"><span data-stu-id="24103-126">This pressed event is sent to your app asynchronously, along with the corresponding SpatialInteractionSourceState at the time the press happened.</span></span> <span data-ttu-id="24103-127">Ihre app oder eine Spiele-Engine möglicherweise ausführen möchten sofort verarbeiten oder möglicherweise möchten die Daten in der Eingabe verarbeiten Routine in die Warteschlange.</span><span class="sxs-lookup"><span data-stu-id="24103-127">Your app or game engine may want to perform some processing right away or you may want to queue up the event data in your input processing routine.</span></span> <span data-ttu-id="24103-128">Hier ist eine Ereignishandlerfunktion für das SourcePressed-Ereignis, das zeigt, wie Sie überprüfen, ob die auswählen-Schaltfläche gedrückt wurde.</span><span class="sxs-lookup"><span data-stu-id="24103-128">Here is an event handler function for the SourcePressed event, which shows how to check whether the select button was pressed.</span></span>

```cpp
using namespace winrt::Windows::UI::Input::Spatial;

void MyApp::OnSourcePressed(SpatialInteractionManager const& sender, SpatialInteractionSourceEventArgs const& args)
{
    if (args.PressKind() == SpatialInteractionPressKind::Select)
    {
        // Select button was pressed, update app state
    }
}
```

<span data-ttu-id="24103-129">Der obige Code überprüft nur die "Select" Press, die der primären Aktion auf dem Gerät entspricht.</span><span class="sxs-lookup"><span data-stu-id="24103-129">The above code only checks for the 'Select' press, which corresponds to the primary action on the device.</span></span> <span data-ttu-id="24103-130">Beispiele hierfür sind ein AirTap für HoloLens oder das Abrufen des Triggers für einen Controller während der Übertragung.</span><span class="sxs-lookup"><span data-stu-id="24103-130">Examples include doing an AirTap on HoloLens or pulling the trigger on a motion controller.</span></span>  <span data-ttu-id="24103-131">'Select' drückt darstellen des Benutzers Absicht an, die – Hologramm aktiviert werden, die sie verwenden möchten.</span><span class="sxs-lookup"><span data-stu-id="24103-131">'Select' presses represent the user's intention to activate the hologram they are targeting.</span></span>  <span data-ttu-id="24103-132">Das SourcePressed-Ereignis wird ausgelöst, für eine Reihe von verschiedene Schaltflächen und Gesten, und Sie können überprüfen, dass andere Eigenschaften auf der SpatialInteractionSource für diese Fälle zu testen.</span><span class="sxs-lookup"><span data-stu-id="24103-132">The SourcePressed event will fire for a number of different buttons and gestures, and you can inspect other properties on the SpatialInteractionSource to test for those cases.</span></span>

### <a name="polling-based-input"></a><span data-ttu-id="24103-133">Abrufbasierten Eingabe</span><span class="sxs-lookup"><span data-stu-id="24103-133">Polling-based input</span></span>
<span data-ttu-id="24103-134">Sie können auch SpatialInteractionManager verwenden, für den aktuellen Status der Eingabe jedes Bild abrufen.</span><span class="sxs-lookup"><span data-stu-id="24103-134">You can also use SpatialInteractionManager to poll for the current state of input every frame.</span></span>  <span data-ttu-id="24103-135">Zu diesem Zweck rufen Sie ganz einfach [GetDetectedSourcesAtTimestamp](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.getdetectedsourcesattimestamp) jeder Frame.</span><span class="sxs-lookup"><span data-stu-id="24103-135">To do this, simply call [GetDetectedSourcesAtTimestamp](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.getdetectedsourcesattimestamp) every frame.</span></span>  <span data-ttu-id="24103-136">Diese Funktion gibt ein Array mit einer [SpatialInteractionSourceState](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate) für jede aktive [SpatialInteractionSource](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsource).</span><span class="sxs-lookup"><span data-stu-id="24103-136">This function returns an array containing one [SpatialInteractionSourceState](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate) for every active [SpatialInteractionSource](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsource).</span></span> <span data-ttu-id="24103-137">Dies bedeutet eine für jeden aktiven Motion-Controller, eine für jeden überwachten Hand und eine für Sprache, wenn ein Befehl "select" kürzlich uttered wurde.</span><span class="sxs-lookup"><span data-stu-id="24103-137">This means one for each active motion controller, one for each tracked hand, and one for speech if a 'select' command was recently uttered.</span></span> <span data-ttu-id="24103-138">Sie können die Eigenschaften auf jeder SpatialInteractionSourceState auf Laufwerk Eingabe klicken Sie dann in Ihre Anwendung prüfen.</span><span class="sxs-lookup"><span data-stu-id="24103-138">You can then inspect the properties on each SpatialInteractionSourceState to drive input into your application.</span></span> 

<span data-ttu-id="24103-139">Hier ist ein Beispiel für das Verwenden der Abrufmethode für die'select'-Aktion zu überprüfen.</span><span class="sxs-lookup"><span data-stu-id="24103-139">Here is an example of how to check for the 'select' action using the polling method.</span></span> <span data-ttu-id="24103-140">Beachten Sie, dass die *Vorhersage* Variable steht für eine [HolographicFramePrediction](https://docs.microsoft.com/en-us/uwp/api/Windows.Graphics.Holographic.HolographicFramePrediction) -Objekt, das aus abgerufen werden kann die [HolographicFrame](https://docs.microsoft.com/en-us/uwp/api/windows.graphics.holographic.holographicframe).</span><span class="sxs-lookup"><span data-stu-id="24103-140">Note that the *prediction* variable represents a [HolographicFramePrediction](https://docs.microsoft.com/en-us/uwp/api/Windows.Graphics.Holographic.HolographicFramePrediction) object, which can be obtained from the [HolographicFrame](https://docs.microsoft.com/en-us/uwp/api/windows.graphics.holographic.holographicframe).</span></span>

```cpp
using namespace winrt::Windows::UI::Input::Spatial;

auto interactionManager = SpatialInteractionManager::GetForCurrentView();
auto sourceStates = m_spatialInteractionManager.GetDetectedSourcesAtTimestamp(prediction.Timestamp());

for (auto& sourceState : sourceStates)
{
    if (sourceState.IsSelectPressed())
    {
        // Select button is down, update app state
    }
}
```

<span data-ttu-id="24103-141">Jede SpatialInteractionSource verfügt über eine ID, die Sie verwenden können, geben Sie die neue Datenquellen und die vorhandene Quellen von Frame zu Frame zu korrelieren.</span><span class="sxs-lookup"><span data-stu-id="24103-141">Each SpatialInteractionSource has an ID, which you can use to identify new sources and correlate existing sources from frame to frame.</span></span>  <span data-ttu-id="24103-142">Jedes Mal, wenn sie lassen, und geben Sie das Blickfeld, aber der Controller-IDs für die Dauer der Sitzung statisch bleiben, werden praktische eine neue ID zugewiesen.</span><span class="sxs-lookup"><span data-stu-id="24103-142">Hands are assigned a new ID every time they leave and enter the FOV, but controller IDs remain static for the duration of the session.</span></span>  <span data-ttu-id="24103-143">Sie können die Ereignisse auf SpatialInteractionManager wie z. B. [SourceDetected](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcedetected) und [SourceLost](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcelost), zur Reaktion Hand eingeben, oder lassen Sie das Gerät auf der Anzeige oder wenn während der Übertragung Controller sind aktiviert und deaktiviert oder sind gekoppelte/Ungepaarte.</span><span class="sxs-lookup"><span data-stu-id="24103-143">You can use the events on SpatialInteractionManager such as [SourceDetected](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcedetected) and [SourceLost](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcelost), to react when hands enter or leave the device's view, or when motion controllers are turned on/off or are paired/unpaired.</span></span>

### <a name="predicted-vs-historical-poses"></a><span data-ttu-id="24103-144">Im Vergleich zu historischen stellt vorhergesagt</span><span class="sxs-lookup"><span data-stu-id="24103-144">Predicted vs. historical poses</span></span>
<span data-ttu-id="24103-145">Beachten Sie, dass GetDetectedSourcesAtTimestamp einen Timestampparameter.</span><span class="sxs-lookup"><span data-stu-id="24103-145">Note that GetDetectedSourcesAtTimestamp has a timestamp parameter.</span></span> <span data-ttu-id="24103-146">Dadurch können Sie Anforderungsstatus und Darstellen von Daten, die entweder vorhergesagt werden, oder historische, sodass Sie die räumliche Interaktionen mit anderen Quellen der Eingabe korrelieren.</span><span class="sxs-lookup"><span data-stu-id="24103-146">This enables you to request state and pose data that is either predicted or historical, letting you correlate spatial interactions with other sources of input.</span></span> <span data-ttu-id="24103-147">Z. B. das Handsymbol des Position im aktuellen Frame zu rendern, Sie können übergeben der vorhergesagten Zeitstempel, der durch die [HolographicFrame](https://docs.microsoft.com/en-us/uwp/api/windows.graphics.holographic.holographicframe).</span><span class="sxs-lookup"><span data-stu-id="24103-147">For example, when rendering the hand's position in the current frame, you can pass in the predicted timestamp provided by the [HolographicFrame](https://docs.microsoft.com/en-us/uwp/api/windows.graphics.holographic.holographicframe).</span></span> <span data-ttu-id="24103-148">Dadurch kann es sich um das System, um die Position des Zeigers an das eng mit der gerenderte Frame-Ausgabe, die gefühlte Latenz minimieren Forward vorherzusagen.</span><span class="sxs-lookup"><span data-stu-id="24103-148">This enables the system to forward-predict the hand position to closely align with the rendered frame output, minimizing perceived latency.</span></span>

<span data-ttu-id="24103-149">Solche eine vorhergesagte Haltung ergibt jedoch keine ideale zeigen Chow mit einer Datenquelle für die Interaktion auf.</span><span class="sxs-lookup"><span data-stu-id="24103-149">However, such a predicted pose does not produce an ideal pointing ray for targeting with an interaction source.</span></span> <span data-ttu-id="24103-150">Wenn eine Controller mit der Schaltfläche gedrückt wird, kann es beispielsweise bis zu 20 ms für das Ereignis über Bluetooth an das Betriebssystem Bubbling dauern.</span><span class="sxs-lookup"><span data-stu-id="24103-150">For example, when a motion controller button is pressed, it can take up to 20ms for that event to bubble up through Bluetooth to the operating system.</span></span> <span data-ttu-id="24103-151">Nachdem ein Benutzer eine Geste für ein manuell ausführt, kann auf ähnliche Weise eine bestimmte Zeit verstreichen, bevor das System die Bewegung und Ihre app erkennt dann fragt Sie ab.</span><span class="sxs-lookup"><span data-stu-id="24103-151">Similarly, after a user performs a hand gesture, some amount of time may pass before the system detects the gesture and your app then polls for it.</span></span> <span data-ttu-id="24103-152">Durch die Zeit Ihrer app führt eine Abfrage für eine statusänderung, verwendet die Haupt- und Hand ist Ziel, die Interaktion tatsächlich in der Vergangenheit aufgetreten sind.</span><span class="sxs-lookup"><span data-stu-id="24103-152">By the time your app polls for a state change, the head and hand poses used to target that interaction actually happened in the past.</span></span> <span data-ttu-id="24103-153">Wenn Sie abzielen, indem Sie Ihre aktuellen HolographicFrames Zeitstempel an GetDetectedSourcesAtTimestamp übergeben, wird der Haltung stattdessen weiterleiten vorhergesagt werden, die für die Zielgruppenadressierung Chow zum Zeitpunkt der Rahmen angezeigt wird, kann die mehr als 20 ms in der Zukunft liegen.</span><span class="sxs-lookup"><span data-stu-id="24103-153">If you target by passing your current HolographicFrame's timestamp to GetDetectedSourcesAtTimestamp, the pose will instead be forward predicted to the targeting ray at the time the frame will be displayed, which could be more than 20ms in the future.</span></span> <span data-ttu-id="24103-154">Diese Haltung zukünftige eignet sich gut für *Rendering* die Interaktion-Quelle, aber auch unser Problem Zeit für *für* Interaktion, wie der Benutzer als Ziel, die in der Vergangenheit aufgetreten sind.</span><span class="sxs-lookup"><span data-stu-id="24103-154">This future pose is good for *rendering* the interaction source, but compounds our time problem for *targeting* the interaction, as the user's targeting occurred in the past.</span></span>

<span data-ttu-id="24103-155">Glücklicherweise die [SourcePressed](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcepressed), [SourceReleased](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcereleased) und [SourceUpdated](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourceupdated) Ereignisse bieten die historischen [Zustand](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourceeventargs.state) zugeordnet jedes Eingabeereignis.</span><span class="sxs-lookup"><span data-stu-id="24103-155">Fortunately, the [SourcePressed](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcepressed), [SourceReleased](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcereleased) and [SourceUpdated](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourceupdated) events provide the historical [State](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourceeventargs.state) associated with each input event.</span></span>  <span data-ttu-id="24103-156">Dies schließt direkt den Verlaufsdaten Head "und" manuell ist, die über [TryGetPointerPose](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.trygetpointerpose), zusammen mit einer historischen [Zeitstempel](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.timestamp) , die an andere APIs zur Korrelation mit diesem Ereignis übergeben werden können.</span><span class="sxs-lookup"><span data-stu-id="24103-156">This directly includes the historical head and hand poses available through [TryGetPointerPose](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.trygetpointerpose), along with a historical [Timestamp](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.timestamp) that you can pass to other APIs to correlate with this event.</span></span>

<span data-ttu-id="24103-157">Daraus ergibt sich die folgenden bewährten Methoden beim Rendern und Ziele mit Hände und Controller alle Frames:</span><span class="sxs-lookup"><span data-stu-id="24103-157">That leads to the following best practices when rendering and targeting with hands and controllers each frame:</span></span>
* <span data-ttu-id="24103-158">Für **Hand/Controller Rendering** jeden Frame Ihre app sollte **Abruf** für die **Forward-vorhergesagt** jeder Quelle für die Interaktion des aktuellen Frames Photon Zeitpunkt darstellen.</span><span class="sxs-lookup"><span data-stu-id="24103-158">For **hand/controller rendering** each frame, your app should **poll** for the **forward-predicted** pose of each interaction source at the current frame’s photon time.</span></span>  <span data-ttu-id="24103-159">Sie können für alle Interaktion Quellen abrufen, durch den Aufruf [GetDetectedSourcesAtTimestamp](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.getdetectedsourcesattimestamp) jeden Frame, übergibt des vorhergesagten Zeitstempels von bereitgestellten [HolographicFrame::CurrentPrediction](https://docs.microsoft.com/en-us/uwp/api/windows.graphics.holographic.holographicframe.currentprediction).</span><span class="sxs-lookup"><span data-stu-id="24103-159">You can poll for all interaction sources by calling [GetDetectedSourcesAtTimestamp](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.getdetectedsourcesattimestamp) each frame, passing in the predicted timestamp provided by [HolographicFrame::CurrentPrediction](https://docs.microsoft.com/en-us/uwp/api/windows.graphics.holographic.holographicframe.currentprediction).</span></span>
* <span data-ttu-id="24103-160">Für **Hand/Controller als Ziel** anhand eines drücken oder die Version, sollte Ihre app behandeln, gedrückt/veröffentlicht **Ereignisse**, feinheiten beim Raycasting basierend auf den **historische** Haupt- oder manuell Haltung für Dieses Ereignis.</span><span class="sxs-lookup"><span data-stu-id="24103-160">For **hand/controller targeting** upon a press or release, your app should handle pressed/released **events**, raycasting based on the **historical** head or hand pose for that event.</span></span> <span data-ttu-id="24103-161">Erhalten Sie diese für die Zielgruppenadressierung Chow durch Behandeln der [SourcePressed](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcepressed) oder [SourceReleased](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcereleased) Ereignis Abrufen der [Zustand](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourceeventargs.state) Eigenschaft aus den Ereignisargumenten und dem anschließenden Aufrufen der [ TryGetPointerPose](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.trygetpointerpose) Methode.</span><span class="sxs-lookup"><span data-stu-id="24103-161">You get this targeting ray by handling the [SourcePressed](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcepressed) or [SourceReleased](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcereleased) event, getting the [State](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourceeventargs.state) property from the event arguments, and then calling its [TryGetPointerPose](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.trygetpointerpose) method.</span></span>

## <a name="cross-device-input-properties"></a><span data-ttu-id="24103-162">Geräteübergreifende Eingabeeigenschaften</span><span class="sxs-lookup"><span data-stu-id="24103-162">Cross-device input properties</span></span>
<span data-ttu-id="24103-163">Die SpatialInteractionSource-API unterstützt die Controller und manuell Nachverfolgen von Systemen mit einer Vielzahl von Funktionen.</span><span class="sxs-lookup"><span data-stu-id="24103-163">The SpatialInteractionSource API supports controllers and hand tracking systems with a wide range of capabilities.</span></span> <span data-ttu-id="24103-164">Diese Funktionen sind häufig zwischen Gerät und Typen.</span><span class="sxs-lookup"><span data-stu-id="24103-164">A number of these capabilities are common between device types.</span></span> <span data-ttu-id="24103-165">Geben Sie z. B. manuell nachverfolgen und während der Übertragung Domänencontroller sowohl auf, eine Aktion "auswählen" und eine 3D-Position.</span><span class="sxs-lookup"><span data-stu-id="24103-165">For example, hand tracking and motion controllers both provide a 'select' action and a 3D position.</span></span> <span data-ttu-id="24103-166">Wo immer dies möglich ist, wird die API diese allgemeinen Funktionen die gleichen Eigenschaften für die SpatialInteractionSource zugeordnet.</span><span class="sxs-lookup"><span data-stu-id="24103-166">Wherever possible, the API maps these common capabilities to the same properties on the SpatialInteractionSource.</span></span>  <span data-ttu-id="24103-167">Dies ermöglicht es Anwendungen leichter eine Vielzahl von Eingabetypen zu unterstützen.</span><span class="sxs-lookup"><span data-stu-id="24103-167">This enables applications to more easily support a wide range of input types.</span></span> <span data-ttu-id="24103-168">Die folgende Tabelle beschreibt die Eigenschaften, die unterstützt werden und wie sie über Eingabetypen vergleichen.</span><span class="sxs-lookup"><span data-stu-id="24103-168">The following table describes the properties that are supported, and how they compare across input types.</span></span>

| <span data-ttu-id="24103-169">Eigenschaft</span><span class="sxs-lookup"><span data-stu-id="24103-169">Property</span></span> | <span data-ttu-id="24103-170">Beschreibung</span><span class="sxs-lookup"><span data-stu-id="24103-170">Description</span></span> | <span data-ttu-id="24103-171">HoloLens-Gesten</span><span class="sxs-lookup"><span data-stu-id="24103-171">HoloLens Gestures</span></span> | <span data-ttu-id="24103-172">Motion-Controller</span><span class="sxs-lookup"><span data-stu-id="24103-172">Motion Controllers</span></span> | <span data-ttu-id="24103-173">Umrissene Händen</span><span class="sxs-lookup"><span data-stu-id="24103-173">Articulated Hands</span></span>|
|--- |--- |--- |--- |--- |
| [<span data-ttu-id="24103-174">SpatialInteractionSource::**Händigkeit**</span><span class="sxs-lookup"><span data-stu-id="24103-174">SpatialInteractionSource::**Handedness**</span></span>](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsource.handedness) | <span data-ttu-id="24103-175">Rechten oder linken / Controller.</span><span class="sxs-lookup"><span data-stu-id="24103-175">Right or left hand / controller.</span></span> | <span data-ttu-id="24103-176">Nicht unterstützt</span><span class="sxs-lookup"><span data-stu-id="24103-176">Not Supported</span></span> | <span data-ttu-id="24103-177">Unterstützt</span><span class="sxs-lookup"><span data-stu-id="24103-177">Supported</span></span> | <span data-ttu-id="24103-178">Unterstützt</span><span class="sxs-lookup"><span data-stu-id="24103-178">Supported</span></span> |
| [<span data-ttu-id="24103-179">SpatialInteractionSourceState::**IsSelectPressed**</span><span class="sxs-lookup"><span data-stu-id="24103-179">SpatialInteractionSourceState::**IsSelectPressed**</span></span>](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.isselectpressed) | <span data-ttu-id="24103-180">Aktuellen Status der primären Schaltfläche.</span><span class="sxs-lookup"><span data-stu-id="24103-180">Current state of the primary button.</span></span> | <span data-ttu-id="24103-181">Tippen Sie auf</span><span class="sxs-lookup"><span data-stu-id="24103-181">Air Tap</span></span> | <span data-ttu-id="24103-182">Trigger</span><span class="sxs-lookup"><span data-stu-id="24103-182">Trigger</span></span> | <span data-ttu-id="24103-183">Gelockerte Air tippen (aufrechte verkleinern)</span><span class="sxs-lookup"><span data-stu-id="24103-183">Relaxed Air Tap (upright pinch)</span></span> |
| [<span data-ttu-id="24103-184">SpatialInteractionSourceState::**IsGrasped**</span><span class="sxs-lookup"><span data-stu-id="24103-184">SpatialInteractionSourceState::**IsGrasped**</span></span>](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.isgrasped) | <span data-ttu-id="24103-185">Aktuelle Zustand der Schaltfläche Ziehpunkte.</span><span class="sxs-lookup"><span data-stu-id="24103-185">Current state of the grab button.</span></span> | <span data-ttu-id="24103-186">Nicht unterstützt</span><span class="sxs-lookup"><span data-stu-id="24103-186">Not Supported</span></span> | <span data-ttu-id="24103-187">Ziehen Sie die Schaltfläche "</span><span class="sxs-lookup"><span data-stu-id="24103-187">Grab button</span></span> | <span data-ttu-id="24103-188">Zoomgesten oder geschlossenen manuell</span><span class="sxs-lookup"><span data-stu-id="24103-188">Pinch or Closed Hand</span></span> |
| [<span data-ttu-id="24103-189">SpatialInteractionSourceState::**IsMenuPressed**</span><span class="sxs-lookup"><span data-stu-id="24103-189">SpatialInteractionSourceState::**IsMenuPressed**</span></span>](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.ismenupressed) | <span data-ttu-id="24103-190">Aktuellen Status der Menü-Schaltfläche.</span><span class="sxs-lookup"><span data-stu-id="24103-190">Current state of the menu button.</span></span>    | <span data-ttu-id="24103-191">Nicht unterstützt</span><span class="sxs-lookup"><span data-stu-id="24103-191">Not Supported</span></span> | <span data-ttu-id="24103-192">Menütaste</span><span class="sxs-lookup"><span data-stu-id="24103-192">Menu Button</span></span> | <span data-ttu-id="24103-193">Nicht unterstützt</span><span class="sxs-lookup"><span data-stu-id="24103-193">Not Supported</span></span> |
| [<span data-ttu-id="24103-194">SpatialInteractionSourceLocation::**Position**</span><span class="sxs-lookup"><span data-stu-id="24103-194">SpatialInteractionSourceLocation::**Position**</span></span>](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcelocation.position) | <span data-ttu-id="24103-195">XYZ-Speicherort, der manuell oder durch Ziehpunkt Position auf dem Controller.</span><span class="sxs-lookup"><span data-stu-id="24103-195">XYZ location of the hand or grip position on the controller.</span></span> | <span data-ttu-id="24103-196">Palm-Speicherort</span><span class="sxs-lookup"><span data-stu-id="24103-196">Palm location</span></span> | <span data-ttu-id="24103-197">Ziehpunkt Haltung position</span><span class="sxs-lookup"><span data-stu-id="24103-197">Grip pose position</span></span> | <span data-ttu-id="24103-198">Palm-Speicherort</span><span class="sxs-lookup"><span data-stu-id="24103-198">Palm location</span></span> |
| [<span data-ttu-id="24103-199">SpatialInteractionSourceLocation::**Orientation**</span><span class="sxs-lookup"><span data-stu-id="24103-199">SpatialInteractionSourceLocation::**Orientation**</span></span>](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcelocation.orientation) | <span data-ttu-id="24103-200">Die Quaternion, die die Ausrichtung der Hand oder des Ziehpunkts zur Größenänderung darstellt darstellen, auf dem Controller.</span><span class="sxs-lookup"><span data-stu-id="24103-200">Quaternion representing the orientation of the hand or grip pose on the controller.</span></span> | <span data-ttu-id="24103-201">Nicht unterstützt</span><span class="sxs-lookup"><span data-stu-id="24103-201">Not Supported</span></span> | <span data-ttu-id="24103-202">Ziehpunkt Haltung Ausrichtung</span><span class="sxs-lookup"><span data-stu-id="24103-202">Grip pose orientation</span></span> | <span data-ttu-id="24103-203">Palm-Ausrichtung</span><span class="sxs-lookup"><span data-stu-id="24103-203">Palm orientation</span></span> |
| [<span data-ttu-id="24103-204">SpatialPointerInteractionSourcePose::**Position**</span><span class="sxs-lookup"><span data-stu-id="24103-204">SpatialPointerInteractionSourcePose::**Position**</span></span>](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialpointerinteractionsourcepose.position#Windows_UI_Input_Spatial_SpatialPointerInteractionSourcePose_Position) | <span data-ttu-id="24103-205">Der Ursprung des Strahls zeigen.</span><span class="sxs-lookup"><span data-stu-id="24103-205">Origin of the pointing ray.</span></span> | <span data-ttu-id="24103-206">Nicht unterstützt</span><span class="sxs-lookup"><span data-stu-id="24103-206">Not Supported</span></span> | <span data-ttu-id="24103-207">Unterstützt</span><span class="sxs-lookup"><span data-stu-id="24103-207">Supported</span></span> | <span data-ttu-id="24103-208">Unterstützt</span><span class="sxs-lookup"><span data-stu-id="24103-208">Supported</span></span> |
| [<span data-ttu-id="24103-209">SpatialPointerInteractionSourcePose::**ForwardDirection**</span><span class="sxs-lookup"><span data-stu-id="24103-209">SpatialPointerInteractionSourcePose::**ForwardDirection**</span></span>](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialpointerinteractionsourcepose.forwarddirection#Windows_UI_Input_Spatial_SpatialPointerInteractionSourcePose_ForwardDirection) | <span data-ttu-id="24103-210">Die Richtung des Strahls zeigen.</span><span class="sxs-lookup"><span data-stu-id="24103-210">Direction of the pointing ray.</span></span> | <span data-ttu-id="24103-211">Nicht unterstützt</span><span class="sxs-lookup"><span data-stu-id="24103-211">Not Supported</span></span> | <span data-ttu-id="24103-212">Unterstützt</span><span class="sxs-lookup"><span data-stu-id="24103-212">Supported</span></span> | <span data-ttu-id="24103-213">Unterstützt</span><span class="sxs-lookup"><span data-stu-id="24103-213">Supported</span></span> |

<span data-ttu-id="24103-214">Einige der oben genannten Eigenschaften sind nicht auf allen Geräten verfügbar, und die API bietet die Möglichkeit, dies zu testen.</span><span class="sxs-lookup"><span data-stu-id="24103-214">Some of the above properties are not available on all devices, and the API provides a means to test for this.</span></span> <span data-ttu-id="24103-215">Sie können z. B. Überprüfen der [SpatialInteractionSource::IsGraspSupported](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsource.isgraspsupported) Eigenschaft, um zu bestimmen, ob die Quelle eine Aktion verstehen.</span><span class="sxs-lookup"><span data-stu-id="24103-215">For example, you can inspect the [SpatialInteractionSource::IsGraspSupported](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsource.isgraspsupported) property to determine whether the source provides a grasp action.</span></span>

### <a name="grip-pose-vs-pointing-pose"></a><span data-ttu-id="24103-216">Ziehpunkt Haltung im Vergleich zu zeigenden Haltung</span><span class="sxs-lookup"><span data-stu-id="24103-216">Grip pose vs. pointing pose</span></span>

<span data-ttu-id="24103-217">Windows Mixed Reality unterstützt die Motion-Controller in einer Vielzahl von Formfaktoren.</span><span class="sxs-lookup"><span data-stu-id="24103-217">Windows Mixed Reality supports motion controllers in a variety of form factors.</span></span>  <span data-ttu-id="24103-218">Darüber hinaus wird die angezeigte Seite tracking-Systeme unterstützt.</span><span class="sxs-lookup"><span data-stu-id="24103-218">It also supports articulated hand tracking systems.</span></span>  <span data-ttu-id="24103-219">Alle diese Systeme verfügen über unterschiedliche Beziehungen zwischen die Position des Zeigers und der natürliche "Weiterleiten" Richtung, die apps für verweist oder Rendreing Objekte des Benutzers verfügen verwendet werden soll.</span><span class="sxs-lookup"><span data-stu-id="24103-219">All of these systems have different relationships between the hand position and the natural "forward" direction that apps should use for pointing or rendreing objects in the user's hand.</span></span>  <span data-ttu-id="24103-220">Um all dies zu unterstützen, gibt es zwei Arten von 3D für beide Controller Hand, nachverfolgung und während der Übertragung angegeben ist.</span><span class="sxs-lookup"><span data-stu-id="24103-220">To support all of this, there are two types of 3D poses provided for both hand tracking and motion controllers.</span></span>  <span data-ttu-id="24103-221">Die erste ist Ziehpunkt Haltung, in der Hand-Position des Benutzers darstellt.</span><span class="sxs-lookup"><span data-stu-id="24103-221">The first is grip pose, which represents the user's hand position.</span></span>  <span data-ttu-id="24103-222">Die zweite handelt es sich um Haltung, verweist das ein zeigen Strahl von Hand oder Controller des Benutzers darstellt.</span><span class="sxs-lookup"><span data-stu-id="24103-222">The second is pointing pose, which represents a pointing ray originating from the user's hand or controller.</span></span> <span data-ttu-id="24103-223">Wenn Sie rendern möchten **des Benutzers manuell** oder **frei, die ein Objekt des Benutzers verfügen**, z. B. ein "sword" oder ein damoklesschwert, verwenden den Ziehpunkt Haltung.</span><span class="sxs-lookup"><span data-stu-id="24103-223">So, if you want to render **the user's hand** or **an object held in the user's hand**, such as a sword or gun, use the grip pose.</span></span> <span data-ttu-id="24103-224">Wenn Sie möchten Raycast in den Controller bzw. die Hand, z. B. wenn der Benutzer ist **zeigen Sie auf der Benutzeroberfläche** , verwenden Sie die Haltung zeigen.</span><span class="sxs-lookup"><span data-stu-id="24103-224">If you want to raycast from the controller or hand, for example when the user is **pointing at UI** , use the pointing pose.</span></span>

<span data-ttu-id="24103-225">Sie können den Zugriff auf die **Ziehpunkt Haltung** über [SpatialInteractionSourceState::Properties::TryGetLocation(...) ](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourceproperties.trygetlocation#Windows_UI_Input_Spatial_SpatialInteractionSourceProperties_TryGetLocation_Windows_Perception_Spatial_SpatialCoordinateSystem_).  Es ist wie folgt definiert:</span><span class="sxs-lookup"><span data-stu-id="24103-225">You can access the **grip pose** through [SpatialInteractionSourceState::Properties::TryGetLocation(...)](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourceproperties.trygetlocation#Windows_UI_Input_Spatial_SpatialInteractionSourceProperties_TryGetLocation_Windows_Perception_Spatial_SpatialCoordinateSystem_).  It is defined as follows:</span></span>
* <span data-ttu-id="24103-226">Die **fassen Sie Position**: Der Schwerpunkt Palm, wenn der Controller natürlich mit angepasst nach links oder rechts zentriert die Position in den Ziehpunkt.</span><span class="sxs-lookup"><span data-stu-id="24103-226">The **grip position**: The palm centroid when holding the controller naturally, adjusted left or right to center the position within the grip.</span></span>
* <span data-ttu-id="24103-227">Die **fassen Sie die rechte Achse die Ausrichtung**: Wenn Sie Ihre Hand, um einen flachen 5 Finger Haltung bilden vollständig geöffnet haben, dem Strahl, der ist normal, zu Ihrem Palm (vorwärts vom linken Palm, rückwärts von rechts Palm)</span><span class="sxs-lookup"><span data-stu-id="24103-227">The **grip orientation's Right axis**: When you completely open your hand to form a flat 5-finger pose, the ray that is normal to your palm (forward from left palm, backward from right palm)</span></span>
* <span data-ttu-id="24103-228">Die **fassen Sie die Ausrichtung, vorwärts gerichtete Achse**: Wenn Sie Ihre Hand schließen, teilweise (als ob den Controller enthält), der vom Strahl, der "forward" über die Tube gebildet, indem die Finger nicht-Thumb-Steuerelement zeigt.</span><span class="sxs-lookup"><span data-stu-id="24103-228">The **grip orientation's Forward axis**: When you close your hand partially (as if holding the controller), the ray that points "forward" through the tube formed by your non-thumb fingers.</span></span>
* <span data-ttu-id="24103-229">Die **fassen Sie die Ausrichtung des einrichten Achse**: Die nach-oben-Achse impliziert durch die rechts- und -Weiterleiten-Definitionen.</span><span class="sxs-lookup"><span data-stu-id="24103-229">The **grip orientation's Up axis**: The Up axis implied by the Right and Forward definitions.</span></span>

<span data-ttu-id="24103-230">Sie können den Zugriff auf die **Zeiger Haltung** über [SpatialInteractionSourceState::Properties::TryGetLocation (...):: SourcePointerPose](https://docs.microsoft.com/uwp/api/windows.ui.input.spatial.spatialinteractionsourcelocation#Windows_UI_Input_Spatial_SpatialInteractionSourceLocation_SourcePointerPose) oder [SpatialInteractionSourceState:: TryGetPointerPose (...):: TryGetInteractionSourcePose](https://docs.microsoft.com/uwp/api/windows.ui.input.spatial.spatialpointerpose#Windows_UI_Input_Spatial_SpatialPointerPose_TryGetInteractionSourcePose_Windows_UI_Input_Spatial_SpatialInteractionSource_).</span><span class="sxs-lookup"><span data-stu-id="24103-230">You can access the **pointer pose** through [SpatialInteractionSourceState::Properties::TryGetLocation(...)::SourcePointerPose](https://docs.microsoft.com/uwp/api/windows.ui.input.spatial.spatialinteractionsourcelocation#Windows_UI_Input_Spatial_SpatialInteractionSourceLocation_SourcePointerPose) or [SpatialInteractionSourceState::TryGetPointerPose(...)::TryGetInteractionSourcePose](https://docs.microsoft.com/uwp/api/windows.ui.input.spatial.spatialpointerpose#Windows_UI_Input_Spatial_SpatialPointerPose_TryGetInteractionSourcePose_Windows_UI_Input_Spatial_SpatialInteractionSource_).</span></span>

## <a name="controller-specific-input-properties"></a><span data-ttu-id="24103-231">Controller-spezifische Eingabeeigenschaften</span><span class="sxs-lookup"><span data-stu-id="24103-231">Controller-specific input properties</span></span>
<span data-ttu-id="24103-232">Für Controller verwendet hat die SpatialInteractionSource eine Controller-Eigenschaft, mit zusätzlichen Funktionen.</span><span class="sxs-lookup"><span data-stu-id="24103-232">For controllers, the SpatialInteractionSource has a Controller property with additional capabilities.</span></span>
* <span data-ttu-id="24103-233">**HasThumbstick:** Bei "true", hat der Controller eine Ministick an.</span><span class="sxs-lookup"><span data-stu-id="24103-233">**HasThumbstick:** If true, the controller has a thumbstick.</span></span> <span data-ttu-id="24103-234">Überprüfen Sie die [ControllerProperties](https://docs.microsoft.com/uwp/api/windows.ui.input.spatial.spatialinteractioncontrollerproperties) Eigenschaft der SpatialInteractionSourceState Ministick abrufen x und y-Werte (ThumbstickX und ThumbstickY) sowie ihren aktuellen Status (IsThumbstickPressed).</span><span class="sxs-lookup"><span data-stu-id="24103-234">Inspect the [ControllerProperties](https://docs.microsoft.com/uwp/api/windows.ui.input.spatial.spatialinteractioncontrollerproperties) property of the SpatialInteractionSourceState to acquire the thumbstick x and y values (ThumbstickX and ThumbstickY), as well as its pressed state (IsThumbstickPressed).</span></span>
* <span data-ttu-id="24103-235">**HasTouchpad:** Bei "true", hat der Controller Touchpads an.</span><span class="sxs-lookup"><span data-stu-id="24103-235">**HasTouchpad:** If true, the controller has a touchpad.</span></span> <span data-ttu-id="24103-236">Überprüfen Sie die ControllerProperties-Eigenschaft, der die SpatialInteractionSourceState zum Abrufen der Touchpad x- und y Werte (TouchpadX und TouchpadY), und wissen, ob der Benutzer das Pad "" (IsTouchpadTouched) berührt, und wenn sie das Touchpad nach unten (drücken, werden IsTouchpadPressed).</span><span class="sxs-lookup"><span data-stu-id="24103-236">Inspect the ControllerProperties property of the SpatialInteractionSourceState to acquire the touchpad x and y values (TouchpadX and TouchpadY), and to know if the user is touching the pad (IsTouchpadTouched) and if they are pressing the touchpad down (IsTouchpadPressed).</span></span>
* <span data-ttu-id="24103-237">**SimpleHapticsController:** Die SimpleHapticsController-API für den Controller können Sie die Funktionen Haptics des Controllers zu überprüfen, und sie können außerdem zum Übermitteln von haptischem Feedback zu steuern.</span><span class="sxs-lookup"><span data-stu-id="24103-237">**SimpleHapticsController:** The SimpleHapticsController API for the controller allows you to inspect the haptics capabilities of the controller, and it also allows you to control haptic feedback.</span></span>

<span data-ttu-id="24103-238">Beachten Sie, dass der Bereich für Touchpad und Ministick-1 für beide Achsen auf 1 (von unten nach oben und von links nach rechts).</span><span class="sxs-lookup"><span data-stu-id="24103-238">Note that the range for touchpad and thumbstick is -1 to 1 for both axes (from bottom to top, and from left to right).</span></span> <span data-ttu-id="24103-239">Der Bereich für den analogen Trigger, die mithilfe der SpatialInteractionSourceState::SelectPressedValue-Eigenschaft zugegriffen wird, hat es sich um einen Bereich von 0 bis 1.</span><span class="sxs-lookup"><span data-stu-id="24103-239">The range for the analog trigger, which is accessed using the SpatialInteractionSourceState::SelectPressedValue property, has a range of 0 to 1.</span></span> <span data-ttu-id="24103-240">Ein Wert von 1 korreliert mit IsSelectPressed ist gleich "true". Jeder andere Wert korreliert mit IsSelectPressed ist gleich "false".</span><span class="sxs-lookup"><span data-stu-id="24103-240">A value of 1 correlates with IsSelectPressed being equal to true; any other value correlates with IsSelectPressed being equal to false.</span></span>

## <a name="articulated-hand-tracking"></a><span data-ttu-id="24103-241">Umrissene manuell nachverfolgen</span><span class="sxs-lookup"><span data-stu-id="24103-241">Articulated hand tracking</span></span>
<span data-ttu-id="24103-242">Die Windows Mixed Reality-API bietet vollständige Unterstützung für definierte manuell nachverfolgen, z. B. für HoloLens 2.</span><span class="sxs-lookup"><span data-stu-id="24103-242">The Windows Mixed Reality API provides full support for articulated hand tracking, for example on HoloLens 2.</span></span> <span data-ttu-id="24103-243">Articulated manuell nachverfolgen kann verwendet werden, um die direkte Bearbeitung und Punkt-und-Commit-Eingabe-Modelle in Ihren Anwendungen implementieren.</span><span class="sxs-lookup"><span data-stu-id="24103-243">Articulated hand tracking can be used to implement direct manipulation and point-and-commit input models in your applications.</span></span> <span data-ttu-id="24103-244">Sie können auch verwendet werden, vollständig benutzerdefinierte Aktivitäten erstellen.</span><span class="sxs-lookup"><span data-stu-id="24103-244">It can also be used to author fully custom interactions.</span></span>

### <a name="hand-skeleton"></a><span data-ttu-id="24103-245">Hand-Gerüst</span><span class="sxs-lookup"><span data-stu-id="24103-245">Hand skeleton</span></span>
<span data-ttu-id="24103-246">Angezeigte Seite, die nachverfolgung bietet eine 25 joint Gerüst, das viele verschiedene Arten von Aktivitäten ermöglicht.</span><span class="sxs-lookup"><span data-stu-id="24103-246">Articulated hand tracking provides a 25 joint skeleton that enables many different types of interactions.</span></span>  <span data-ttu-id="24103-247">Das Gerüst enthält 5 Knoten für den Index/mittleren/Ring/kleinen Finger, 4 Joints für das Thumb-Steuerelement und 1 Handgelenk joint.</span><span class="sxs-lookup"><span data-stu-id="24103-247">The skeleton provides 5 joints for the index/middle/ring/little fingers, 4 joints for the thumb, and 1 wrist joint.</span></span>  <span data-ttu-id="24103-248">Das Handgelenk Joint dient als Basis der Hierarchie.</span><span class="sxs-lookup"><span data-stu-id="24103-248">The wrist joint serves as the base of the hierarchy.</span></span> <span data-ttu-id="24103-249">Die folgende Abbildung veranschaulicht das Gerüst des Layouts.</span><span class="sxs-lookup"><span data-stu-id="24103-249">The following picture illustrates the layout of the skeleton.</span></span>

![Hand-Gerüst](images/hand-skeleton.png)

<span data-ttu-id="24103-251">In den meisten Fällen wird jede Verbindung mit dem Namen basierend auf Knochenarbeit, die es darstellt.</span><span class="sxs-lookup"><span data-stu-id="24103-251">In most cases, each joint is named based on the bone that it represents.</span></span>  <span data-ttu-id="24103-252">Da es sich um zwei Bones an jedem Joint, verwenden wir eine Konvention für die Benennung von jeder Verbindung basierend auf den untergeordneten Knochenarbeit an diesem Speicherort aus.</span><span class="sxs-lookup"><span data-stu-id="24103-252">Since there are two bones at every joint, we use a convention of naming each joint based on the child bone at that location.</span></span>  <span data-ttu-id="24103-253">Untergeordnete Knochenarbeit wird als Knochenarbeit das. Handgelenk definiert.</span><span class="sxs-lookup"><span data-stu-id="24103-253">The child bone is defined as the bone further from the wrist.</span></span>  <span data-ttu-id="24103-254">Beispielsweise enthält der "Index nächsten" gemeinsame die Anfangsposition des nächsten Bones Index und die Ausrichtung des, Knochenarbeit.</span><span class="sxs-lookup"><span data-stu-id="24103-254">For example, the "Index Proximal" joint contains the beginning position of the index proximal bone, and the orientation of that bone.</span></span>  <span data-ttu-id="24103-255">Es sind nicht die Endposition des Bones enthalten.</span><span class="sxs-lookup"><span data-stu-id="24103-255">It does not contain the ending position of the bone.</span></span>  <span data-ttu-id="24103-256">Bei Bedarf, die erhalten sie von der nächsten in der Hierarchie, der "Index"Zwischenzertifizierungsstelle"gemeinsame joint Sie.</span><span class="sxs-lookup"><span data-stu-id="24103-256">If you need that, you'd get it from the next joint in the hierarchy, the "Index Intermediate" joint.</span></span>

<span data-ttu-id="24103-257">Zusätzlich zu den 25 hierarchischen Gelenken stellt das System eine Palm-Verbindung.</span><span class="sxs-lookup"><span data-stu-id="24103-257">In addition to the 25 hierarchical joints, the system provides a palm joint.</span></span>  <span data-ttu-id="24103-258">Legen Sie die gilt in der Regel nicht Teil der skeletal-Struktur.</span><span class="sxs-lookup"><span data-stu-id="24103-258">The palm is not typically considered part of the skeletal structure.</span></span>  <span data-ttu-id="24103-259">Es dient nur als eine einfache Möglichkeit, das des Handsymbol des gesamten Position und Ausrichtung zu erhalten.</span><span class="sxs-lookup"><span data-stu-id="24103-259">It is provided only as a convenient way to get the hand's overall position and orientation.</span></span>

<span data-ttu-id="24103-260">Die folgende Informationen werden für jede Verbindung bereitgestellt:</span><span class="sxs-lookup"><span data-stu-id="24103-260">The following information is provided for each joint:</span></span>

| <span data-ttu-id="24103-261">Name</span><span class="sxs-lookup"><span data-stu-id="24103-261">Name</span></span> | <span data-ttu-id="24103-262">Beschreibung</span><span class="sxs-lookup"><span data-stu-id="24103-262">Description</span></span> |
|--- |--- |
|<span data-ttu-id="24103-263">Position</span><span class="sxs-lookup"><span data-stu-id="24103-263">Position</span></span> | <span data-ttu-id="24103-264">3D-Position von der Verbindung, die in alle angeforderten Koordinatensystem verfügbar.</span><span class="sxs-lookup"><span data-stu-id="24103-264">3D position of the joint, available in any requested coordinate system.</span></span> |
|<span data-ttu-id="24103-265">Ausrichtung</span><span class="sxs-lookup"><span data-stu-id="24103-265">Orientation</span></span> | <span data-ttu-id="24103-266">3D-Orientierung des Bones, verfügbar in allen angeforderten Koordinatensystem.</span><span class="sxs-lookup"><span data-stu-id="24103-266">3D orientation of the bone, available in any requested coordinate system.</span></span> |
|<span data-ttu-id="24103-267">Radius</span><span class="sxs-lookup"><span data-stu-id="24103-267">Radius</span></span> | <span data-ttu-id="24103-268">Abstand und die Oberfläche der Skin an der gemeinsamen Position.</span><span class="sxs-lookup"><span data-stu-id="24103-268">Distance to surface of the skin at the joint position.</span></span> <span data-ttu-id="24103-269">Ist nützlich für die Optimierung der direkte Interaktionen oder Visualisierungen, die Finger Breite verwenden.</span><span class="sxs-lookup"><span data-stu-id="24103-269">Useful for tuning direct interactions or visualizations that rely on finger width.</span></span> |
|<span data-ttu-id="24103-270">Genauigkeit</span><span class="sxs-lookup"><span data-stu-id="24103-270">Accuracy</span></span> | <span data-ttu-id="24103-271">Stellt einen Hinweis auf eine Falls Ja: wie das System diese gemeinsam mit den Informationen fühlt.</span><span class="sxs-lookup"><span data-stu-id="24103-271">Provides a hint on how confident the system feels about this joint's information.</span></span> |

<span data-ttu-id="24103-272">Sie können die Skelett Hand-Daten über eine Funktion zugreifen, auf die [SpatialInteractionSourceState](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate).</span><span class="sxs-lookup"><span data-stu-id="24103-272">You can access the hand skeleton data through a function on the [SpatialInteractionSourceState](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate).</span></span>  <span data-ttu-id="24103-273">Die Funktion wird aufgerufen, [TryGetHandPose](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.trygethandpose#Windows_UI_Input_Spatial_SpatialInteractionSourceState_TryGetHandPose), und gibt ein Objekt namens [HandPose](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.handpose).</span><span class="sxs-lookup"><span data-stu-id="24103-273">The function is called [TryGetHandPose](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.trygethandpose#Windows_UI_Input_Spatial_SpatialInteractionSourceState_TryGetHandPose), and it returns an object called [HandPose](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.handpose).</span></span>  <span data-ttu-id="24103-274">Wenn die Quelle angezeigte Hände nicht unterstützt, gibt diese Funktion null zurück.</span><span class="sxs-lookup"><span data-stu-id="24103-274">If the source does not support articulated hands, then this function will return null.</span></span>  <span data-ttu-id="24103-275">Nachdem Sie eine HandPose haben, erhalten Sie aktuelle gemeinsame Daten durch den Aufruf [TryGetJoint](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.handpose.trygetjoint#Windows_Perception_People_HandPose_TryGetJoint_Windows_Perception_Spatial_SpatialCoordinateSystem_Windows_Perception_People_HandJointKind_Windows_Perception_People_JointPose__), durch den Namen des gemeinsamen Sie interessiert sind.</span><span class="sxs-lookup"><span data-stu-id="24103-275">Once you have a HandPose, you can get current joint data by calling [TryGetJoint](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.handpose.trygetjoint#Windows_Perception_People_HandPose_TryGetJoint_Windows_Perception_Spatial_SpatialCoordinateSystem_Windows_Perception_People_HandJointKind_Windows_Perception_People_JointPose__), with the name of the joint you are interested in.</span></span>  <span data-ttu-id="24103-276">Die Daten werden zurückgegeben, als eine [JointPose](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.jointpose) Struktur.</span><span class="sxs-lookup"><span data-stu-id="24103-276">The data is returned as a [JointPose](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.jointpose) structure.</span></span>  <span data-ttu-id="24103-277">Der folgende Code Ruft die Position des Tipps Zeigefinger ab.</span><span class="sxs-lookup"><span data-stu-id="24103-277">The following code gets the position of the index finger tip.</span></span> <span data-ttu-id="24103-278">Die Variable *CurrentState* stellt eine Instanz der [SpatialInteractionSourceState](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate).</span><span class="sxs-lookup"><span data-stu-id="24103-278">The variable *currentState* represents an instance of [SpatialInteractionSourceState](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate).</span></span>

```cpp
using namespace winrt::Windows::Perception::People;
using namespace winrt::Windows::Foundation::Numerics;

auto handPose = currentState.TryGetHandPose();
if (handPose)
{
    JointPose joint;
    if (handPose.TryGetJoint(desiredCoordinateSystem, HandJointKind::IndexTip, joint))
    {
        float3 indexTipPosition = joint.Position;

        // Do something with the index tip position
    }
}
```

### <a name="hand-mesh"></a><span data-ttu-id="24103-279">Hand-Netz</span><span class="sxs-lookup"><span data-stu-id="24103-279">Hand mesh</span></span>

<span data-ttu-id="24103-280">Die angezeigte manuell nachverfolgen API ermöglicht ein vollständig verformbaren Dreieckgitter zur Hand.</span><span class="sxs-lookup"><span data-stu-id="24103-280">The articulated hand tracking API allows for a fully deformable triangle hand mesh.</span></span>  <span data-ttu-id="24103-281">Dieses Mesh kann in Echtzeit zusammen mit der Hand-Gerüst deformieren, und eignet sich für die Visualisierung als auch erweiterte Physik Techniken.</span><span class="sxs-lookup"><span data-stu-id="24103-281">This mesh can deform in real time along with the hand skeleton, and is useful for visualization as well as advanced physics techniques.</span></span>  <span data-ttu-id="24103-282">Für den Zugriff auf das Netz Hand, müssen Sie zuerst erstellen eine [HandMeshObserver](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.handmeshobserver) Objekt durch Aufrufen von [TryCreateHandMeshObserverAsync](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsource.trycreatehandmeshobserverasync) auf die [SpatialInteractionSource](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsource).</span><span class="sxs-lookup"><span data-stu-id="24103-282">To access the hand mesh, you need to first create a [HandMeshObserver](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.handmeshobserver) object by calling [TryCreateHandMeshObserverAsync](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsource.trycreatehandmeshobserverasync) on the [SpatialInteractionSource](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsource).</span></span>  <span data-ttu-id="24103-283">Dies muss nur einmal pro Quelle, in der Regel beim ersten erfolgen angezeigt.</span><span class="sxs-lookup"><span data-stu-id="24103-283">This only needs to be done once per source, typically the first time you see it.</span></span>  <span data-ttu-id="24103-284">Das bedeutet, dass es sich bei nennen Sie diese Funktion, um ein HandMeshObserver-Objekt erstellen, wenn eine Seite das Blickfeld erreicht.</span><span class="sxs-lookup"><span data-stu-id="24103-284">That means you'll call this function to create a HandMeshObserver object whenever a hand enters the FOV.</span></span>  <span data-ttu-id="24103-285">Beachten Sie, dass dies eine Async-Funktion ist, müssen für den Umgang mit ein wenig Parallelität hier.</span><span class="sxs-lookup"><span data-stu-id="24103-285">Note that this is an async function, so you'll have to deal with a bit of concurrency here.</span></span>  <span data-ttu-id="24103-286">Sobald Sie verfügbar ist, kannst du das HandMeshObserver-Objekt für den Index-Puffer Dreieck durch Aufrufen von [GetTriangleIndices](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.handmeshobserver.gettriangleindices#Windows_Perception_People_HandMeshObserver_GetTriangleIndices_System_UInt16___).</span><span class="sxs-lookup"><span data-stu-id="24103-286">Once available, you can ask the HandMeshObserver object for the triangle index buffer by calling [GetTriangleIndices](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.handmeshobserver.gettriangleindices#Windows_Perception_People_HandMeshObserver_GetTriangleIndices_System_UInt16___).</span></span>  <span data-ttu-id="24103-287">Indizes ändern nicht Frame über Frames, damit Sie diese einmal abrufen und Zwischenspeichern für die Lebensdauer der Quelle.</span><span class="sxs-lookup"><span data-stu-id="24103-287">Indices don't change frame over frame, so you can get those once and cache them for the lifetime of the source.</span></span>  <span data-ttu-id="24103-288">Indizes werden in-wicklungsreihenfolge im Uhrzeigersinn angegeben.</span><span class="sxs-lookup"><span data-stu-id="24103-288">Indices are provided in clockwise winding order.</span></span>

<span data-ttu-id="24103-289">Der folgende Code startet einen getrennten Std:: Thread um den Beobachter Netz zu erstellen und Indexpuffer extrahiert, sobald der Beobachter Mesh verfügbar ist.</span><span class="sxs-lookup"><span data-stu-id="24103-289">The following code spins up a detached std::thread to create the mesh observer and extracts the index buffer once the mesh observer is available.</span></span>  <span data-ttu-id="24103-290">Er beginnt mit einer Variablen namens *CurrentState*, dies ist eine Instanz von [SpatialInteractionSourceState](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate) eine nachverfolgte Hand darstellt.</span><span class="sxs-lookup"><span data-stu-id="24103-290">It starts from a variable called *currentState*, which is an instance of [SpatialInteractionSourceState](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate) representing a tracked hand.</span></span>

```cpp
using namespace Windows::Perception::People;

std::thread createObserverThread([this, currentState]()
{
    HandMeshObserver newHandMeshObserver = currentState.Source().TryCreateHandMeshObserverAsync().get();
    if (newHandMeshObserver)
    {
        unsigned indexCount = newHandMeshObserver.TriangleIndexCount();
        vector<unsigned short> indices(indexCount);
        newHandMeshObserver.GetTriangleIndices(indices);

        // Save the indices and handMeshObserver for later use - and use a mutex to synchronize access if needed!
     }
});
createObserverThread.detach();
```
<span data-ttu-id="24103-291">Starten eines getrennten Threads ist nur eine Option für die Verarbeitung von asynchronen Aufrufe.</span><span class="sxs-lookup"><span data-stu-id="24103-291">Starting a detached thread is just one option for handling async calls.</span></span>  <span data-ttu-id="24103-292">Alternativ können Sie die neue verwenden [Co_await](https://docs.microsoft.com/en-us/windows/uwp/cpp-and-winrt-apis/concurrency) von unterstützten Funktionen C++"/ WinRT".</span><span class="sxs-lookup"><span data-stu-id="24103-292">Alternatively, you could use the new [co_await](https://docs.microsoft.com/en-us/windows/uwp/cpp-and-winrt-apis/concurrency) functionality supported by C++/WinRT.</span></span>

<span data-ttu-id="24103-293">Nachdem Sie ein Objekt HandMeshObserver haben, sollten Sie darum für die Dauer halten, die die entsprechenden SpatialInteractionSource aktiv ist.</span><span class="sxs-lookup"><span data-stu-id="24103-293">Once you have a HandMeshObserver object, you should hold onto it for the duration that its corresponding SpatialInteractionSource is active.</span></span>  <span data-ttu-id="24103-294">Klicken Sie dann für jeden Frame, kannst du es für den aktuellen Vertexpuffer, das das Handsymbol durch den Aufruf darstellt [GetVertexStateForPose](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.handmeshobserver.getvertexstateforpose) und übergeben Sie einen [HandPose](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.handpose) -Instanz, der Haltung darstellt, wirklich Vertices, für.</span><span class="sxs-lookup"><span data-stu-id="24103-294">Then each frame, you can ask it for the latest vertex buffer that represents the hand by calling [GetVertexStateForPose](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.handmeshobserver.getvertexstateforpose) and passing in a [HandPose](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.handpose) instance that represents the pose that you want vertices for.</span></span>  <span data-ttu-id="24103-295">Jeder Scheitelpunkt im Puffer hat eine Position und einer normalen.</span><span class="sxs-lookup"><span data-stu-id="24103-295">Each vertex in the buffer has a position and a normal.</span></span>  <span data-ttu-id="24103-296">Hier ist ein Beispiel für den aktuellen Satz von Vertices für ein Gitter manuell abrufen.</span><span class="sxs-lookup"><span data-stu-id="24103-296">Here's an example of how to get the current set of vertices for a hand mesh.</span></span>  <span data-ttu-id="24103-297">Wie zuvor, die *CurrentState* Variable stellt eine Instanz der [SpatialInteractionSourceState](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate).</span><span class="sxs-lookup"><span data-stu-id="24103-297">Just as before, the *currentState* variable represents an instance of [SpatialInteractionSourceState](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate).</span></span>

```cpp
using namespace winrt::Windows::Perception::People;

auto handPose = currentState.TryGetHandPose();
if (handPose)
{
    std::vector<HandMeshVertex> vertices(handMeshObserver.VertexCount());
    auto vertexState = handMeshObserver.GetVertexStateForPose(handPose);
    vertexState.GetVertices(vertices);

    auto meshTransform = vertexState.CoordinateSystem().TryGetTransformTo(desiredCoordinateSystem);
    if (meshTransform != nullptr)
    {
        // Do something with the vertices and mesh transform, along with the indices that you saved earlier
    }
}
```

<span data-ttu-id="24103-298">Im Gegensatz zu Skelett Gelenken lässt die manuell Mesh-API nicht an einem Koordinatensystem für die Scheitelpunkte.</span><span class="sxs-lookup"><span data-stu-id="24103-298">In contrast to skeleton joints, the hand mesh API does not allow you to specify a coordinate system for the vertices.</span></span>  <span data-ttu-id="24103-299">Stattdessen die [HandMeshVertexState](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.handmeshvertexstate) gibt das Koordinatensystem, die die Scheitelpunkte im bereitgestellt werden.</span><span class="sxs-lookup"><span data-stu-id="24103-299">Instead, the [HandMeshVertexState](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.handmeshvertexstate) specifies the coordinate system that the vertices are provided in.</span></span>  <span data-ttu-id="24103-300">Anschließend können Sie eine Transformation Mesh abrufen, durch den Aufruf [TryGetTransformTo](https://docs.microsoft.com/en-us/uwp/api/windows.perception.spatial.spatialcoordinatesystem.trygettransformto#Windows_Perception_Spatial_SpatialCoordinateSystem_TryGetTransformTo_Windows_Perception_Spatial_SpatialCoordinateSystem_) und Ihre gewünschte Koordinatensystem angeben.</span><span class="sxs-lookup"><span data-stu-id="24103-300">You can then get a mesh transform by calling [TryGetTransformTo](https://docs.microsoft.com/en-us/uwp/api/windows.perception.spatial.spatialcoordinatesystem.trygettransformto#Windows_Perception_Spatial_SpatialCoordinateSystem_TryGetTransformTo_Windows_Perception_Spatial_SpatialCoordinateSystem_) and specifying your desired coordinate system.</span></span>  <span data-ttu-id="24103-301">Sie müssen diese Mesh-Transformation zu verwenden, sobald Sie mit den Scheitelpunkten arbeiten.</span><span class="sxs-lookup"><span data-stu-id="24103-301">You'll need to use this mesh transform whenever you work with the vertices.</span></span>  <span data-ttu-id="24103-302">Dieser Ansatz reduziert die CPU-Auslastung, insbesondere dann, wenn Sie nur das Netz Rendering zu verwenden.</span><span class="sxs-lookup"><span data-stu-id="24103-302">This approach reduces CPU overhead, especially if you are only using the mesh for rendering purposes.</span></span>

## <a name="gaze-and-commit-composite-gestures"></a><span data-ttu-id="24103-303">Bestaunen Sie und Committen Sie zusammengesetzte Gesten</span><span class="sxs-lookup"><span data-stu-id="24103-303">Gaze and Commit composite gestures</span></span>
<span data-ttu-id="24103-304">Für Anwendungen, verwenden das Eingabemodell Blicke und Commits, insbesondere für HoloLens (der ersten Generation), die räumliche Eingabe-API bietet ein optionales [SpatialGestureRecognizer](https://msdn.microsoft.com/library/windows/apps/windows.ui.input.spatial.spatialgesturerecognizer.aspx) , verwendet werden kann, zusammengesetzte baut auf Gesten aktivieren die 'select' Ereignis.</span><span class="sxs-lookup"><span data-stu-id="24103-304">For applications using the gaze-and-commit input model, particularly on HoloLens (first gen), the Spatial Input API provides an optional [SpatialGestureRecognizer](https://msdn.microsoft.com/library/windows/apps/windows.ui.input.spatial.spatialgesturerecognizer.aspx) that can be used to to enable composite gestures built on top of the 'select' event.</span></span>  <span data-ttu-id="24103-305">Durch routing Interaktionen über die SpatialInteractionManager, ggf. ein Hologramm SpatialGestureRecognizer können Ereignisse tippen, halten, Bearbeitung und Navigation gleichmäßig über praktische, Sprach- und räumliche Eingabegeräte, erkennen Sie apps, ohne drückt behandeln zu müssen und manuell frei.</span><span class="sxs-lookup"><span data-stu-id="24103-305">By routing interactions from the SpatialInteractionManager to a hologram's SpatialGestureRecognizer, apps can detect Tap, Hold, Manipulation, and Navigation events uniformly across hands, voice, and spatial input devices, without having to handle presses and releases manually.</span></span>

<span data-ttu-id="24103-306">SpatialGestureRecognizer führt nur die minimale Mehrdeutigkeit zwischen den Satz von Aktionen, die Sie anfordern.</span><span class="sxs-lookup"><span data-stu-id="24103-306">SpatialGestureRecognizer performs only the minimal disambiguation between the set of gestures that you request.</span></span> <span data-ttu-id="24103-307">Z. B., wenn Sie nur tippen anfordern, kann der Benutzer den Finger halten Sie solange wie sie und durch Tippen auf finden weiterhin statt.</span><span class="sxs-lookup"><span data-stu-id="24103-307">For example, if you request just Tap, the user may hold their finger down as long as they like and a Tap will still occur.</span></span> <span data-ttu-id="24103-308">Wenn Sie anfordern, tippen Sie auf und enthalten Sie, die nach einer Sekunde von der Sie ihren Finger gedrückt halten, die Bewegung zu stehen stuft, und durch Tippen auf nicht mehr ausgeführt wird.</span><span class="sxs-lookup"><span data-stu-id="24103-308">If you request both Tap and Hold, after about a second of holding down their finger, the gesture will promote to a Hold and a Tap will no longer occur.</span></span>

<span data-ttu-id="24103-309">Um SpatialGestureRecognizer verwenden zu können, behandelt der SpatialInteractionManager des [InteractionDetected](https://msdn.microsoft.com/library/windows/apps/xaml/Windows.UI.Input.Spatial.SpatialInteractionManager.InteractionDetected) Ereignis- und Ziehpunkte, die es auf die SpatialPointerPose verfügbar gemacht.</span><span class="sxs-lookup"><span data-stu-id="24103-309">To use SpatialGestureRecognizer, handle the SpatialInteractionManager's [InteractionDetected](https://msdn.microsoft.com/library/windows/apps/xaml/Windows.UI.Input.Spatial.SpatialInteractionManager.InteractionDetected) event and grab the SpatialPointerPose exposed there.</span></span> <span data-ttu-id="24103-310">Verwenden für die Überschneidung mit den Hologramme des Benutzers Head Blicke Strahl von diesem Haltung und Oberfläche, die in der Umgebung des Benutzers, um zu bestimmen, was der Benutzer beabsichtigt ist, für die Interaktion mit Gitter.</span><span class="sxs-lookup"><span data-stu-id="24103-310">Use the user's head gaze ray from this pose to intersect with the holograms and surface meshes in the user's surroundings, in order to determine what the user is intending to interact with.</span></span> <span data-ttu-id="24103-311">Klicken Sie dann die SpatialInteraction weitergeleitet, in die Ereignisargumente, um das Ziel – Hologramm SpatialGestureRecognizer, mit dessen [CaptureInteraction](http://msdn.microsoft.com/library/windows/apps/xaml/Windows.UI.Input.Spatial.SpatialGestureRecognizer.CaptureInteraction) Methode.</span><span class="sxs-lookup"><span data-stu-id="24103-311">Then, route the SpatialInteraction in the event arguments to the target hologram's SpatialGestureRecognizer, using its [CaptureInteraction](http://msdn.microsoft.com/library/windows/apps/xaml/Windows.UI.Input.Spatial.SpatialGestureRecognizer.CaptureInteraction) method.</span></span> <span data-ttu-id="24103-312">Dies startet diese Interaktion nach Interpretation der [SpatialGestureSettings](https://msdn.microsoft.com/library/windows/apps/xaml/Windows.UI.Input.Spatial.SpatialGestureSettings) legen Sie für dieses Erkennungsmodul zum Zeitpunkt der Erstellung – oder durch [TrySetGestureSettings](http://msdn.microsoft.com/library/windows/apps/xaml/Windows.UI.Input.Spatial.SpatialGestureRecognizer.TrySetGestureSettings).</span><span class="sxs-lookup"><span data-stu-id="24103-312">This starts interpreting that interaction according to the [SpatialGestureSettings](https://msdn.microsoft.com/library/windows/apps/xaml/Windows.UI.Input.Spatial.SpatialGestureSettings) set on that recognizer at creation time - or by [TrySetGestureSettings](http://msdn.microsoft.com/library/windows/apps/xaml/Windows.UI.Input.Spatial.SpatialGestureRecognizer.TrySetGestureSettings).</span></span>

<span data-ttu-id="24103-313">Für HoloLens (der ersten Generation), Interaktionen und Gesten sollten im Allgemeinen ableiten, die für die Zielgruppenadressierung von Head Blicke des Benutzers, statt beim Rendern oder an die Hand, die Position direkt interagieren.</span><span class="sxs-lookup"><span data-stu-id="24103-313">On HoloLens (first gen), interactions and gestures should generally derive their targeting from the user's head gaze, rather than trying to render or interact at the hand's location directly.</span></span> <span data-ttu-id="24103-314">Nachdem eine Aktivität gestartet wurde, können relative Bewegungen des Zeigers verwendet werden zur Steuerung der Bewegung wie bei der Manipulation oder die Bildschirmnavigation Bewegung.</span><span class="sxs-lookup"><span data-stu-id="24103-314">Once an interaction has started, relative motions of the hand may be used to control the gesture, as with the Manipulation or Navigation gesture.</span></span>

## <a name="see-also"></a><span data-ttu-id="24103-315">Siehe auch</span><span class="sxs-lookup"><span data-stu-id="24103-315">See also</span></span>
* [<span data-ttu-id="24103-316">Haupt- und Eye Blicke in DirectX</span><span class="sxs-lookup"><span data-stu-id="24103-316">Head and eye gaze in DirectX</span></span>](gaze-in-directx.md)
* [<span data-ttu-id="24103-317">Direkte Bearbeitung Eingabemodell</span><span class="sxs-lookup"><span data-stu-id="24103-317">Direct manipulation input model</span></span>](direct-manipulation.md)
* [<span data-ttu-id="24103-318">Punkt-und-Commit-Eingabemodell</span><span class="sxs-lookup"><span data-stu-id="24103-318">Point-and-commit input model</span></span>](point-and-commit.md)
* [<span data-ttu-id="24103-319">Blicke und Commit Eingabemodell</span><span class="sxs-lookup"><span data-stu-id="24103-319">Gaze and commit input model</span></span>](gaze-and-commit.md)
* [<span data-ttu-id="24103-320">Motion-Controller</span><span class="sxs-lookup"><span data-stu-id="24103-320">Motion controllers</span></span>](motion-controllers.md)
